{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.28 (Sat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model: spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_web_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 86 total examples\n",
      "Using 43 train / 43 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2260.23       3.822      5.714      4.580                                 \n",
      " 2     304.20      96.203     72.381     82.609                                 \n",
      " 3      35.94      93.069     89.524     91.262                                 \n",
      " 4       7.71      91.262     89.524     90.385                                 \n",
      " 5       6.89      94.000     89.524     91.707                                 \n",
      " 6       6.26      94.949     89.524     92.157                                 \n",
      " 7       4.15      94.000     89.524     91.707                                 \n",
      " 8      10.58      92.157     89.524     90.821                                 \n",
      " 9       1.78      92.157     89.524     90.821                                 \n",
      "10       0.00      93.069     89.524     91.262                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.949   89.524    92.157\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m92.157\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_28_match/en_rf_web_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_match models/en_core_web_lg_no_ner --output models/2020_03_28_match/en_rf_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model: scispaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 86 total examples\n",
      "Using 43 train / 43 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1864.33       3.333      2.941      3.125                                 \n",
      " 2     303.79      93.902     75.490     83.696                                 \n",
      " 3      22.39      92.784     88.235     90.452                                 \n",
      " 4      17.47      94.792     89.216     91.919                                 \n",
      " 5       5.36      93.814     89.216     91.457                                 \n",
      " 6       6.78      92.857     89.216     91.000                                 \n",
      " 7       6.09      93.814     89.216     91.457                                 \n",
      " 8       4.87      94.792     89.216     91.919                                 \n",
      " 9       9.64      93.814     89.216     91.457                                 \n",
      "10       4.02      94.792     89.216     91.919                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.792   89.216    91.919\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m91.919\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_28_match/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_match models/en_core_sci_lg_no_ner --output models/2020_03_28_match/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.29 (Sun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model trained on Sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "def test_model(model_path):\n",
    "    warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "    \n",
    "    nlp = spacy.load(model_path)\n",
    "    texts = [\n",
    "    \"Known risk factors for the disease are: older age, male gender, diabetes and leukemia. Female patiens and children are less susceptible.\",\n",
    "    \"Diabetes is a known risk factor.\",\n",
    "    \"Leukemia is a risk factor, too.\"\n",
    "    ]\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "\n",
    "        spacy.displacy.render(doc, style='ent', jupyter=True)\n",
    "        pprint([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Known risk factors for the disease are: older \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    age\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    male\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " gender, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " and leukemia. Female patiens and children are less susceptible.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('age', 'RISK_FACTOR'), ('male', 'RISK_FACTOR'), ('diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " is a known risk factor.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Leukemia is a risk factor, too.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_model(\"models/2020_03_28_match/en_rf_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the factors that appeared during the training are detected. _Leukemia_ is **not highlighed** and that means that the NER model did not learn to recognize risk factors based on the sentence structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train new models after the `teach` session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_web_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 393 total examples\n",
      "Using 197 train / 196 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     333.36      89.669     92.735     91.176                                 \n",
      " 2      64.66      92.982     90.598     91.775                                 \n",
      " 3      53.47      94.492     95.299     94.894                                 \n",
      " 4      45.26      94.492     95.299     94.894                                 \n",
      " 5      29.42      94.958     96.581     95.763                                 \n",
      " 6      30.44      96.170     96.581     96.375                                 \n",
      " 7      23.82      95.745     96.154     95.949                                 \n",
      " 8       5.78      95.319     95.726     95.522                                 \n",
      " 9       4.12      95.299     95.299     95.299                                 \n",
      "10       5.46      96.137     95.726     95.931                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      96.170   96.581    96.375\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m96.375\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_29_teach/en_rf_web_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_teach models/en_core_web_lg_no_ner --output models/2020_03_29_teach/en_rf_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 393 total examples\n",
      "Using 197 train / 196 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     289.28      90.991     91.818     91.403                                 \n",
      " 2      54.12      92.237     91.818     92.027                                 \n",
      " 3      84.39      91.593     94.091     92.825                                 \n",
      " 4      46.45      93.213     93.636     93.424                                 \n",
      " 5      19.43      95.000     95.000     95.000                                 \n",
      " 6      15.25      93.665     94.091     93.878                                 \n",
      " 7       4.07      93.363     95.909     94.619                                 \n",
      " 8      11.23      93.722     95.000     94.357                                 \n",
      " 9      10.13      94.595     95.455     95.023                                 \n",
      "10       6.20      94.595     95.455     95.023                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.595   95.455    95.023\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m95.023\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_29_teach/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_teach models/en_core_sci_lg_no_ner --output models/2020_03_29_teach/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Known risk factors for the disease are: older \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    age\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    male gender\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " and leukemia. Female patiens and children are less susceptible.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('age', 'RISK_FACTOR'),\n",
      " ('male gender', 'RISK_FACTOR'),\n",
      " ('diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " is a known risk factor.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Leukemia is a risk factor, too.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_model(\"models/2020_03_29_teach/en_rf_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better model scores, but _leukemia_ still **not detected**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.30 (Mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`strict`)\n",
    "\n",
    "Terms like _male_ or _age_ will only be marked, when they are mentioned in the context of COVID-19 risk factors, i.e. not in articles about animals or children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_abstracts_strict to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 41 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_abstracts_strict\n",
      "Session ID: 2020-03-30_20-24-26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual cord_19_abstracts_strict models/en_core_sci_lg_no_ner data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR --patterns patterns/RF_list_2020.03.17.20037572.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 41 total examples\n",
      "Using 21 train / 20 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1737.49       0.000      0.000      0.000                                 \n",
      " 2      25.99       0.000      0.000      0.000                                 \n",
      " 3     115.63       0.000      0.000      0.000                                 \n",
      " 4      24.86       0.000      0.000      0.000                                 \n",
      " 5      22.36       0.000      0.000      0.000                                 \n",
      " 6      18.33       0.000      0.000      0.000                                 \n",
      " 7      20.52       0.000      0.000      0.000                                 \n",
      " 8      28.45       0.000      0.000      0.000                                 \n",
      " 9      18.38       0.000      0.000      0.000                                 \n",
      "10       7.78       0.000      0.000      0.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR       0.000    0.000     0.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m0.000\u001b[0m\n",
      "Baseline       0.000             \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_30_strict/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_strict models/en_core_sci_lg_no_ner --output models/2020_03_30_strict/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`all RF`)\n",
    "\n",
    "Highlight all risk factors - for any disease or species - but only is sentences that clear say it is a risk factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!prodigy ner.manual cord_19_abstracts_all_rf models/en_core_sci_lg_no_ner data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR --patterns patterns/RF_highlight_factor_phrases.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 58 total examples\n",
      "Using 29 train / 29 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1960.54       0.000      0.000      0.000                                 \n",
      " 2      95.38       0.000      0.000      0.000                                 \n",
      " 3     161.78     100.000      2.128      4.167                                 \n",
      " 4      88.78      40.000      4.255      7.692                                 \n",
      " 5      97.87      33.333      4.255      7.547                                 \n",
      " 6      87.81      37.500      6.383     10.909                                 \n",
      " 7     341.72      25.000      2.128      3.922                                 \n",
      " 8     169.64      40.000      4.255      7.692                                 \n",
      " 9      79.07      30.000      6.383     10.526                                 \n",
      "10     268.87      33.333      6.383     10.714                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      37.500    6.383    10.909\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m10.909\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_30_all_RF/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_abstracts_all_rf models/en_core_sci_lg_no_ner --output models/2020_03_30_all_RF/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "\n",
      "✨  Starting the web server at http://localhost:8081 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 7 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_abstracts_all_rf\n",
      "Session ID: 2020-03-30_22-01-26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.teach cord_19_abstracts_all_rf models/2020_03_30_all_RF/en_rf_sci_lg data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.06 (Mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`RF sentences`)\n",
    "\n",
    "Following the official guide:\n",
    "- https://www.youtube.com/watch?v=59BKHO_xBPA\n",
    "- https://github.com/explosion/projects/tree/master/ner-food-ingredients#data-creation-and-training-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 102 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences\n",
      "Session ID: 2020-04-06_22-08-56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual cord_19_rf_sentences blank:en data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     389.18       0.000      0.000      0.000                                 \n",
      " 2     191.03      25.000      4.000      6.897                                 \n",
      " 3     265.45      35.294     24.000     28.571                                 \n",
      " 4     246.57      28.571     24.000     26.087                                 \n",
      " 5     239.21      22.727     20.000     21.277                                 \n",
      " 6     215.80      42.857     24.000     30.769                                 \n",
      " 7     258.40      42.105     32.000     36.364                                 \n",
      " 8     237.19      50.000     32.000     39.024                                 \n",
      " 9     208.67      62.500     40.000     48.780                                 \n",
      "10     141.30      66.667     40.000     50.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667   40.000    50.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m50.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1421.81       0.000      0.000      0.000                                 \n",
      " 2    1245.16       0.000      0.000      0.000                                 \n",
      " 3    1262.77       0.000      0.000      0.000                                 \n",
      " 4    1249.04       0.000      0.000      0.000                                 \n",
      " 5    1262.46       0.000      0.000      0.000                                 \n",
      " 6    1205.26       0.000      0.000      0.000                                 \n",
      " 7    1137.92       0.000      0.000      0.000                                 \n",
      " 8    1131.84       0.000      0.000      0.000                                 \n",
      " 9    1058.85       0.000      0.000      0.000                                 \n",
      "10    1143.62       0.000      0.000      0.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "GPE               0.000    0.000     0.000\n",
      "RISK_FACTOR       0.000    0.000     0.000\n",
      "CARDINAL          0.000    0.000     0.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m0.000\u001b[0m\n",
      "Baseline       0.000             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⁉️ Why is `en_core_web_lg` producing no results at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     559.17       0.000      0.000      0.000                                 \n",
      " 2     550.33      33.333      8.000     12.903                                 \n",
      " 3     538.43      50.000     24.000     32.432                                 \n",
      " 4     457.89      52.632     40.000     45.455                                 \n",
      " 5     452.06      50.000     36.000     41.860                                 \n",
      " 6     415.01      60.000     48.000     53.333                                 \n",
      " 7     489.45      47.826     44.000     45.833                                 \n",
      " 8     461.13      45.000     36.000     40.000                                 \n",
      " 9     486.03      47.619     40.000     43.478                                 \n",
      "10     406.83      54.545     48.000     51.064                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   48.000    53.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m53.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_06_rf_sentences\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 --output models/2020_04_06_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "embed_rows: 2000 | require_vectors: True | cnn_maxout_pieces: 3 |\n",
      "token_vector_width: 96 | conv_depth: 4 | nr_feature_tokens: 3 |\n",
      "pretrained_vectors: en_vectors_web_lg.vectors\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     339.88       0.000      0.000      0.000                                 \n",
      " 2     199.85      50.000     16.000     24.242                                 \n",
      " 3     128.26      50.000     28.000     35.897                                 \n",
      " 4      76.43      42.857     24.000     30.769                                 \n",
      " 5      63.28      60.000     36.000     45.000                                 \n",
      " 6      29.70      53.333     32.000     40.000                                 \n",
      " 7      21.18      56.250     36.000     43.902                                 \n",
      " 8      36.86      50.000     36.000     41.860                                 \n",
      " 9      13.28      52.941     36.000     42.857                                 \n",
      "10       7.74      52.941     36.000     42.857                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   36.000    45.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m45.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2055.18       0.000      0.000      0.000                                 \n",
      " 2    1808.48       0.000      0.000      0.000                                 \n",
      " 3    1624.76       0.000      0.000      0.000                                 \n",
      " 4    1443.31       0.000      0.000      0.000                                 \n",
      " 5    1652.93       0.000      0.000      0.000                                 \n",
      " 6    1470.22       0.000      0.000      0.000                                 \n",
      " 7    1345.14       0.000      0.000      0.000                                 \n",
      " 8    1403.16      50.000      4.000      7.407                                 \n",
      " 9    1249.90      66.667      8.000     14.286                                 \n",
      "10    1357.22      66.667      8.000     14.286                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667    8.000    14.286\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m14.286\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     536.68       0.000      0.000      0.000                                 \n",
      " 2     631.61       0.000      0.000      0.000                                 \n",
      " 3     539.99      40.000     24.000     30.000                                 \n",
      " 4     505.27      47.619     40.000     43.478                                 \n",
      " 5     508.05      45.000     36.000     40.000                                 \n",
      " 6     461.69      52.941     36.000     42.857                                 \n",
      " 7     473.25      45.000     36.000     40.000                                 \n",
      " 8     571.35      61.111     44.000     51.163                                 \n",
      " 9     465.27      55.556     40.000     46.512                                 \n",
      "10     455.26      43.750     28.000     34.146                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      61.111   44.000    51.163\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m51.163\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label more data by correcting the model's predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model so far will be used: `Best F-Score   53.333`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_rf_sentences_correct to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 220 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences_correct\n",
      "Session ID: 2020-04-06_23-58-48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.correct cord_19_rf_sentences_correct models/2020_04_06_rf_sentences data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR --exclude cord_19_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For futher training, only `en_core_sci_lg` will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1554.25      61.538     37.500     46.602                                 \n",
      " 2    1346.09      64.407     59.375     61.789                                 \n",
      " 3    1407.15      66.667     50.000     57.143                                 \n",
      " 4    1411.73      72.727     50.000     59.259                                 \n",
      " 5    1412.81      73.913     53.125     61.818                                 \n",
      " 6    1319.96      73.913     53.125     61.818                                 \n",
      " 7    1378.05      72.917     54.688     62.500                                 \n",
      " 8    1208.99      72.727     62.500     67.227                                 \n",
      " 9    1177.16      73.077     59.375     65.517                                 \n",
      "10    1211.40      72.549     57.812     64.348                                 \n",
      "11    1142.34      74.510     59.375     66.087                                 \n",
      "12    1196.27      72.000     56.250     63.158                                 \n",
      "13    1153.93      72.000     56.250     63.158                                 \n",
      "14    1149.78      72.549     57.812     64.348                                 \n",
      "15    1154.34      69.231     56.250     62.069                                 \n",
      "16    1104.68      69.231     56.250     62.069                                 \n",
      "17    1062.17      68.627     54.688     60.870                                 \n",
      "18    1063.28      68.627     54.688     60.870                                 \n",
      "19    1048.51      68.627     54.688     60.870                                 \n",
      "20    1120.40      68.627     54.688     60.870                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.727   62.500    67.227\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.227\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1578.16      64.000     25.000     35.955                                 \n",
      " 2    1439.61      55.319     40.625     46.847                                 \n",
      " 3    1528.20      72.222     60.938     66.102                                 \n",
      " 4    1429.18      71.154     57.812     63.793                                 \n",
      " 5    1414.46      69.388     53.125     60.177                                 \n",
      " 6    1344.69      75.472     62.500     68.376                                 \n",
      " 7    1472.62      70.909     60.938     65.546                                 \n",
      " 8    1296.39      74.545     64.062     68.908                                 \n",
      " 9    1285.11      68.966     62.500     65.574                                 \n",
      "10    1236.84      70.175     62.500     66.116                                 \n",
      "11    1181.13      71.429     62.500     66.667                                 \n",
      "12    1235.60      70.909     60.938     65.546                                 \n",
      "13    1238.99      76.923     62.500     68.966                                 \n",
      "14    1151.94      75.926     64.062     69.492                                 \n",
      "15    1151.25      75.926     64.062     69.492                                 \n",
      "16    1218.30      78.000     60.938     68.421                                 \n",
      "17    1074.01      75.926     64.062     69.492                                 \n",
      "18    1121.71      76.364     65.625     70.588                                 \n",
      "19    1084.27      77.358     64.062     70.085                                 \n",
      "20    1106.32      76.471     60.938     67.826                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_07_rf_sentences_corrected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin --output models/2020_04_07_rf_sentences_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.28      62.500     23.438     34.091                                 \n",
      " 2    1397.40      59.091     40.625     48.148                                 \n",
      " 3    1485.47      70.833     53.125     60.714                                 \n",
      " 4    1445.56      68.293     43.750     53.333                                 \n",
      " 5    1431.31      64.000     50.000     56.140                                 \n",
      " 6    1339.87      70.833     53.125     60.714                                 \n",
      " 7    1387.07      72.340     53.125     61.261                                 \n",
      " 8    1232.74      76.596     56.250     64.865                                 \n",
      " 9    1207.39      72.340     53.125     61.261                                 \n",
      "10    1231.53      75.926     64.062     69.492                                 \n",
      "11    1154.22      74.545     64.062     68.908                                 \n",
      "12    1304.76      75.472     62.500     68.376                                 \n",
      "13    1155.21      69.811     57.812     63.248                                 \n",
      "14    1158.97      67.273     57.812     62.185                                 \n",
      "15    1092.88      69.811     57.812     63.248                                 \n",
      "16    1134.04      68.627     54.688     60.870                                 \n",
      "17    1055.42      66.667     56.250     61.017                                 \n",
      "18    1071.15      66.667     56.250     61.017                                 \n",
      "19    1060.90      69.231     56.250     62.069                                 \n",
      "20    1063.32      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model989.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.09 (Thu)\n",
    "## Experiments with new `tok2vec` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1577.68      57.895     34.375     43.137                                 \n",
      " 2    1386.95      67.308     54.688     60.345                                 \n",
      " 3    1455.49      76.596     56.250     64.865                                 \n",
      " 4    1457.04      79.592     60.938     69.027                                 \n",
      " 5    1413.30      78.431     62.500     69.565                                 \n",
      " 6    1351.85      76.923     62.500     68.966                                 \n",
      " 7    1304.38      78.000     60.938     68.421                                 \n",
      " 8    1255.67      76.471     60.938     67.826                                 \n",
      " 9    1219.66      78.431     62.500     69.565                                 \n",
      "10    1203.83      74.545     64.062     68.908                                 \n",
      "11    1125.02      74.545     64.062     68.908                                 \n",
      "12    1224.65      74.074     62.500     67.797                                 \n",
      "13    1173.56      75.000     60.938     67.241                                 \n",
      "14    1170.88      75.000     60.938     67.241                                 \n",
      "15    1074.42      71.154     57.812     63.793                                 \n",
      "16    1144.97      75.000     60.938     67.241                                 \n",
      "17    1041.02      73.077     59.375     65.517                                 \n",
      "18    1094.32      74.510     59.375     66.087                                 \n",
      "19    1051.65      74.510     59.375     66.087                                 \n",
      "20    1099.61      78.000     60.938     68.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.431   62.500    69.565\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.565\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model978_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1630.03      55.556     23.438     32.967                                 \n",
      " 2    1442.41      55.556     46.875     50.847                                 \n",
      " 3    1429.19      65.957     48.438     55.856                                 \n",
      " 4    1467.20      65.455     56.250     60.504                                 \n",
      " 5    1467.20      69.643     60.938     65.000                                 \n",
      " 6    1376.49      67.241     60.938     63.934                                 \n",
      " 7    1324.06      73.585     60.938     66.667                                 \n",
      " 8    1261.74      75.472     62.500     68.376                                 \n",
      " 9    1229.62      77.358     64.062     70.085                                 \n",
      "10    1162.35      74.545     64.062     68.908                                 \n",
      "11    1129.31      72.727     62.500     67.227                                 \n",
      "12    1226.05      73.684     65.625     69.421                                 \n",
      "13    1154.44      73.684     65.625     69.421                                 \n",
      "14    1146.38      69.492     64.062     66.667                                 \n",
      "15    1157.15      70.175     62.500     66.116                                 \n",
      "16    1122.06      72.549     57.812     64.348                                 \n",
      "17    1069.36      70.909     60.938     65.546                                 \n",
      "18    1112.07      71.930     64.062     67.769                                 \n",
      "19    1040.95      70.370     59.375     64.407                                 \n",
      "20    1074.33      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   64.062    70.085\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.085\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model997_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1587.95      62.963     26.562     37.363                                 \n",
      " 2    1500.37      60.784     48.438     53.913                                 \n",
      " 3    1510.36      63.492     62.500     62.992                                 \n",
      " 4    1519.20      60.000     56.250     58.065                                 \n",
      " 5    1521.26      65.574     62.500     64.000                                 \n",
      " 6    1495.73      64.912     57.812     61.157                                 \n",
      " 7    1386.50      65.517     59.375     62.295                                 \n",
      " 8    1225.63      65.574     62.500     64.000                                 \n",
      " 9    1277.40      65.079     64.062     64.567                                 \n",
      "10    1258.71      62.903     60.938     61.905                                 \n",
      "11    1151.32      61.905     60.938     61.417                                 \n",
      "12    1249.35      63.793     57.812     60.656                                 \n",
      "13    1169.56      67.241     60.938     63.934                                 \n",
      "14    1163.40      65.517     59.375     62.295                                 \n",
      "15    1137.84      65.517     59.375     62.295                                 \n",
      "16    1137.22      67.241     60.938     63.934                                 \n",
      "17    1094.24      67.857     59.375     63.333                                 \n",
      "18    1079.29      63.793     57.812     60.656                                 \n",
      "19    1028.63      63.158     56.250     59.504                                 \n",
      "20    1096.86      63.158     56.250     59.504                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.079   64.062    64.567\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.567\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_abs_fil_sci_model975_gpu.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.10 (Fri)\n",
    "## Experiments with new `tok2vec` models (cont.)\n",
    "\n",
    "The Kaggle notebook training models for the full set of abstracts (i.e. `cord_19_abstracts.jsonl`) crashed, so I have only partial results and no loss metrics for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model100.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.29      43.478     31.250     36.364                                 \n",
      " 2    1421.36      59.574     43.750     50.450                                 \n",
      " 3    1486.19      68.519     57.812     62.712                                 \n",
      " 4    1477.14      70.000     54.688     61.404                                 \n",
      " 5    1389.42      73.469     56.250     63.717                                 \n",
      " 6    1377.87      70.000     54.688     61.404                                 \n",
      " 7    1379.27      65.385     53.125     58.621                                 \n",
      " 8    1256.60      64.151     53.125     58.120                                 \n",
      " 9    1242.36      66.038     54.688     59.829                                 \n",
      "10    1237.03      63.636     54.688     58.824                                 \n",
      "11    1130.25      65.385     53.125     58.621                                 \n",
      "12    1249.05      65.455     56.250     60.504                                 \n",
      "13    1186.25      68.519     57.812     62.712                                 \n",
      "14    1166.91      68.519     57.812     62.712                                 \n",
      "15    1119.23      66.071     57.812     61.667                                 \n",
      "16    1100.72      67.925     56.250     61.538                                 \n",
      "17    1057.66      74.576     68.750     71.545                                 \n",
      "18    1086.26      74.138     67.188     70.492                                 \n",
      "19    1057.49      69.841     68.750     69.291                                 \n",
      "20    1090.37      73.684     65.625     69.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model103.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1615.03      42.308     34.375     37.931                                 \n",
      " 2    1529.31      54.167     40.625     46.429                                 \n",
      " 3    1432.51      61.905     60.938     61.417                                 \n",
      " 4    1456.81      64.407     59.375     61.789                                 \n",
      " 5    1486.92      66.176     70.312     68.182                                 \n",
      " 6    1414.35      59.649     53.125     56.198                                 \n",
      " 7    1351.85      64.706     51.562     57.391                                 \n",
      " 8    1280.06      66.667     50.000     57.143                                 \n",
      " 9    1247.71      68.085     50.000     57.658                                 \n",
      "10    1260.09      64.706     51.562     57.391                                 \n",
      "11    1175.66      63.636     54.688     58.824                                 \n",
      "12    1233.33      66.038     54.688     59.829                                 \n",
      "13    1183.98      66.038     54.688     59.829                                 \n",
      "14    1172.20      65.455     56.250     60.504                                 \n",
      "15    1133.71      66.000     51.562     57.895                                 \n",
      "16    1148.27      70.000     54.688     61.404                                 \n",
      "17    1097.20      66.000     51.562     57.895                                 \n",
      "18    1111.37      67.347     51.562     58.407                                 \n",
      "19    1078.84      66.000     51.562     57.895                                 \n",
      "20    1081.29      66.667     53.125     59.130                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.176   70.312    68.182\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.182\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model106.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1626.49      51.282     31.250     38.835                                 \n",
      " 2    1402.84      58.333     43.750     50.000                                 \n",
      " 3    1448.12      69.492     64.062     66.667                                 \n",
      " 4    1425.40      66.102     60.938     63.415                                 \n",
      " 5    1443.46      65.625     65.625     65.625                                 \n",
      " 6    1467.54      63.636     54.688     58.824                                 \n",
      " 7    1365.40      67.241     60.938     63.934                                 \n",
      " 8    1221.18      71.667     67.188     69.355                                 \n",
      " 9    1211.09      69.355     67.188     68.254                                 \n",
      "10    1197.41      65.079     64.062     64.567                                 \n",
      "11    1144.63      67.742     65.625     66.667                                 \n",
      "12    1278.95      67.213     64.062     65.600                                 \n",
      "13    1184.90      68.333     64.062     66.129                                 \n",
      "14    1168.25      67.213     64.062     65.600                                 \n",
      "15    1127.71      68.852     65.625     67.200                                 \n",
      "16    1109.56      69.492     64.062     66.667                                 \n",
      "17    1091.60      70.000     65.625     67.742                                 \n",
      "18    1102.18      70.492     67.188     68.800                                 \n",
      "19    1059.60      70.492     67.188     68.800                                 \n",
      "20    1087.33      70.492     67.188     68.800                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.667   67.188    69.355\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.355\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model109.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1561.45      39.130     28.125     32.727                                 \n",
      " 2    1401.05      67.347     51.562     58.407                                 \n",
      " 3    1566.76      68.519     57.812     62.712                                 \n",
      " 4    1543.17      69.565     50.000     58.182                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5    1438.40      69.767     46.875     56.075                                 \n",
      " 6    1374.64      72.340     53.125     61.261                                 \n",
      " 7    1349.92      70.833     53.125     60.714                                 \n",
      " 8    1265.91      73.585     60.938     66.667                                 \n",
      " 9    1237.50      71.698     59.375     64.957                                 \n",
      "10    1189.43      69.811     57.812     63.248                                 \n",
      "11    1123.23      68.519     57.812     62.712                                 \n",
      "12    1216.75      68.966     62.500     65.574                                 \n",
      "13    1190.32      68.966     62.500     65.574                                 \n",
      "14    1141.33      72.222     60.938     66.102                                 \n",
      "15    1148.12      72.727     62.500     67.227                                 \n",
      "16    1092.32      70.909     60.938     65.546                                 \n",
      "17    1053.18      74.545     64.062     68.908                                 \n",
      "18    1112.70      72.727     62.500     67.227                                 \n",
      "19    1049.31      72.222     60.938     66.102                                 \n",
      "20    1076.63      73.077     59.375     65.517                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   64.062    68.908\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.908\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model112.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1576.27      45.238     29.688     35.849                                 \n",
      " 2    1436.61      56.250     42.188     48.214                                 \n",
      " 3    1422.12      68.519     57.812     62.712                                 \n",
      " 4    1410.82      68.966     62.500     65.574                                 \n",
      " 5    1346.28      68.966     62.500     65.574                                 \n",
      " 6    1402.36      68.000     53.125     59.649                                 \n",
      " 7    1353.25      73.913     53.125     61.818                                 \n",
      " 8    1308.22      74.074     62.500     67.797                                 \n",
      " 9    1251.09      70.833     53.125     60.714                                 \n",
      "10    1157.35      66.667     53.125     59.130                                 \n",
      "11    1099.64      68.000     53.125     59.649                                 \n",
      "12    1199.89      67.308     54.688     60.345                                 \n",
      "13    1153.75      67.308     54.688     60.345                                 \n",
      "14    1179.79      68.627     54.688     60.870                                 \n",
      "15    1119.03      70.000     54.688     61.404                                 \n",
      "16    1096.21      68.627     54.688     60.870                                 \n",
      "17    1063.56      66.038     54.688     59.829                                 \n",
      "18    1089.48      64.815     54.688     59.322                                 \n",
      "19    1062.14      66.038     54.688     59.829                                 \n",
      "20    1117.95      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.074   62.500    67.797\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.797\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model115.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1597.96      48.837     32.812     39.252                                 \n",
      " 2    1450.79      54.545     46.875     50.420                                 \n",
      " 3    1411.01      64.583     48.438     55.357                                 \n",
      " 4    1443.18      72.549     57.812     64.348                                 \n",
      " 5    1479.16      62.264     51.562     56.410                                 \n",
      " 6    1378.43      65.574     62.500     64.000                                 \n",
      " 7    1362.59      62.264     51.562     56.410                                 \n",
      " 8    1246.27      69.231     56.250     62.069                                 \n",
      " 9    1255.67      66.000     51.562     57.895                                 \n",
      "10    1204.06      69.811     57.812     63.248                                 \n",
      "11    1135.99      66.667     56.250     61.017                                 \n",
      "12    1217.70      66.038     54.688     59.829                                 \n",
      "13    1187.47      62.000     48.438     54.386                                 \n",
      "14    1155.20      63.265     48.438     54.867                                 \n",
      "15    1099.30      64.583     48.438     55.357                                 \n",
      "16    1118.82      64.000     50.000     56.140                                 \n",
      "17    1060.48      66.667     50.000     57.143                                 \n",
      "18    1078.31      64.583     48.438     55.357                                 \n",
      "19    1085.52      62.500     46.875     53.571                                 \n",
      "20    1087.44      63.265     48.438     54.867                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.549   57.812    64.348\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.348\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model118.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1587.78      51.163     34.375     41.121                                 \n",
      " 2    1538.60      62.500     46.875     53.571                                 \n",
      " 3    1498.85      69.388     53.125     60.177                                 \n",
      " 4    1392.61      64.151     53.125     58.120                                 \n",
      " 5    1462.58      65.000     60.938     62.903                                 \n",
      " 6    1388.14      70.492     67.188     68.800                                 \n",
      " 7    1336.71      66.667     62.500     64.516                                 \n",
      " 8    1257.79      67.241     60.938     63.934                                 \n",
      " 9    1174.52      68.966     62.500     65.574                                 \n",
      "10    1169.98      66.102     60.938     63.415                                 \n",
      "11    1128.97      67.241     60.938     63.934                                 \n",
      "12    1218.23      63.333     59.375     61.290                                 \n",
      "13    1162.66      65.000     60.938     62.903                                 \n",
      "14    1179.99      66.129     64.062     65.079                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    1132.84      70.690     64.062     67.213                                 \n",
      "16    1097.80      70.909     60.938     65.546                                 \n",
      "17    1067.76      69.091     59.375     63.866                                 \n",
      "18    1100.65      69.643     60.938     65.000                                 \n",
      "19    1028.38      72.222     60.938     66.102                                 \n",
      "20    1105.80      72.222     60.938     66.102                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.492   67.188    68.800\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.800\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model121.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1586.76      47.619     31.250     37.736                                 \n",
      " 2    1425.95      56.522     40.625     47.273                                 \n",
      " 3    1437.64      71.930     64.062     67.769                                 \n",
      " 4    1422.12      67.241     60.938     63.934                                 \n",
      " 5    1435.75      70.000     65.625     67.742                                 \n",
      " 6    1328.16      69.091     59.375     63.866                                 \n",
      " 7    1376.11      69.643     60.938     65.000                                 \n",
      " 8    1266.11      70.492     67.188     68.800                                 \n",
      " 9    1211.72      69.231     70.312     69.767                                 \n",
      "10    1189.08      67.164     70.312     68.702                                 \n",
      "11    1153.66      70.149     73.438     71.756                                 \n",
      "12    1186.26      68.657     71.875     70.229                                 \n",
      "13    1190.30      69.841     68.750     69.291                                 \n",
      "14    1202.16      67.692     68.750     68.217                                 \n",
      "15    1145.89      66.667     68.750     67.692                                 \n",
      "16    1085.16      69.231     70.312     69.767                                 \n",
      "17    1087.67      68.254     67.188     67.717                                 \n",
      "18    1099.13      66.667     65.625     66.142                                 \n",
      "19    1046.86      67.692     68.750     68.217                                 \n",
      "20    1091.00      67.188     67.188     67.188                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.149   73.438    71.756\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.756\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model124.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1650.20      47.500     29.688     36.538                                 \n",
      " 2    1426.98      50.909     43.750     47.059                                 \n",
      " 3    1492.49      66.129     64.062     65.079                                 \n",
      " 4    1424.81      74.510     59.375     66.087                                 \n",
      " 5    1363.71      68.627     54.688     60.870                                 \n",
      " 6    1391.24      68.750     51.562     58.929                                 \n",
      " 7    1361.91      75.000     65.625     70.000                                 \n",
      " 8    1198.71      69.492     64.062     66.667                                 \n",
      " 9    1254.03      71.667     67.188     69.355                                 \n",
      "10    1205.19      71.930     64.062     67.769                                 \n",
      "11    1161.62      70.690     64.062     67.213                                 \n",
      "12    1246.74      71.186     65.625     68.293                                 \n",
      "13    1189.68      72.414     65.625     68.852                                 \n",
      "14    1155.81      71.667     67.188     69.355                                 \n",
      "15    1112.24      69.355     67.188     68.254                                 \n",
      "16    1096.56      69.355     67.188     68.254                                 \n",
      "17    1050.63      69.492     64.062     66.667                                 \n",
      "18    1058.49      70.690     64.062     67.213                                 \n",
      "19    1075.17      71.429     62.500     66.667                                 \n",
      "20    1097.10      70.690     64.062     67.213                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   65.625    70.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model127.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1560.14      57.143     31.250     40.404                                 \n",
      " 2    1460.59      63.158     56.250     59.504                                 \n",
      " 3    1444.44      67.857     59.375     63.333                                 \n",
      " 4    1443.53      60.000     51.562     55.462                                 \n",
      " 5    1390.15      64.286     56.250     60.000                                 \n",
      " 6    1387.46      70.833     53.125     60.714                                 \n",
      " 7    1405.40      70.000     54.688     61.404                                 \n",
      " 8    1248.66      69.388     53.125     60.177                                 \n",
      " 9    1238.20      75.000     65.625     70.000                                 \n",
      "10    1179.37      72.727     62.500     67.227                                 \n",
      "11    1135.71      72.222     60.938     66.102                                 \n",
      "12    1283.28      71.429     62.500     66.667                                 \n",
      "13    1220.33      73.214     64.062     68.333                                 \n",
      "14    1154.82      73.214     64.062     68.333                                 \n",
      "15    1094.29      69.388     53.125     60.177                                 \n",
      "16    1136.89      66.667     53.125     59.130                                 \n",
      "17    1030.72      64.706     51.562     57.391                                 \n",
      "18    1068.69      66.000     51.562     57.895                                 \n",
      "19    1050.86      65.385     53.125     58.621                                 \n",
      "20    1082.48      65.385     53.125     58.621                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   65.625    70.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model130.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1576.00      59.459     34.375     43.564                                 \n",
      " 2    1414.30      60.417     45.312     51.786                                 \n",
      " 3    1398.84      69.231     56.250     62.069                                 \n",
      " 4    1483.87      72.222     60.938     66.102                                 \n",
      " 5    1485.96      72.093     48.438     57.944                                 \n",
      " 6    1377.94      72.000     56.250     63.158                                 \n",
      " 7    1322.02      68.000     53.125     59.649                                 \n",
      " 8    1241.86      67.347     51.562     58.407                                 \n",
      " 9    1221.92      70.909     60.938     65.546                                 \n",
      "10    1244.13      71.429     62.500     66.667                                 \n",
      "11    1134.71      71.698     59.375     64.957                                 \n",
      "12    1232.76      68.421     60.938     64.463                                 \n",
      "13    1167.35      67.213     64.062     65.600                                 \n",
      "14    1134.63      68.852     65.625     67.200                                 \n",
      "15    1104.36      70.690     64.062     67.213                                 \n",
      "16    1102.72      68.333     64.062     66.129                                 \n",
      "17    1059.01      68.966     62.500     65.574                                 \n",
      "18    1086.54      68.966     62.500     65.574                                 \n",
      "19    1057.29      69.492     64.062     66.667                                 \n",
      "20    1063.46      69.492     64.062     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.690   64.062    67.213\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.213\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model133.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1609.26      73.077     29.688     42.222                                 \n",
      " 2    1408.47      47.826     34.375     40.000                                 \n",
      " 3    1522.52      62.500     54.688     58.333                                 \n",
      " 4    1498.41      69.091     59.375     63.866                                 \n",
      " 5    1425.16      71.429     54.688     61.947                                 \n",
      " 6    1396.93      66.667     46.875     55.046                                 \n",
      " 7    1355.34      65.385     53.125     58.621                                 \n",
      " 8    1260.26      72.340     53.125     61.261                                 \n",
      " 9    1208.47      69.643     60.938     65.000                                 \n",
      "10    1174.20      70.175     62.500     66.116                                 \n",
      "11    1190.00      68.519     57.812     62.712                                 \n",
      "12    1224.78      69.811     57.812     63.248                                 \n",
      "13    1148.77      66.667     59.375     62.810                                 \n",
      "14    1130.10      68.966     62.500     65.574                                 \n",
      "15    1096.57      69.643     60.938     65.000                                 \n",
      "16    1122.88      70.909     60.938     65.546                                 \n",
      "17    1034.40      70.909     60.938     65.546                                 \n",
      "18    1068.79      70.909     60.938     65.546                                 \n",
      "19    1052.84      64.286     56.250     60.000                                 \n",
      "20    1115.99      68.852     65.625     67.200                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      68.852   65.625    67.200\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.200\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model136.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1557.83      53.333     37.500     44.037                                 \n",
      " 2    1430.95      60.377     50.000     54.701                                 \n",
      " 3    1454.69      76.786     67.188     71.667                                 \n",
      " 4    1431.67      67.241     60.938     63.934                                 \n",
      " 5    1370.65      66.129     64.062     65.079                                 \n",
      " 6    1362.00      66.667     59.375     62.810                                 \n",
      " 7    1337.40      66.102     60.938     63.415                                 \n",
      " 8    1239.78      68.333     64.062     66.129                                 \n",
      " 9    1245.79      69.355     67.188     68.254                                 \n",
      "10    1165.37      68.254     67.188     67.717                                 \n",
      "11    1140.44      69.841     68.750     69.291                                 \n",
      "12    1215.47      70.492     67.188     68.800                                 \n",
      "13    1159.35      70.968     68.750     69.841                                 \n",
      "14    1164.11      72.131     68.750     70.400                                 \n",
      "15    1083.33      71.667     67.188     69.355                                 \n",
      "16    1131.68      71.667     67.188     69.355                                 \n",
      "17    1084.90      70.000     65.625     67.742                                 \n",
      "18    1106.12      70.000     65.625     67.742                                 \n",
      "19    1073.87      70.000     65.625     67.742                                 \n",
      "20    1110.13      70.492     67.188     68.800                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.786   67.188    71.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model139.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1563.29      51.020     39.062     44.248                                 \n",
      " 2    1501.66      58.333     43.750     50.000                                 \n",
      " 3    1542.60      67.188     67.188     67.188                                 \n",
      " 4    1474.47      72.222     60.938     66.102                                 \n",
      " 5    1509.19      75.000     56.250     64.286                                 \n",
      " 6    1413.26      68.000     53.125     59.649                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7    1335.99      68.627     54.688     60.870                                 \n",
      " 8    1413.31      64.706     51.562     57.391                                 \n",
      " 9    1186.98      66.667     56.250     61.017                                 \n",
      "10    1248.32      69.231     56.250     62.069                                 \n",
      "11    1140.08      69.388     53.125     60.177                                 \n",
      "12    1236.78      68.750     51.562     58.929                                 \n",
      "13    1175.07      65.385     53.125     58.621                                 \n",
      "14    1142.11      65.385     53.125     58.621                                 \n",
      "15    1129.54      66.038     54.688     59.829                                 \n",
      "16    1106.93      68.750     51.562     58.929                                 \n",
      "17    1070.87      70.213     51.562     59.459                                 \n",
      "18    1088.39      70.213     51.562     59.459                                 \n",
      "19    1034.52      70.213     51.562     59.459                                 \n",
      "20    1128.90      68.750     51.562     58.929                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      67.188   67.188    67.188\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.188\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model142.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1579.40      68.182     23.438     34.884                                 \n",
      " 2    1530.14      68.293     43.750     53.333                                 \n",
      " 3    1494.22      68.750     51.562     58.929                                 \n",
      " 4    1417.23      68.085     50.000     57.658                                 \n",
      " 5    1416.02      68.085     50.000     57.658                                 \n",
      " 6    1395.83      68.750     51.562     58.929                                 \n",
      " 7    1390.24      68.750     51.562     58.929                                 \n",
      " 8    1266.00      63.462     51.562     56.897                                 \n",
      " 9    1169.26      68.519     57.812     62.712                                 \n",
      "10    1186.41      68.333     64.062     66.129                                 \n",
      "11    1113.15      67.797     62.500     65.041                                 \n",
      "12    1222.24      68.966     62.500     65.574                                 \n",
      "13    1132.96      70.370     59.375     64.407                                 \n",
      "14    1131.24      72.222     60.938     66.102                                 \n",
      "15    1097.42      70.909     60.938     65.546                                 \n",
      "16    1083.47      73.077     59.375     65.517                                 \n",
      "17    1052.27      71.698     59.375     64.957                                 \n",
      "18    1079.89      70.909     60.938     65.546                                 \n",
      "19    1038.73      67.241     60.938     63.934                                 \n",
      "20    1130.47      66.667     59.375     62.810                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      68.333   64.062    66.129\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.129\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model145.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1555.74      42.857     32.812     37.168                                 \n",
      " 2    1342.82      66.667     53.125     59.130                                 \n",
      " 3    1464.44      66.667     50.000     57.143                                 \n",
      " 4    1451.93      76.471     60.938     67.826                                 \n",
      " 5    1428.93      72.000     56.250     63.158                                 \n",
      " 6    1365.28      75.556     53.125     62.385                                 \n",
      " 7    1327.63      72.881     67.188     69.919                                 \n",
      " 8    1315.30      73.016     71.875     72.441                                 \n",
      " 9    1287.23      72.222     60.938     66.102                                 \n",
      "10    1210.44      73.585     60.938     66.667                                 \n",
      "11    1169.15      73.077     59.375     65.517                                 \n",
      "12    1236.54      74.576     68.750     71.545                                 \n",
      "13    1198.33      74.138     67.188     70.492                                 \n",
      "14    1187.34      72.881     67.188     69.919                                 \n",
      "15    1161.06      69.492     64.062     66.667                                 \n",
      "16    1121.94      72.131     68.750     70.400                                 \n",
      "17    1058.12      72.131     68.750     70.400                                 \n",
      "18    1072.01      72.131     68.750     70.400                                 \n",
      "19    1080.56      72.881     67.188     69.919                                 \n",
      "20    1091.55      73.333     68.750     70.968                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.016   71.875    72.441\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.441\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model148.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1585.39      52.500     32.812     40.385                                 \n",
      " 2    1445.38      58.491     48.438     52.991                                 \n",
      " 3    1462.89      67.857     59.375     63.333                                 \n",
      " 4    1428.36      68.519     57.812     62.712                                 \n",
      " 5    1402.81      70.000     65.625     67.742                                 \n",
      " 6    1323.93      72.131     68.750     70.400                                 \n",
      " 7    1309.82      69.355     67.188     68.254                                 \n",
      " 8    1330.60      71.930     64.062     67.769                                 \n",
      " 9    1243.44      71.667     67.188     69.355                                 \n",
      "10    1185.63      70.000     65.625     67.742                                 \n",
      "11    1129.66      68.852     65.625     67.200                                 \n",
      "12    1229.93      70.968     68.750     69.841                                 \n",
      "13    1155.74      70.492     67.188     68.800                                 \n",
      "14    1153.65      71.667     67.188     69.355                                 \n",
      "15    1097.30      70.492     67.188     68.800                                 \n",
      "16    1124.06      74.138     67.188     70.492                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    1015.86      73.684     65.625     69.421                                 \n",
      "18    1056.15      73.684     65.625     69.421                                 \n",
      "19    1042.82      73.684     65.625     69.421                                 \n",
      "20    1068.21      76.364     65.625     70.588                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model151.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1572.19      57.692     23.438     33.333                                 \n",
      " 2    1458.11      52.083     39.062     44.643                                 \n",
      " 3    1516.07      68.182     46.875     55.556                                 \n",
      " 4    1588.45      69.643     60.938     65.000                                 \n",
      " 5    1547.30      67.347     51.562     58.407                                 \n",
      " 6    1375.33      71.698     59.375     64.957                                 \n",
      " 7    1331.48      76.000     59.375     66.667                                 \n",
      " 8    1273.73      72.340     53.125     61.261                                 \n",
      " 9    1237.56      68.750     51.562     58.929                                 \n",
      "10    1211.97      70.213     51.562     59.459                                 \n",
      "11    1149.57      68.750     51.562     58.929                                 \n",
      "12    1211.57      66.667     53.125     59.130                                 \n",
      "13    1202.63      64.706     51.562     57.391                                 \n",
      "14    1140.13      62.963     53.125     57.627                                 \n",
      "15    1120.65      60.714     53.125     56.667                                 \n",
      "16    1107.78      62.963     53.125     57.627                                 \n",
      "17    1064.87      67.273     57.812     62.185                                 \n",
      "18    1107.42      67.857     59.375     63.333                                 \n",
      "19    1037.02      67.857     59.375     63.333                                 \n",
      "20    1084.78      63.793     57.812     60.656                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.000   59.375    66.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model154.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1559.53      57.778     40.625     47.706                                 \n",
      " 2    1413.33      55.319     40.625     46.847                                 \n",
      " 3    1515.26      68.750     51.562     58.929                                 \n",
      " 4    1448.09      67.857     59.375     63.333                                 \n",
      " 5    1414.96      73.913     53.125     61.818                                 \n",
      " 6    1407.29      76.087     54.688     63.636                                 \n",
      " 7    1342.76      77.083     57.812     66.071                                 \n",
      " 8    1295.46      73.469     56.250     63.717                                 \n",
      " 9    1221.95      74.468     54.688     63.063                                 \n",
      "10    1194.35      75.000     56.250     64.286                                 \n",
      "11    1168.20      76.596     56.250     64.865                                 \n",
      "12    1224.75      73.913     53.125     61.818                                 \n",
      "13    1169.96      73.913     53.125     61.818                                 \n",
      "14    1150.07      75.000     56.250     64.286                                 \n",
      "15    1109.22      74.468     54.688     63.063                                 \n",
      "16    1090.61      70.833     53.125     60.714                                 \n",
      "17    1035.76      72.000     56.250     63.158                                 \n",
      "18    1070.79      70.588     56.250     62.609                                 \n",
      "19    1097.64      72.000     56.250     63.158                                 \n",
      "20    1080.24      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.083   57.812    66.071\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.071\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model157.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1560.73      48.980     37.500     42.478                                 \n",
      " 2    1532.22      67.442     45.312     54.206                                 \n",
      " 3    1469.90      70.732     45.312     55.238                                 \n",
      " 4    1425.10      69.048     45.312     54.717                                 \n",
      " 5    1377.80      68.085     50.000     57.658                                 \n",
      " 6    1369.69      73.333     51.562     60.550                                 \n",
      " 7    1400.36      70.213     51.562     59.459                                 \n",
      " 8    1297.10      70.833     53.125     60.714                                 \n",
      " 9    1254.39      68.627     54.688     60.870                                 \n",
      "10    1278.33      71.930     64.062     67.769                                 \n",
      "11    1201.00      73.585     60.938     66.667                                 \n",
      "12    1247.01      74.510     59.375     66.087                                 \n",
      "13    1201.53      75.926     64.062     69.492                                 \n",
      "14    1139.42      71.930     64.062     67.769                                 \n",
      "15    1127.21      68.966     62.500     65.574                                 \n",
      "16    1084.76      68.421     60.938     64.463                                 \n",
      "17    1061.20      71.429     62.500     66.667                                 \n",
      "18    1102.78      71.429     62.500     66.667                                 \n",
      "19    1052.63      69.492     64.062     66.667                                 \n",
      "20    1065.21      71.930     64.062     67.769                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model160.bin\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1576.79      57.143     37.500     45.283                                 \n",
      " 2    1367.72      59.184     45.312     51.327                                 \n",
      " 3    1447.57      66.667     59.375     62.810                                 \n",
      " 4    1401.18      64.286     56.250     60.000                                 \n",
      " 5    1415.15      66.667     50.000     57.143                                 \n",
      " 6    1336.37      71.930     64.062     67.769                                 \n",
      " 7    1349.04      71.154     57.812     63.793                                 \n",
      " 8    1181.99      67.857     59.375     63.333                                 \n",
      " 9    1174.85      70.909     60.938     65.546                                 \n",
      "10    1216.98      72.727     62.500     67.227                                 \n",
      "11    1183.74      70.175     62.500     66.116                                 \n",
      "12    1242.34      75.000     60.938     67.241                                 \n",
      "13    1150.82      76.471     60.938     67.826                                 \n",
      "14    1144.61      75.472     62.500     68.376                                 \n",
      "15    1059.42      75.472     62.500     68.376                                 \n",
      "16    1115.12      75.000     60.938     67.241                                 \n",
      "17    1054.31      73.585     60.938     66.667                                 \n",
      "18    1070.13      73.585     60.938     66.667                                 \n",
      "19    1037.50      73.585     60.938     66.667                                 \n",
      "20    1091.89      72.222     60.938     66.102                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.472   62.500    68.376\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.376\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model163.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1564.56      48.000     37.500     42.105                                 \n",
      " 2    1417.12      50.000     39.062     43.860                                 \n",
      " 3    1374.56      63.462     51.562     56.897                                 \n",
      " 4    1469.43      66.667     56.250     61.017                                 \n",
      " 5    1379.67      62.712     57.812     60.163                                 \n",
      " 6    1400.15      70.000     54.688     61.404                                 \n",
      " 7    1343.24      67.308     54.688     60.345                                 \n",
      " 8    1300.82      68.000     53.125     59.649                                 \n",
      " 9    1266.84      68.085     50.000     57.658                                 \n",
      "10    1203.36      70.213     51.562     59.459                                 \n",
      "11    1149.98      68.750     51.562     58.929                                 \n",
      "12    1213.31      71.111     50.000     58.716                                 \n",
      "13    1187.31      71.111     50.000     58.716                                 \n",
      "14    1144.06      70.455     48.438     57.407                                 \n",
      "15    1090.23      65.957     48.438     55.856                                 \n",
      "16    1104.55      69.565     50.000     58.182                                 \n",
      "17    1061.93      74.510     59.375     66.087                                 \n",
      "18    1046.46      73.077     59.375     65.517                                 \n",
      "19    1033.99      72.222     60.938     66.102                                 \n",
      "20    1102.93      71.429     62.500     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.429   62.500    66.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model166.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1536.93      57.692     46.875     51.724                                 \n",
      " 2    1410.91      56.522     40.625     47.273                                 \n",
      " 3    1433.99      63.934     60.938     62.400                                 \n",
      " 4    1468.00      61.404     54.688     57.851                                 \n",
      " 5    1449.58      61.818     53.125     57.143                                 \n",
      " 6    1442.79      62.000     48.438     54.386                                 \n",
      " 7    1395.36      64.151     53.125     58.120                                 \n",
      " 8    1235.31      62.500     54.688     58.333                                 \n",
      " 9    1256.24      66.038     54.688     59.829                                 \n",
      "10    1201.33      68.627     54.688     60.870                                 \n",
      "11    1151.51      69.811     57.812     63.248                                 \n",
      "12    1253.82      69.841     68.750     69.291                                 \n",
      "13    1270.55      68.852     65.625     67.200                                 \n",
      "14    1153.98      65.517     59.375     62.295                                 \n",
      "15    1086.22      67.797     62.500     65.041                                 \n",
      "16    1081.04      68.966     62.500     65.574                                 \n",
      "17    1053.39      71.429     62.500     66.667                                 \n",
      "18    1084.77      71.429     62.500     66.667                                 \n",
      "19    1106.04      68.966     62.500     65.574                                 \n",
      "20    1065.52      67.797     62.500     65.041                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      69.841   68.750    69.291\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.291\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model169.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1541.18      56.000     43.750     49.123                                 \n",
      " 2    1537.20      54.545     46.875     50.420                                 \n",
      " 3    1478.91      63.158     56.250     59.504                                 \n",
      " 4    1476.83      65.455     56.250     60.504                                 \n",
      " 5    1384.58      72.222     60.938     66.102                                 \n",
      " 6    1328.57      70.213     51.562     59.459                                 \n",
      " 7    1356.66      72.000     56.250     63.158                                 \n",
      " 8    1213.30      68.333     64.062     66.129                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9    1226.29      68.966     62.500     65.574                                 \n",
      "10    1216.42      69.492     64.062     66.667                                 \n",
      "11    1164.83      71.667     67.188     69.355                                 \n",
      "12    1277.11      71.667     67.188     69.355                                 \n",
      "13    1209.09      73.333     68.750     70.968                                 \n",
      "14    1150.05      72.414     65.625     68.852                                 \n",
      "15    1110.54      71.667     67.188     69.355                                 \n",
      "16    1104.07      70.492     67.188     68.800                                 \n",
      "17    1057.22      68.852     65.625     67.200                                 \n",
      "18    1087.16      68.254     67.188     67.717                                 \n",
      "19    1036.89      68.254     67.188     67.717                                 \n",
      "20    1091.13      69.355     67.188     68.254                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.333   68.750    70.968\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.968\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model172.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1545.99      59.459     34.375     43.564                                 \n",
      " 2    1408.59      55.814     37.500     44.860                                 \n",
      " 3    1426.92      63.333     59.375     61.290                                 \n",
      " 4    1408.43      68.889     48.438     56.881                                 \n",
      " 5    1403.25      67.692     68.750     68.217                                 \n",
      " 6    1376.31      72.414     65.625     68.852                                 \n",
      " 7    1331.97      68.421     60.938     64.463                                 \n",
      " 8    1260.04      67.308     54.688     60.345                                 \n",
      " 9    1217.37      69.231     56.250     62.069                                 \n",
      "10    1223.21      70.000     54.688     61.404                                 \n",
      "11    1167.77      69.643     60.938     65.000                                 \n",
      "12    1260.40      72.222     60.938     66.102                                 \n",
      "13    1236.41      70.909     60.938     65.546                                 \n",
      "14    1140.45      72.727     62.500     67.227                                 \n",
      "15    1111.71      71.429     62.500     66.667                                 \n",
      "16    1099.28      71.429     62.500     66.667                                 \n",
      "17    1044.94      71.930     64.062     67.769                                 \n",
      "18    1099.85      74.545     64.062     68.908                                 \n",
      "19    1046.68      78.182     67.188     72.269                                 \n",
      "20    1110.90      76.364     65.625     70.588                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model175.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1589.57      41.176     32.812     36.522                                 \n",
      " 2    1429.01      64.815     54.688     59.322                                 \n",
      " 3    1412.67      66.071     57.812     61.667                                 \n",
      " 4    1410.12      69.643     60.938     65.000                                 \n",
      " 5    1415.49      64.706     51.562     57.391                                 \n",
      " 6    1453.60      68.000     53.125     59.649                                 \n",
      " 7    1325.03      68.966     62.500     65.574                                 \n",
      " 8    1230.22      67.797     62.500     65.041                                 \n",
      " 9    1203.85      73.214     64.062     68.333                                 \n",
      "10    1188.68      71.930     64.062     67.769                                 \n",
      "11    1179.00      76.271     70.312     73.171                                 \n",
      "12    1267.34      73.333     68.750     70.968                                 \n",
      "13    1195.61      74.138     67.188     70.492                                 \n",
      "14    1143.34      73.214     64.062     68.333                                 \n",
      "15    1132.45      72.881     67.188     69.919                                 \n",
      "16    1117.27      74.545     64.062     68.908                                 \n",
      "17    1063.61      71.429     62.500     66.667                                 \n",
      "18    1090.30      72.222     60.938     66.102                                 \n",
      "19    1087.62      74.074     62.500     67.797                                 \n",
      "20    1096.95      75.472     62.500     68.376                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.271   70.312    73.171\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.171\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model178.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1548.43      60.976     39.062     47.619                                 \n",
      " 2    1396.43      63.043     45.312     52.727                                 \n",
      " 3    1488.35      68.085     50.000     57.658                                 \n",
      " 4    1412.67      69.565     50.000     58.182                                 \n",
      " 5    1416.63      65.957     48.438     55.856                                 \n",
      " 6    1373.68      71.111     50.000     58.716                                 \n",
      " 7    1388.35      75.472     62.500     68.376                                 \n",
      " 8    1260.08      69.388     53.125     60.177                                 \n",
      " 9    1297.26      71.429     54.688     61.947                                 \n",
      "10    1221.41      71.429     54.688     61.947                                 \n",
      "11    1112.34      76.364     65.625     70.588                                 \n",
      "12    1259.60      67.857     59.375     63.333                                 \n",
      "13    1150.64      66.071     57.812     61.667                                 \n",
      "14    1120.27      67.308     54.688     60.345                                 \n",
      "15    1143.57      69.231     56.250     62.069                                 \n",
      "16    1108.60      69.091     59.375     63.866                                 \n",
      "17    1037.24      66.667     59.375     62.810                                 \n",
      "18    1059.90      67.857     59.375     63.333                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    1029.31      65.517     59.375     62.295                                 \n",
      "20    1091.05      67.797     62.500     65.041                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model181.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1512.77      66.667     40.625     50.485                                 \n",
      " 2    1377.63      56.522     40.625     47.273                                 \n",
      " 3    1408.40      65.116     43.750     52.336                                 \n",
      " 4    1430.03      64.583     48.438     55.357                                 \n",
      " 5    1361.72      68.000     53.125     59.649                                 \n",
      " 6    1395.98      68.519     57.812     62.712                                 \n",
      " 7    1360.21      68.519     57.812     62.712                                 \n",
      " 8    1218.90      66.667     56.250     61.017                                 \n",
      " 9    1229.28      67.273     57.812     62.185                                 \n",
      "10    1146.20      62.264     51.562     56.410                                 \n",
      "11    1090.57      65.385     53.125     58.621                                 \n",
      "12    1195.17      65.385     53.125     58.621                                 \n",
      "13    1164.26      62.963     53.125     57.627                                 \n",
      "14    1156.23      66.038     54.688     59.829                                 \n",
      "15    1077.18      66.667     53.125     59.130                                 \n",
      "16    1070.13      68.085     50.000     57.658                                 \n",
      "17    1033.71      68.085     50.000     57.658                                 \n",
      "18    1043.44      68.085     50.000     57.658                                 \n",
      "19    1029.31      68.750     51.562     58.929                                 \n",
      "20    1051.78      69.388     53.125     60.177                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      68.519   57.812    62.712\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m62.712\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model184.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1537.58      64.000     25.000     35.955                                 \n",
      " 2    1570.46      50.000     34.375     40.741                                 \n",
      " 3    1394.05      64.912     57.812     61.157                                 \n",
      " 4    1485.07      62.500     46.875     53.571                                 \n",
      " 5    1419.92      66.667     59.375     62.810                                 \n",
      " 6    1314.88      63.462     51.562     56.897                                 \n",
      " 7    1340.84      63.462     51.562     56.897                                 \n",
      " 8    1246.85      63.462     51.562     56.897                                 \n",
      " 9    1297.38      58.491     48.438     52.991                                 \n",
      "10    1217.06      66.667     62.500     64.516                                 \n",
      "11    1158.99      69.492     64.062     66.667                                 \n",
      "12    1186.41      71.930     64.062     67.769                                 \n",
      "13    1161.97      71.930     64.062     67.769                                 \n",
      "14    1133.81      73.684     65.625     69.421                                 \n",
      "15    1149.70      73.684     65.625     69.421                                 \n",
      "16    1100.58      68.966     62.500     65.574                                 \n",
      "17    1063.33      66.667     59.375     62.810                                 \n",
      "18    1061.10      63.793     57.812     60.656                                 \n",
      "19    1045.01      68.333     64.062     66.129                                 \n",
      "20    1085.50      73.684     65.625     69.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model187.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1543.89      55.556     39.062     45.872                                 \n",
      " 2    1498.37      66.667     50.000     57.143                                 \n",
      " 3    1445.61      70.370     59.375     64.407                                 \n",
      " 4    1438.64      69.231     70.312     69.767                                 \n",
      " 5    1410.14      66.038     54.688     59.829                                 \n",
      " 6    1359.24      76.364     65.625     70.588                                 \n",
      " 7    1343.06      74.138     67.188     70.492                                 \n",
      " 8    1212.96      75.000     65.625     70.000                                 \n",
      " 9    1214.09      76.786     67.188     71.667                                 \n",
      "10    1219.04      78.846     64.062     70.690                                 \n",
      "11    1173.05      70.909     60.938     65.546                                 \n",
      "12    1213.55      72.222     60.938     66.102                                 \n",
      "13    1175.78      68.421     60.938     64.463                                 \n",
      "14    1110.75      68.966     62.500     65.574                                 \n",
      "15    1089.24      70.175     62.500     66.116                                 \n",
      "16    1088.89      70.370     59.375     64.407                                 \n",
      "17    1049.12      69.643     60.938     65.000                                 \n",
      "18    1070.38      69.643     60.938     65.000                                 \n",
      "19    1056.69      66.667     62.500     64.516                                 \n",
      "20    1103.37      68.421     60.938     64.463                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.786   67.188    71.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model190.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    1508.05      64.516     31.250     42.105                                 \n",
      " 2    1399.78      63.636     54.688     58.824                                 \n",
      " 3    1447.90      62.069     56.250     59.016                                 \n",
      " 4    1409.38      62.903     60.938     61.905                                 \n",
      " 5    1412.41      69.492     64.062     66.667                                 \n",
      " 6    1388.97      66.667     68.750     67.692                                 \n",
      " 7    1319.59      62.500     54.688     58.333                                 \n",
      " 8    1280.30      60.714     53.125     56.667                                 \n",
      " 9    1215.82      60.714     53.125     56.667                                 \n",
      "10    1188.50      60.714     53.125     56.667                                 \n",
      "11    1171.68      67.742     65.625     66.667                                 \n",
      "12    1224.73      70.690     64.062     67.213                                 \n",
      "13    1199.54      70.690     64.062     67.213                                 \n",
      "14    1139.21      69.492     64.062     66.667                                 \n",
      "15    1097.42      69.492     64.062     66.667                                 \n",
      "16    1065.37      72.727     62.500     67.227                                 \n",
      "17    1061.83      71.429     62.500     66.667                                 \n",
      "18    1081.51      69.492     64.062     66.667                                 \n",
      "19    1059.79      71.186     65.625     68.293                                 \n",
      "20    1084.20      72.414     65.625     68.852                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.414   65.625    68.852\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.852\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model193.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1526.32      58.333     43.750     50.000                                 \n",
      " 2    1390.50      56.818     39.062     46.296                                 \n",
      " 3    1440.06      64.286     56.250     60.000                                 \n",
      " 4    1402.78      62.903     60.938     61.905                                 \n",
      " 5    1382.93      73.214     64.062     68.333                                 \n",
      " 6    1365.24      72.881     67.188     69.919                                 \n",
      " 7    1347.58      73.333     68.750     70.968                                 \n",
      " 8    1203.81      70.968     68.750     69.841                                 \n",
      " 9    1243.86      72.881     67.188     69.919                                 \n",
      "10    1229.27      74.138     67.188     70.492                                 \n",
      "11    1202.41      74.138     67.188     70.492                                 \n",
      "12    1249.87      74.576     68.750     71.545                                 \n",
      "13    1174.04      72.881     67.188     69.919                                 \n",
      "14    1138.70      72.881     67.188     69.919                                 \n",
      "15    1111.29      74.138     67.188     70.492                                 \n",
      "16    1063.44      75.000     65.625     70.000                                 \n",
      "17    1051.99      75.000     65.625     70.000                                 \n",
      "18    1073.05      74.074     62.500     67.797                                 \n",
      "19    1032.28      76.923     62.500     68.966                                 \n",
      "20    1081.49      76.923     62.500     68.966                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model196.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1515.76      72.973     42.188     53.465                                 \n",
      " 2    1424.43      54.167     40.625     46.429                                 \n",
      " 3    1459.06      66.667     62.500     64.516                                 \n",
      " 4    1529.34      65.306     50.000     56.637                                 \n",
      " 5    1422.36      72.000     56.250     63.158                                 \n",
      " 6    1377.58      70.213     51.562     59.459                                 \n",
      " 7    1337.31      68.750     51.562     58.929                                 \n",
      " 8    1251.43      70.833     53.125     60.714                                 \n",
      " 9    1229.13      67.308     54.688     60.345                                 \n",
      "10    1192.31      66.000     51.562     57.895                                 \n",
      "11    1162.71      66.667     53.125     59.130                                 \n",
      "12    1226.28      70.175     62.500     66.116                                 \n",
      "13    1201.98      66.667     62.500     64.516                                 \n",
      "14    1143.81      67.241     60.938     63.934                                 \n",
      "15    1148.11      67.797     62.500     65.041                                 \n",
      "16    1133.63      68.421     60.938     64.463                                 \n",
      "17    1075.25      72.222     60.938     66.102                                 \n",
      "18    1063.17      72.222     60.938     66.102                                 \n",
      "19    1048.83      74.074     62.500     67.797                                 \n",
      "20    1104.72      74.074     62.500     67.797                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.074   62.500    67.797\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.797\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model199.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1533.41      45.238     29.688     35.849                                 \n",
      " 2    1426.40      58.696     42.188     49.091                                 \n",
      " 3    1474.62      60.000     46.875     52.632                                 \n",
      " 4    1489.01      64.583     48.438     55.357                                 \n",
      " 5    1507.60      68.519     57.812     62.712                                 \n",
      " 6    1310.45      74.000     57.812     64.912                                 \n",
      " 7    1350.66      74.468     54.688     63.063                                 \n",
      " 8    1237.33      74.510     59.375     66.087                                 \n",
      " 9    1168.20      73.585     60.938     66.667                                 \n",
      "10    1237.18      74.545     64.062     68.908                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    1158.58      71.698     59.375     64.957                                 \n",
      "12    1256.12      73.077     59.375     65.517                                 \n",
      "13    1179.84      72.000     56.250     63.158                                 \n",
      "14    1109.52      71.429     54.688     61.947                                 \n",
      "15    1107.24      74.074     62.500     67.797                                 \n",
      "16    1129.53      73.077     59.375     65.517                                 \n",
      "17    1025.24      71.154     57.812     63.793                                 \n",
      "18    1097.39      70.588     56.250     62.609                                 \n",
      "19    1053.17      73.077     59.375     65.517                                 \n",
      "20    1118.76      71.698     59.375     64.957                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   64.062    68.908\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.908\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model202.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1541.94      68.182     23.438     34.884                                 \n",
      " 2    1380.82      57.692     46.875     51.724                                 \n",
      " 3    1427.77      70.909     60.938     65.546                                 \n",
      " 4    1507.66      63.462     51.562     56.897                                 \n",
      " 5    1472.41      69.388     53.125     60.177                                 \n",
      " 6    1413.53      75.472     62.500     68.376                                 \n",
      " 7    1356.76      76.364     65.625     70.588                                 \n",
      " 8    1234.86      75.472     62.500     68.376                                 \n",
      " 9    1241.53      67.308     54.688     60.345                                 \n",
      "10    1192.95      66.102     60.938     63.415                                 \n",
      "11    1158.40      64.407     59.375     61.789                                 \n",
      "12    1239.24      68.519     57.812     62.712                                 \n",
      "13    1182.66      64.912     57.812     61.157                                 \n",
      "14    1161.27      64.912     57.812     61.157                                 \n",
      "15    1091.26      66.667     59.375     62.810                                 \n",
      "16    1098.54      67.857     59.375     63.333                                 \n",
      "17    1027.21      69.811     57.812     63.248                                 \n",
      "18    1091.74      64.912     57.812     61.157                                 \n",
      "19    1025.60      66.667     59.375     62.810                                 \n",
      "20    1065.26      69.811     57.812     63.248                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model205.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1545.34      50.000     25.000     33.333                                 \n",
      " 2    1410.81      58.491     48.438     52.991                                 \n",
      " 3    1443.45      70.175     62.500     66.116                                 \n",
      " 4    1482.46      70.909     60.938     65.546                                 \n",
      " 5    1514.29      74.576     68.750     71.545                                 \n",
      " 6    1382.43      75.000     70.312     72.581                                 \n",
      " 7    1388.65      74.138     67.188     70.492                                 \n",
      " 8    1262.94      75.862     68.750     72.131                                 \n",
      " 9    1232.23      78.182     67.188     72.269                                 \n",
      "10    1213.19      74.545     64.062     68.908                                 \n",
      "11    1138.57      72.414     65.625     68.852                                 \n",
      "12    1232.53      70.690     64.062     67.213                                 \n",
      "13    1205.58      70.690     64.062     67.213                                 \n",
      "14    1132.34      72.414     65.625     68.852                                 \n",
      "15    1134.21      72.414     65.625     68.852                                 \n",
      "16    1092.14      71.186     65.625     68.293                                 \n",
      "17    1045.80      70.000     65.625     67.742                                 \n",
      "18    1075.98      68.852     65.625     67.200                                 \n",
      "19    1062.05      70.000     65.625     67.742                                 \n",
      "20    1051.29      68.852     65.625     67.200                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   70.312    72.581\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.581\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model208.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1522.07      64.865     37.500     47.525                                 \n",
      " 2    1431.85      61.818     53.125     57.143                                 \n",
      " 3    1497.00      62.903     60.938     61.905                                 \n",
      " 4    1358.72      68.421     60.938     64.463                                 \n",
      " 5    1412.51      66.071     57.812     61.667                                 \n",
      " 6    1335.04      68.421     60.938     64.463                                 \n",
      " 7    1317.14      72.414     65.625     68.852                                 \n",
      " 8    1272.91      75.862     68.750     72.131                                 \n",
      " 9    1255.28      74.138     67.188     70.492                                 \n",
      "10    1162.08      71.667     67.188     69.355                                 \n",
      "11    1196.66      72.581     70.312     71.429                                 \n",
      "12    1234.33      71.429     70.312     70.866                                 \n",
      "13    1201.57      72.131     68.750     70.400                                 \n",
      "14    1142.99      73.684     65.625     69.421                                 \n",
      "15    1123.82      72.414     65.625     68.852                                 \n",
      "16    1140.76      70.000     65.625     67.742                                 \n",
      "17    1039.94      71.930     64.062     67.769                                 \n",
      "18    1081.32      71.186     65.625     68.293                                 \n",
      "19    1014.29      73.214     64.062     68.333                                 \n",
      "20    1096.08      71.930     64.062     67.769                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.862   68.750    72.131\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.131\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model211.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1577.06      47.222     26.562     34.000                                 \n",
      " 2    1402.29      71.154     57.812     63.793                                 \n",
      " 3    1436.70      69.091     59.375     63.866                                 \n",
      " 4    1574.95      68.750     51.562     58.929                                 \n",
      " 5    1455.37      67.308     54.688     60.345                                 \n",
      " 6    1369.23      66.038     54.688     59.829                                 \n",
      " 7    1319.05      59.322     54.688     56.911                                 \n",
      " 8    1243.72      63.636     65.625     64.615                                 \n",
      " 9    1230.96      68.966     62.500     65.574                                 \n",
      "10    1234.11      72.222     60.938     66.102                                 \n",
      "11    1155.98      71.930     64.062     67.769                                 \n",
      "12    1226.45      72.414     65.625     68.852                                 \n",
      "13    1201.38      70.370     59.375     64.407                                 \n",
      "14    1133.34      69.811     57.812     63.248                                 \n",
      "15    1148.72      67.308     54.688     60.345                                 \n",
      "16    1122.90      69.388     53.125     60.177                                 \n",
      "17    1063.52      70.000     54.688     61.404                                 \n",
      "18    1091.77      66.667     56.250     61.017                                 \n",
      "19    1043.16      67.925     56.250     61.538                                 \n",
      "20    1083.07      69.091     59.375     63.866                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.414   65.625    68.852\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.852\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model214.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1533.79      65.625     32.812     43.750                                 \n",
      " 2    1415.91      65.306     50.000     56.637                                 \n",
      " 3    1453.58      60.784     48.438     53.913                                 \n",
      " 4    1415.36      65.306     50.000     56.637                                 \n",
      " 5    1430.98      62.264     51.562     56.410                                 \n",
      " 6    1368.19      72.917     54.688     62.500                                 \n",
      " 7    1367.88      67.925     56.250     61.538                                 \n",
      " 8    1233.48      61.818     53.125     57.143                                 \n",
      " 9    1193.00      60.000     51.562     55.462                                 \n",
      "10    1166.33      60.000     51.562     55.462                                 \n",
      "11    1118.88      61.818     53.125     57.143                                 \n",
      "12    1199.66      67.925     56.250     61.538                                 \n",
      "13    1168.78      69.231     56.250     62.069                                 \n",
      "14    1138.82      66.667     56.250     61.017                                 \n",
      "15    1115.23      66.667     56.250     61.017                                 \n",
      "16    1088.57      67.925     56.250     61.538                                 \n",
      "17    1020.88      68.000     53.125     59.649                                 \n",
      "18    1064.75      70.000     54.688     61.404                                 \n",
      "19    1058.04      67.308     54.688     60.345                                 \n",
      "20    1045.67      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.917   54.688    62.500\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m62.500\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model217.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1588.40      50.000     34.375     40.741                                 \n",
      " 2    1381.86      64.444     45.312     53.211                                 \n",
      " 3    1377.05      72.549     57.812     64.348                                 \n",
      " 4    1447.86      79.592     60.938     69.027                                 \n",
      " 5    1434.80      77.193     68.750     72.727                                 \n",
      " 6    1396.29      76.667     71.875     74.194                                 \n",
      " 7    1305.60      76.667     71.875     74.194                                 \n",
      " 8    1262.80      71.429     70.312     70.866                                 \n",
      " 9    1177.84      69.231     70.312     69.767                                 \n",
      "10    1187.94      71.186     65.625     68.293                                 \n",
      "11    1123.51      71.930     64.062     67.769                                 \n",
      "12    1221.49      70.690     64.062     67.213                                 \n",
      "13    1162.42      73.214     64.062     68.333                                 \n",
      "14    1143.42      73.585     60.938     66.667                                 \n",
      "15    1102.69      69.643     60.938     65.000                                 \n",
      "16    1078.37      70.909     60.938     65.546                                 \n",
      "17    1052.39      72.222     60.938     66.102                                 \n",
      "18    1064.30      74.545     64.062     68.908                                 \n",
      "19    1045.06      74.545     64.062     68.908                                 \n",
      "20    1089.94      73.214     64.062     68.333                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.667   71.875    74.194\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.194\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model220.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1530.26      53.333     25.000     34.043                                 \n",
      " 2    1372.82      59.091     40.625     48.148                                 \n",
      " 3    1376.35      57.143     43.750     49.558                                 \n",
      " 4    1501.74      68.889     48.438     56.881                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5    1369.22      73.585     60.938     66.667                                 \n",
      " 6    1395.24      71.429     54.688     61.947                                 \n",
      " 7    1343.63      66.667     53.125     59.130                                 \n",
      " 8    1254.10      63.158     56.250     59.504                                 \n",
      " 9    1255.24      64.815     54.688     59.322                                 \n",
      "10    1169.19      74.576     68.750     71.545                                 \n",
      "11    1158.29      72.414     65.625     68.852                                 \n",
      "12    1220.35      72.414     65.625     68.852                                 \n",
      "13    1174.16      74.138     67.188     70.492                                 \n",
      "14    1121.06      74.545     64.062     68.908                                 \n",
      "15    1088.34      71.186     65.625     68.293                                 \n",
      "16    1129.11      70.690     64.062     67.213                                 \n",
      "17    1070.65      72.727     62.500     67.227                                 \n",
      "18    1077.19      73.214     64.062     68.333                                 \n",
      "19    1052.67      73.214     64.062     68.333                                 \n",
      "20    1081.74      74.576     68.750     71.545                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model223.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1529.38      50.000     21.875     30.435                                 \n",
      " 2    1492.33      64.000     50.000     56.140                                 \n",
      " 3    1462.03      71.698     59.375     64.957                                 \n",
      " 4    1484.38      67.857     59.375     63.333                                 \n",
      " 5    1430.92      65.455     56.250     60.504                                 \n",
      " 6    1351.13      73.913     53.125     61.818                                 \n",
      " 7    1323.99      70.000     65.625     67.742                                 \n",
      " 8    1255.33      68.333     64.062     66.129                                 \n",
      " 9    1271.21      65.625     65.625     65.625                                 \n",
      "10    1241.70      65.152     67.188     66.154                                 \n",
      "11    1165.39      67.188     67.188     67.188                                 \n",
      "12    1226.14      68.254     67.188     67.717                                 \n",
      "13    1219.84      69.841     68.750     69.291                                 \n",
      "14    1112.71      72.581     70.312     71.429                                 \n",
      "15    1115.34      70.312     70.312     70.312                                 \n",
      "16    1116.59      71.875     71.875     71.875                                 \n",
      "17    1050.01      70.492     67.188     68.800                                 \n",
      "18    1106.29      71.875     71.875     71.875                                 \n",
      "19    1060.65      69.841     68.750     69.291                                 \n",
      "20    1098.54      68.254     67.188     67.717                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.875   71.875    71.875\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.875\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model226.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1565.36      58.333     32.812     42.000                                 \n",
      " 2    1462.66      57.692     46.875     51.724                                 \n",
      " 3    1432.67      71.429     54.688     61.947                                 \n",
      " 4    1560.44      66.071     57.812     61.667                                 \n",
      " 5    1391.35      76.471     60.938     67.826                                 \n",
      " 6    1398.17      78.261     56.250     65.455                                 \n",
      " 7    1405.21      66.667     53.125     59.130                                 \n",
      " 8    1279.04      67.308     54.688     60.345                                 \n",
      " 9    1228.93      70.690     64.062     67.213                                 \n",
      "10    1163.97      69.492     64.062     66.667                                 \n",
      "11    1118.93      68.421     60.938     64.463                                 \n",
      "12    1198.76      72.727     62.500     67.227                                 \n",
      "13    1167.45      67.797     62.500     65.041                                 \n",
      "14    1135.26      64.583     48.438     55.357                                 \n",
      "15    1078.39      68.750     51.562     58.929                                 \n",
      "16    1075.75      70.213     51.562     59.459                                 \n",
      "17    1047.33      70.833     53.125     60.714                                 \n",
      "18    1059.35      69.388     53.125     60.177                                 \n",
      "19    1053.45      72.340     53.125     61.261                                 \n",
      "20    1090.22      70.833     53.125     60.714                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.471   60.938    67.826\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.826\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model229.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1582.23      60.714     26.562     36.957                                 \n",
      " 2    1491.97      58.824     46.875     52.174                                 \n",
      " 3    1445.07      64.583     48.438     55.357                                 \n",
      " 4    1370.66      64.286     56.250     60.000                                 \n",
      " 5    1379.46      70.690     64.062     67.213                                 \n",
      " 6    1322.32      70.909     60.938     65.546                                 \n",
      " 7    1339.00      67.213     64.062     65.600                                 \n",
      " 8    1267.17      71.186     65.625     68.293                                 \n",
      " 9    1176.07      71.186     65.625     68.293                                 \n",
      "10    1188.91      69.492     64.062     66.667                                 \n",
      "11    1109.66      75.472     62.500     68.376                                 \n",
      "12    1228.06      76.471     60.938     67.826                                 \n",
      "13    1153.96      72.222     60.938     66.102                                 \n",
      "14    1177.20      70.909     60.938     65.546                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    1134.67      70.909     60.938     65.546                                 \n",
      "16    1104.98      69.091     59.375     63.866                                 \n",
      "17    1036.33      67.273     57.812     62.185                                 \n",
      "18    1072.51      67.857     59.375     63.333                                 \n",
      "19    1039.27      71.698     59.375     64.957                                 \n",
      "20    1074.77      71.698     59.375     64.957                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.472   62.500    68.376\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.376\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model232.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1539.27      52.273     35.938     42.593                                 \n",
      " 2    1433.36      62.500     54.688     58.333                                 \n",
      " 3    1399.92      63.265     48.438     54.867                                 \n",
      " 4    1434.45      64.000     50.000     56.140                                 \n",
      " 5    1451.77      77.083     57.812     66.071                                 \n",
      " 6    1418.35      71.667     67.188     69.355                                 \n",
      " 7    1376.29      69.492     64.062     66.667                                 \n",
      " 8    1264.11      71.186     65.625     68.293                                 \n",
      " 9    1236.19      72.727     62.500     67.227                                 \n",
      "10    1244.57      71.429     62.500     66.667                                 \n",
      "11    1141.35      71.186     65.625     68.293                                 \n",
      "12    1222.22      70.690     64.062     67.213                                 \n",
      "13    1181.51      70.909     60.938     65.546                                 \n",
      "14    1118.67      67.925     56.250     61.538                                 \n",
      "15    1091.06      68.519     57.812     62.712                                 \n",
      "16    1068.61      68.519     57.812     62.712                                 \n",
      "17    1037.87      69.091     59.375     63.866                                 \n",
      "18    1097.08      69.091     59.375     63.866                                 \n",
      "19    1029.20      67.857     59.375     63.333                                 \n",
      "20    1108.46      66.071     57.812     61.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.667   67.188    69.355\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.355\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model235.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1550.00      69.697     35.938     47.423                                 \n",
      " 2    1425.35      50.000     35.938     41.818                                 \n",
      " 3    1403.65      69.643     60.938     65.000                                 \n",
      " 4    1406.79      72.414     65.625     68.852                                 \n",
      " 5    1336.41      66.667     59.375     62.810                                 \n",
      " 6    1428.64      65.455     56.250     60.504                                 \n",
      " 7    1344.54      68.519     57.812     62.712                                 \n",
      " 8    1292.38      65.455     56.250     60.504                                 \n",
      " 9    1240.79      67.347     51.562     58.407                                 \n",
      "10    1259.06      67.347     51.562     58.407                                 \n",
      "11    1170.36      68.085     50.000     57.658                                 \n",
      "12    1259.59      70.213     51.562     59.459                                 \n",
      "13    1185.92      74.545     64.062     68.908                                 \n",
      "14    1154.34      73.684     65.625     69.421                                 \n",
      "15    1125.01      75.926     64.062     69.492                                 \n",
      "16    1090.65      73.214     64.062     68.333                                 \n",
      "17    1050.18      72.727     62.500     67.227                                 \n",
      "18    1128.09      72.727     62.500     67.227                                 \n",
      "19    1046.75      72.727     62.500     67.227                                 \n",
      "20    1088.49      72.727     62.500     67.227                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model238.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1575.28      47.368     28.125     35.294                                 \n",
      " 2    1473.45      68.000     53.125     59.649                                 \n",
      " 3    1414.79      73.214     64.062     68.333                                 \n",
      " 4    1463.85      72.727     62.500     67.227                                 \n",
      " 5    1384.56      76.364     65.625     70.588                                 \n",
      " 6    1343.33      82.692     67.188     74.138                                 \n",
      " 7    1333.10      80.000     68.750     73.950                                 \n",
      " 8    1285.83      77.966     71.875     74.797                                 \n",
      " 9    1231.73      74.545     64.062     68.908                                 \n",
      "10    1147.56      68.333     64.062     66.129                                 \n",
      "11    1133.60      71.667     67.188     69.355                                 \n",
      "12    1186.93      71.186     65.625     68.293                                 \n",
      "13    1163.38      68.852     65.625     67.200                                 \n",
      "14    1152.35      72.414     65.625     68.852                                 \n",
      "15    1096.20      69.492     64.062     66.667                                 \n",
      "16    1076.68      69.492     64.062     66.667                                 \n",
      "17    1034.84      71.429     62.500     66.667                                 \n",
      "18    1071.06      73.214     64.062     68.333                                 \n",
      "19    1066.33      73.214     64.062     68.333                                 \n",
      "20    1082.98      72.727     62.500     67.227                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.966   71.875    74.797\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.797\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model241.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1519.45      51.429     28.125     36.364                                 \n",
      " 2    1436.86      50.909     43.750     47.059                                 \n",
      " 3    1510.82      67.797     62.500     65.041                                 \n",
      " 4    1392.90      64.912     57.812     61.157                                 \n",
      " 5    1426.40      62.264     51.562     56.410                                 \n",
      " 6    1431.06      66.667     65.625     66.142                                 \n",
      " 7    1377.47      66.667     65.625     66.142                                 \n",
      " 8    1238.80      67.188     67.188     67.188                                 \n",
      " 9    1215.15      66.667     65.625     66.142                                 \n",
      "10    1177.60      71.667     67.188     69.355                                 \n",
      "11    1205.26      67.797     62.500     65.041                                 \n",
      "12    1227.46      66.667     62.500     64.516                                 \n",
      "13    1226.39      65.625     65.625     65.625                                 \n",
      "14    1154.78      65.079     64.062     64.567                                 \n",
      "15    1092.15      65.079     64.062     64.567                                 \n",
      "16    1104.24      65.079     64.062     64.567                                 \n",
      "17    1085.41      64.516     62.500     63.492                                 \n",
      "18    1083.98      66.667     65.625     66.142                                 \n",
      "19    1056.23      68.852     65.625     67.200                                 \n",
      "20    1097.29      68.333     64.062     66.129                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.667   67.188    69.355\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.355\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model244.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1498.04      59.375     29.688     39.583                                 \n",
      " 2    1478.81      62.500     46.875     53.571                                 \n",
      " 3    1395.34      74.138     67.188     70.492                                 \n",
      " 4    1407.11      72.727     62.500     67.227                                 \n",
      " 5    1370.48      70.909     60.938     65.546                                 \n",
      " 6    1356.16      70.968     68.750     69.841                                 \n",
      " 7    1377.67      71.429     70.312     70.866                                 \n",
      " 8    1198.11      67.692     68.750     68.217                                 \n",
      " 9    1216.56      70.968     68.750     69.841                                 \n",
      "10    1192.46      71.667     67.188     69.355                                 \n",
      "11    1132.36      74.138     67.188     70.492                                 \n",
      "12    1217.13      71.186     65.625     68.293                                 \n",
      "13    1177.90      71.186     65.625     68.293                                 \n",
      "14    1124.33      74.138     67.188     70.492                                 \n",
      "15    1099.64      71.186     65.625     68.293                                 \n",
      "16    1113.97      71.429     62.500     66.667                                 \n",
      "17    1057.53      72.222     60.938     66.102                                 \n",
      "18    1117.49      68.750     51.562     58.929                                 \n",
      "19    1038.71      69.231     56.250     62.069                                 \n",
      "20    1059.21      68.000     53.125     59.649                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.429   70.312    70.866\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.866\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model247.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1506.47      55.000     34.375     42.308                                 \n",
      " 2    1426.66      58.182     50.000     53.782                                 \n",
      " 3    1421.73      71.186     65.625     68.293                                 \n",
      " 4    1351.47      74.000     57.812     64.912                                 \n",
      " 5    1371.10      70.833     53.125     60.714                                 \n",
      " 6    1335.38      64.706     51.562     57.391                                 \n",
      " 7    1344.87      69.231     56.250     62.069                                 \n",
      " 8    1258.18      69.231     56.250     62.069                                 \n",
      " 9    1184.52      67.925     56.250     61.538                                 \n",
      "10    1195.58      69.231     56.250     62.069                                 \n",
      "11    1140.47      67.347     51.562     58.407                                 \n",
      "12    1249.33      71.429     62.500     66.667                                 \n",
      "13    1167.43      67.241     60.938     63.934                                 \n",
      "14    1110.82      66.667     59.375     62.810                                 \n",
      "15    1155.87      65.574     62.500     64.000                                 \n",
      "16    1073.66      65.574     62.500     64.000                                 \n",
      "17    1045.35      65.574     62.500     64.000                                 \n",
      "18    1045.45      65.574     62.500     64.000                                 \n",
      "19    1053.24      65.574     62.500     64.000                                 \n",
      "20    1108.13      66.129     64.062     65.079                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.186   65.625    68.293\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.293\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model250.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1513.34      48.649     28.125     35.644                                 \n",
      " 2    1382.58      69.091     59.375     63.866                                 \n",
      " 3    1396.88      68.254     67.188     67.717                                 \n",
      " 4    1421.64      72.549     57.812     64.348                                 \n",
      " 5    1485.29      75.000     56.250     64.286                                 \n",
      " 6    1307.74      77.551     59.375     67.257                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7    1328.60      76.471     60.938     67.826                                 \n",
      " 8    1220.65      76.596     56.250     64.865                                 \n",
      " 9    1235.62      72.340     53.125     61.261                                 \n",
      "10    1262.71      72.340     53.125     61.261                                 \n",
      "11    1204.17      72.000     56.250     63.158                                 \n",
      "12    1251.53      72.000     56.250     63.158                                 \n",
      "13    1155.18      72.917     54.688     62.500                                 \n",
      "14    1109.41      72.917     54.688     62.500                                 \n",
      "15    1119.35      74.468     54.688     63.063                                 \n",
      "16    1106.50      73.469     56.250     63.717                                 \n",
      "17    1030.60      74.468     54.688     63.063                                 \n",
      "18    1053.18      72.917     54.688     62.500                                 \n",
      "19    1041.28      72.917     54.688     62.500                                 \n",
      "20    1084.84      77.193     68.750     72.727                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.193   68.750    72.727\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.727\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model253.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1522.77      52.778     29.688     38.000                                 \n",
      " 2    1373.12      66.000     51.562     57.895                                 \n",
      " 3    1473.11      74.000     57.812     64.912                                 \n",
      " 4    1490.38      62.500     54.688     58.333                                 \n",
      " 5    1411.31      70.909     60.938     65.546                                 \n",
      " 6    1346.13      67.797     62.500     65.041                                 \n",
      " 7    1380.09      69.643     60.938     65.000                                 \n",
      " 8    1297.70      74.510     59.375     66.087                                 \n",
      " 9    1259.99      69.091     59.375     63.866                                 \n",
      "10    1194.49      73.585     60.938     66.667                                 \n",
      "11    1176.69      67.857     59.375     63.333                                 \n",
      "12    1218.81      65.455     56.250     60.504                                 \n",
      "13    1145.76      66.667     59.375     62.810                                 \n",
      "14    1091.83      67.857     59.375     63.333                                 \n",
      "15    1077.37      67.857     59.375     63.333                                 \n",
      "16    1111.40      70.370     59.375     64.407                                 \n",
      "17    1031.42      70.175     62.500     66.116                                 \n",
      "18    1065.02      71.429     62.500     66.667                                 \n",
      "19    1029.46      71.429     62.500     66.667                                 \n",
      "20    1073.80      75.472     62.500     68.376                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.472   62.500    68.376\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.376\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model256.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1545.08      58.621     26.562     36.559                                 \n",
      " 2    1419.43      62.745     50.000     55.652                                 \n",
      " 3    1450.36      73.214     64.062     68.333                                 \n",
      " 4    1400.91      70.690     64.062     67.213                                 \n",
      " 5    1412.40      70.588     56.250     62.609                                 \n",
      " 6    1341.37      74.000     57.812     64.912                                 \n",
      " 7    1343.98      70.833     53.125     60.714                                 \n",
      " 8    1292.65      71.111     50.000     58.716                                 \n",
      " 9    1179.34      69.565     50.000     58.182                                 \n",
      "10    1247.50      70.213     51.562     59.459                                 \n",
      "11    1175.39      70.833     53.125     60.714                                 \n",
      "12    1229.61      75.472     62.500     68.376                                 \n",
      "13    1182.13      74.545     64.062     68.908                                 \n",
      "14    1167.71      72.222     60.938     66.102                                 \n",
      "15    1113.38      70.370     59.375     64.407                                 \n",
      "16    1094.86      74.074     62.500     67.797                                 \n",
      "17    1076.16      69.091     59.375     63.866                                 \n",
      "18    1109.22      62.500     46.875     53.571                                 \n",
      "19    1060.25      63.830     46.875     54.054                                 \n",
      "20    1087.38      63.830     46.875     54.054                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   64.062    68.908\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.908\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model259.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1510.22      51.020     39.062     44.248                                 \n",
      " 2    1465.72      65.455     56.250     60.504                                 \n",
      " 3    1406.43      68.852     65.625     67.200                                 \n",
      " 4    1442.49      66.667     65.625     66.142                                 \n",
      " 5    1410.52      66.102     60.938     63.415                                 \n",
      " 6    1351.54      75.000     70.312     72.581                                 \n",
      " 7    1325.67      72.881     67.188     69.919                                 \n",
      " 8    1230.14      75.439     67.188     71.074                                 \n",
      " 9    1191.95      77.193     68.750     72.727                                 \n",
      "10    1192.40      75.926     64.062     69.492                                 \n",
      "11    1118.51      74.074     62.500     67.797                                 \n",
      "12    1249.89      72.727     62.500     67.227                                 \n",
      "13    1195.92      73.214     64.062     68.333                                 \n",
      "14    1157.11      73.214     64.062     68.333                                 \n",
      "15    1109.26      73.684     65.625     69.421                                 \n",
      "16    1110.28      73.684     65.625     69.421                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    1073.30      73.585     60.938     66.667                                 \n",
      "18    1067.49      73.585     60.938     66.667                                 \n",
      "19    1059.54      75.000     60.938     67.241                                 \n",
      "20    1117.32      73.585     60.938     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.193   68.750    72.727\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.727\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model262.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1500.73      55.814     37.500     44.860                                 \n",
      " 2    1384.92      57.377     54.688     56.000                                 \n",
      " 3    1424.03      65.574     62.500     64.000                                 \n",
      " 4    1392.78      68.421     60.938     64.463                                 \n",
      " 5    1356.75      72.222     60.938     66.102                                 \n",
      " 6    1305.97      61.111     51.562     55.932                                 \n",
      " 7    1355.10      66.000     51.562     57.895                                 \n",
      " 8    1176.60      69.388     53.125     60.177                                 \n",
      " 9    1193.79      70.833     53.125     60.714                                 \n",
      "10    1184.07      68.750     51.562     58.929                                 \n",
      "11    1108.00      70.588     56.250     62.609                                 \n",
      "12    1178.22      68.627     54.688     60.870                                 \n",
      "13    1119.67      70.000     54.688     61.404                                 \n",
      "14    1122.26      70.000     54.688     61.404                                 \n",
      "15    1104.53      69.231     56.250     62.069                                 \n",
      "16    1107.66      69.231     56.250     62.069                                 \n",
      "17    1049.20      68.000     53.125     59.649                                 \n",
      "18    1076.57      70.000     54.688     61.404                                 \n",
      "19    1052.87      70.000     54.688     61.404                                 \n",
      "20    1107.75      70.000     54.688     61.404                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.222   60.938    66.102\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.102\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model265.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1531.88      68.750     34.375     45.833                                 \n",
      " 2    1455.28      58.000     45.312     50.877                                 \n",
      " 3    1453.16      66.667     56.250     61.017                                 \n",
      " 4    1365.60      68.750     51.562     58.929                                 \n",
      " 5    1352.72      68.519     57.812     62.712                                 \n",
      " 6    1373.20      71.930     64.062     67.769                                 \n",
      " 7    1332.78      75.000     65.625     70.000                                 \n",
      " 8    1228.07      74.576     68.750     71.545                                 \n",
      " 9    1188.04      78.846     64.062     70.690                                 \n",
      "10    1230.43      77.358     64.062     70.085                                 \n",
      "11    1159.47      77.358     64.062     70.085                                 \n",
      "12    1242.90      77.778     65.625     71.186                                 \n",
      "13    1162.09      77.778     65.625     71.186                                 \n",
      "14    1151.17      75.926     64.062     69.492                                 \n",
      "15    1105.87      75.926     64.062     69.492                                 \n",
      "16    1085.36      74.545     64.062     68.908                                 \n",
      "17    1060.54      74.545     64.062     68.908                                 \n",
      "18    1091.96      75.000     65.625     70.000                                 \n",
      "19    1054.22      77.778     65.625     71.186                                 \n",
      "20    1098.06      72.414     65.625     68.852                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model268.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1491.04      68.421     40.625     50.980                                 \n",
      " 2    1476.62      61.702     45.312     52.252                                 \n",
      " 3    1470.66      71.186     65.625     68.293                                 \n",
      " 4    1382.68      78.000     60.938     68.421                                 \n",
      " 5    1392.85      73.214     64.062     68.333                                 \n",
      " 6    1359.68      79.630     67.188     72.881                                 \n",
      " 7    1349.14      75.862     68.750     72.131                                 \n",
      " 8    1211.33      74.576     68.750     71.545                                 \n",
      " 9    1199.24      75.862     68.750     72.131                                 \n",
      "10    1204.47      78.182     67.188     72.269                                 \n",
      "11    1168.89      81.132     67.188     73.504                                 \n",
      "12    1246.88      76.364     65.625     70.588                                 \n",
      "13    1179.84      76.364     65.625     70.588                                 \n",
      "14    1136.82      73.214     64.062     68.333                                 \n",
      "15    1121.14      74.545     64.062     68.908                                 \n",
      "16    1116.84      74.545     64.062     68.908                                 \n",
      "17    1049.11      69.643     60.938     65.000                                 \n",
      "18    1091.57      70.175     62.500     66.116                                 \n",
      "19    1058.25      70.175     62.500     66.116                                 \n",
      "20    1086.94      70.690     64.062     67.213                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.132   67.188    73.504\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.504\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model271.bin\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1495.66      75.862     34.375     47.312                                 \n",
      " 2    1510.79      66.667     56.250     61.017                                 \n",
      " 3    1552.58      69.643     60.938     65.000                                 \n",
      " 4    1410.60      66.667     53.125     59.130                                 \n",
      " 5    1405.83      65.217     46.875     54.545                                 \n",
      " 6    1357.83      64.583     48.438     55.357                                 \n",
      " 7    1320.01      64.000     50.000     56.140                                 \n",
      " 8    1221.06      63.462     51.562     56.897                                 \n",
      " 9    1216.96      62.000     48.438     54.386                                 \n",
      "10    1174.03      69.643     60.938     65.000                                 \n",
      "11    1169.29      69.091     59.375     63.866                                 \n",
      "12    1198.84      69.643     60.938     65.000                                 \n",
      "13    1186.63      69.643     60.938     65.000                                 \n",
      "14    1117.78      70.909     60.938     65.546                                 \n",
      "15    1095.49      68.421     60.938     64.463                                 \n",
      "16    1107.00      69.091     59.375     63.866                                 \n",
      "17    1065.80      69.643     60.938     65.000                                 \n",
      "18    1074.60      69.643     60.938     65.000                                 \n",
      "19    1035.09      69.643     60.938     65.000                                 \n",
      "20    1088.97      69.091     59.375     63.866                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.909   60.938    65.546\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m65.546\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model274.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1499.32      51.163     34.375     41.121                                 \n",
      " 2    1483.42      56.364     48.438     52.101                                 \n",
      " 3    1436.59      71.698     59.375     64.957                                 \n",
      " 4    1440.19      73.214     64.062     68.333                                 \n",
      " 5    1453.36      67.797     62.500     65.041                                 \n",
      " 6    1408.82      75.472     62.500     68.376                                 \n",
      " 7    1351.88      75.926     64.062     69.492                                 \n",
      " 8    1253.50      79.245     65.625     71.795                                 \n",
      " 9    1275.43      78.182     67.188     72.269                                 \n",
      "10    1182.08      78.182     67.188     72.269                                 \n",
      "11    1229.12      81.132     67.188     73.504                                 \n",
      "12    1235.56      75.926     64.062     69.492                                 \n",
      "13    1175.50      74.545     64.062     68.908                                 \n",
      "14    1130.61      73.684     65.625     69.421                                 \n",
      "15    1086.58      72.414     65.625     68.852                                 \n",
      "16    1063.59      73.684     65.625     69.421                                 \n",
      "17    1061.89      74.545     64.062     68.908                                 \n",
      "18    1065.36      76.364     65.625     70.588                                 \n",
      "19    1038.52      76.364     65.625     70.588                                 \n",
      "20    1061.26      76.364     65.625     70.588                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.132   67.188    73.504\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.504\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model277.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1517.53      65.789     39.062     49.020                                 \n",
      " 2    1498.79      60.345     54.688     57.377                                 \n",
      " 3    1453.72      66.667     59.375     62.810                                 \n",
      " 4    1496.23      72.881     67.188     69.919                                 \n",
      " 5    1355.86      67.857     59.375     63.333                                 \n",
      " 6    1298.34      70.370     59.375     64.407                                 \n",
      " 7    1310.18      71.186     65.625     68.293                                 \n",
      " 8    1206.81      67.797     62.500     65.041                                 \n",
      " 9    1229.33      65.574     62.500     64.000                                 \n",
      "10    1164.32      67.742     65.625     66.667                                 \n",
      "11    1122.47      67.797     62.500     65.041                                 \n",
      "12    1216.89      69.643     60.938     65.000                                 \n",
      "13    1144.25      69.643     60.938     65.000                                 \n",
      "14    1098.58      68.421     60.938     64.463                                 \n",
      "15    1114.42      71.186     65.625     68.293                                 \n",
      "16    1105.01      71.930     64.062     67.769                                 \n",
      "17    1045.77      72.414     65.625     68.852                                 \n",
      "18    1087.90      72.414     65.625     68.852                                 \n",
      "19    1039.22      72.881     67.188     69.919                                 \n",
      "20    1095.14      73.333     68.750     70.968                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.333   68.750    70.968\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.968\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model280.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.53      62.500     39.062     48.077                                 \n",
      " 2    1421.24      63.462     51.562     56.897                                 \n",
      " 3    1517.19      62.295     59.375     60.800                                 \n",
      " 4    1416.82      67.241     60.938     63.934                                 \n",
      " 5    1390.25      75.472     62.500     68.376                                 \n",
      " 6    1326.83      70.909     60.938     65.546                                 \n",
      " 7    1335.56      70.370     59.375     64.407                                 \n",
      " 8    1200.81      71.186     65.625     68.293                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9    1217.85      71.186     65.625     68.293                                 \n",
      "10    1185.69      70.690     64.062     67.213                                 \n",
      "11    1114.42      68.333     64.062     66.129                                 \n",
      "12    1234.75      70.690     64.062     67.213                                 \n",
      "13    1175.35      73.684     65.625     69.421                                 \n",
      "14    1138.86      73.214     64.062     68.333                                 \n",
      "15    1078.85      73.684     65.625     69.421                                 \n",
      "16    1084.59      71.429     62.500     66.667                                 \n",
      "17    1007.19      71.429     62.500     66.667                                 \n",
      "18    1059.53      71.930     64.062     67.769                                 \n",
      "19    1024.42      73.684     65.625     69.421                                 \n",
      "20    1090.38      71.930     64.062     67.769                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model283.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1497.69      76.471     40.625     53.061                                 \n",
      " 2    1521.50      64.706     51.562     57.391                                 \n",
      " 3    1445.39      66.667     56.250     61.017                                 \n",
      " 4    1434.39      69.231     56.250     62.069                                 \n",
      " 5    1376.25      75.000     60.938     67.241                                 \n",
      " 6    1302.29      71.930     64.062     67.769                                 \n",
      " 7    1388.69      72.727     62.500     67.227                                 \n",
      " 8    1238.57      70.175     62.500     66.116                                 \n",
      " 9    1195.02      62.264     51.562     56.410                                 \n",
      "10    1173.68      64.815     54.688     59.322                                 \n",
      "11    1223.67      65.385     53.125     58.621                                 \n",
      "12    1205.76      66.667     53.125     59.130                                 \n",
      "13    1154.43      68.852     65.625     67.200                                 \n",
      "14    1104.64      69.355     67.188     68.254                                 \n",
      "15    1086.63      70.492     67.188     68.800                                 \n",
      "16    1089.14      66.071     57.812     61.667                                 \n",
      "17    1037.46      65.079     64.062     64.567                                 \n",
      "18    1064.96      66.154     67.188     66.667                                 \n",
      "19    1045.51      66.154     67.188     66.667                                 \n",
      "20    1088.80      67.188     67.188     67.188                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.492   67.188    68.800\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.800\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model286.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1508.46      73.913     26.562     39.080                                 \n",
      " 2    1490.36      56.364     48.438     52.101                                 \n",
      " 3    1472.65      66.667     62.500     64.516                                 \n",
      " 4    1434.35      71.698     59.375     64.957                                 \n",
      " 5    1366.89      70.909     60.938     65.546                                 \n",
      " 6    1349.77      73.214     64.062     68.333                                 \n",
      " 7    1385.40      72.727     62.500     67.227                                 \n",
      " 8    1228.37      67.241     60.938     63.934                                 \n",
      " 9    1208.41      71.429     62.500     66.667                                 \n",
      "10    1217.24      72.222     60.938     66.102                                 \n",
      "11    1166.13      73.585     60.938     66.667                                 \n",
      "12    1263.82      75.926     64.062     69.492                                 \n",
      "13    1171.87      79.245     65.625     71.795                                 \n",
      "14    1126.80      77.778     65.625     71.186                                 \n",
      "15    1103.60      80.000     68.750     73.950                                 \n",
      "16    1108.07      79.630     67.188     72.881                                 \n",
      "17    1031.29      82.353     65.625     73.043                                 \n",
      "18    1060.26      79.245     65.625     71.795                                 \n",
      "19    1040.32      77.778     65.625     71.186                                 \n",
      "20    1094.39      71.698     59.375     64.957                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      80.000   68.750    73.950\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.950\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model289.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1507.43      73.333     34.375     46.809                                 \n",
      " 2    1372.51      53.704     45.312     49.153                                 \n",
      " 3    1492.78      67.213     64.062     65.600                                 \n",
      " 4    1448.30      66.154     67.188     66.667                                 \n",
      " 5    1475.50      65.079     64.062     64.567                                 \n",
      " 6    1438.47      71.667     67.188     69.355                                 \n",
      " 7    1347.24      62.121     64.062     63.077                                 \n",
      " 8    1280.71      65.574     62.500     64.000                                 \n",
      " 9    1268.75      65.517     59.375     62.295                                 \n",
      "10    1246.65      63.793     57.812     60.656                                 \n",
      "11    1142.04      67.273     57.812     62.185                                 \n",
      "12    1198.70      67.241     60.938     63.934                                 \n",
      "13    1156.95      67.797     62.500     65.041                                 \n",
      "14    1194.09      70.175     62.500     66.116                                 \n",
      "15    1087.68      69.643     60.938     65.000                                 \n",
      "16    1096.67      67.241     60.938     63.934                                 \n",
      "17    1009.75      70.175     62.500     66.116                                 \n",
      "18    1078.97      72.222     60.938     66.102                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    1053.35      72.222     60.938     66.102                                 \n",
      "20    1068.43      71.154     57.812     63.793                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.667   67.188    69.355\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.355\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model292.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1506.33      76.667     35.938     48.936                                 \n",
      " 2    1413.90      53.571     46.875     50.000                                 \n",
      " 3    1424.97      68.966     62.500     65.574                                 \n",
      " 4    1422.02      68.519     57.812     62.712                                 \n",
      " 5    1426.04      70.370     59.375     64.407                                 \n",
      " 6    1350.15      71.930     64.062     67.769                                 \n",
      " 7    1380.76      70.492     67.188     68.800                                 \n",
      " 8    1269.63      68.254     67.188     67.717                                 \n",
      " 9    1227.85      68.750     68.750     68.750                                 \n",
      "10    1243.26      68.182     70.312     69.231                                 \n",
      "11    1210.98      71.429     70.312     70.866                                 \n",
      "12    1267.07      70.968     68.750     69.841                                 \n",
      "13    1174.93      69.841     68.750     69.291                                 \n",
      "14    1161.33      68.852     65.625     67.200                                 \n",
      "15    1170.71      70.000     65.625     67.742                                 \n",
      "16    1086.53      70.690     64.062     67.213                                 \n",
      "17    1029.07      69.492     64.062     66.667                                 \n",
      "18    1115.09      68.966     62.500     65.574                                 \n",
      "19    1049.54      70.909     60.938     65.546                                 \n",
      "20    1105.00      74.074     62.500     67.797                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.429   70.312    70.866\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.866\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model295.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1523.41      65.517     29.688     40.860                                 \n",
      " 2    1468.56      58.824     46.875     52.174                                 \n",
      " 3    1469.97      65.306     50.000     56.637                                 \n",
      " 4    1435.29      66.667     53.125     59.130                                 \n",
      " 5    1517.71      66.667     53.125     59.130                                 \n",
      " 6    1426.38      78.182     67.188     72.269                                 \n",
      " 7    1363.57      74.545     64.062     68.908                                 \n",
      " 8    1204.75      72.131     68.750     70.400                                 \n",
      " 9    1215.02      70.000     65.625     67.742                                 \n",
      "10    1153.08      72.000     56.250     63.158                                 \n",
      "11    1153.13      75.000     65.625     70.000                                 \n",
      "12    1206.34      75.000     65.625     70.000                                 \n",
      "13    1186.23      74.074     62.500     67.797                                 \n",
      "14    1124.83      73.585     60.938     66.667                                 \n",
      "15    1125.46      72.727     62.500     67.227                                 \n",
      "16    1111.84      74.545     64.062     68.908                                 \n",
      "17    1060.41      75.000     65.625     70.000                                 \n",
      "18    1056.05      75.439     67.188     71.074                                 \n",
      "19    1054.58      75.439     67.188     71.074                                 \n",
      "20    1097.81      77.778     65.625     71.186                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model298.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1487.51      66.667     37.500     48.000                                 \n",
      " 2    1433.38      57.895     51.562     54.545                                 \n",
      " 3    1406.38      66.667     62.500     64.516                                 \n",
      " 4    1390.68      70.690     64.062     67.213                                 \n",
      " 5    1387.24      80.000     68.750     73.950                                 \n",
      " 6    1345.31      80.000     68.750     73.950                                 \n",
      " 7    1358.42      75.862     68.750     72.131                                 \n",
      " 8    1277.19      77.193     68.750     72.727                                 \n",
      " 9    1251.72      72.881     67.188     69.919                                 \n",
      "10    1175.26      75.439     67.188     71.074                                 \n",
      "11    1151.42      78.182     67.188     72.269                                 \n",
      "12    1183.31      75.439     67.188     71.074                                 \n",
      "13    1187.71      75.439     67.188     71.074                                 \n",
      "14    1122.01      77.193     68.750     72.727                                 \n",
      "15    1114.62      78.571     68.750     73.333                                 \n",
      "16    1093.52      78.571     68.750     73.333                                 \n",
      "17    1084.97      77.193     68.750     72.727                                 \n",
      "18    1091.87      75.862     68.750     72.131                                 \n",
      "19    1052.42      76.786     67.188     71.667                                 \n",
      "20    1099.33      74.545     64.062     68.908                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      80.000   68.750    73.950\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.950\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model301.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    1516.87      69.231     28.125     40.000                                 \n",
      " 2    1442.83      61.111     51.562     55.932                                 \n",
      " 3    1413.95      71.930     64.062     67.769                                 \n",
      " 4    1403.35      75.000     70.312     72.581                                 \n",
      " 5    1385.03      75.862     68.750     72.131                                 \n",
      " 6    1296.83      74.576     68.750     71.545                                 \n",
      " 7    1358.15      75.862     68.750     72.131                                 \n",
      " 8    1220.61      70.968     68.750     69.841                                 \n",
      " 9    1190.69      73.333     68.750     70.968                                 \n",
      "10    1229.27      73.684     65.625     69.421                                 \n",
      "11    1157.94      78.846     64.062     70.690                                 \n",
      "12    1220.14      74.545     64.062     68.908                                 \n",
      "13    1139.34      73.214     64.062     68.333                                 \n",
      "14    1142.35      74.545     64.062     68.908                                 \n",
      "15    1113.72      75.472     62.500     68.376                                 \n",
      "16    1107.25      77.358     64.062     70.085                                 \n",
      "17    1031.51      75.926     64.062     69.492                                 \n",
      "18    1072.75      76.364     65.625     70.588                                 \n",
      "19    1040.09      73.214     64.062     68.333                                 \n",
      "20    1070.04      72.727     62.500     67.227                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   70.312    72.581\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.581\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model304.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1527.20      64.706     34.375     44.898                                 \n",
      " 2    1514.31      52.381     51.562     51.969                                 \n",
      " 3    1487.56      67.797     62.500     65.041                                 \n",
      " 4    1420.83      70.175     62.500     66.116                                 \n",
      " 5    1392.88      71.186     65.625     68.293                                 \n",
      " 6    1343.58      77.193     68.750     72.727                                 \n",
      " 7    1345.95      76.271     70.312     73.171                                 \n",
      " 8    1223.03      79.310     71.875     75.410                                 \n",
      " 9    1255.10      75.439     67.188     71.074                                 \n",
      "10    1219.86      76.786     67.188     71.667                                 \n",
      "11    1165.85      76.786     67.188     71.667                                 \n",
      "12    1215.02      77.778     65.625     71.186                                 \n",
      "13    1185.63      76.786     67.188     71.667                                 \n",
      "14    1128.99      75.000     65.625     70.000                                 \n",
      "15    1108.05      70.690     64.062     67.213                                 \n",
      "16    1113.84      74.138     67.188     70.492                                 \n",
      "17    1042.53      73.684     65.625     69.421                                 \n",
      "18    1074.24      73.684     65.625     69.421                                 \n",
      "19    1035.15      74.576     68.750     71.545                                 \n",
      "20    1101.89      71.186     65.625     68.293                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.310   71.875    75.410\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.410\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model307.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1532.69      57.778     40.625     47.706                                 \n",
      " 2    1428.41      50.000     45.312     47.541                                 \n",
      " 3    1397.34      67.742     65.625     66.667                                 \n",
      " 4    1485.19      73.214     64.062     68.333                                 \n",
      " 5    1398.73      71.186     65.625     68.293                                 \n",
      " 6    1406.88      76.364     65.625     70.588                                 \n",
      " 7    1364.16      74.138     67.188     70.492                                 \n",
      " 8    1273.97      76.786     67.188     71.667                                 \n",
      " 9    1292.65      77.778     65.625     71.186                                 \n",
      "10    1152.79      76.364     65.625     70.588                                 \n",
      "11    1214.28      75.926     64.062     69.492                                 \n",
      "12    1231.85      76.364     65.625     70.588                                 \n",
      "13    1204.51      75.000     65.625     70.000                                 \n",
      "14    1148.07      76.364     65.625     70.588                                 \n",
      "15    1116.12      75.000     65.625     70.000                                 \n",
      "16    1090.83      76.364     65.625     70.588                                 \n",
      "17    1017.32      76.364     65.625     70.588                                 \n",
      "18    1086.86      75.926     64.062     69.492                                 \n",
      "19    1052.76      76.364     65.625     70.588                                 \n",
      "20    1071.85      76.364     65.625     70.588                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.786   67.188    71.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model310.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1491.33      61.111     34.375     44.000                                 \n",
      " 2    1436.73      54.902     43.750     48.696                                 \n",
      " 3    1381.06      72.414     65.625     68.852                                 \n",
      " 4    1390.55      67.857     59.375     63.333                                 \n",
      " 5    1427.65      74.000     57.812     64.912                                 \n",
      " 6    1394.26      77.778     65.625     71.186                                 \n",
      " 7    1282.94      75.000     65.625     70.000                                 \n",
      " 8    1239.02      74.576     68.750     71.545                                 \n",
      " 9    1213.89      74.138     67.188     70.492                                 \n",
      "10    1175.14      71.186     65.625     68.293                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    1110.71      70.492     67.188     68.800                                 \n",
      "12    1193.98      72.881     67.188     69.919                                 \n",
      "13    1163.38      66.667     65.625     66.142                                 \n",
      "14    1124.38      65.152     67.188     66.154                                 \n",
      "15    1103.28      67.742     65.625     66.667                                 \n",
      "16    1076.95      71.186     65.625     68.293                                 \n",
      "17    1064.07      72.414     65.625     68.852                                 \n",
      "18    1070.69      72.414     65.625     68.852                                 \n",
      "19    1037.43      67.213     64.062     65.600                                 \n",
      "20    1103.58      67.213     64.062     65.600                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model313.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1490.61      71.429     31.250     43.478                                 \n",
      " 2    1368.51      55.357     48.438     51.667                                 \n",
      " 3    1493.72      68.519     57.812     62.712                                 \n",
      " 4    1428.48      74.510     59.375     66.087                                 \n",
      " 5    1446.60      78.182     67.188     72.269                                 \n",
      " 6    1342.90      75.862     68.750     72.131                                 \n",
      " 7    1333.64      74.576     68.750     71.545                                 \n",
      " 8    1300.36      76.271     70.312     73.171                                 \n",
      " 9    1207.78      75.000     70.312     72.581                                 \n",
      "10    1211.80      76.786     67.188     71.667                                 \n",
      "11    1213.85      77.358     64.062     70.085                                 \n",
      "12    1287.86      74.074     62.500     67.797                                 \n",
      "13    1191.99      76.364     65.625     70.588                                 \n",
      "14    1146.05      75.926     64.062     69.492                                 \n",
      "15    1093.81      73.214     64.062     68.333                                 \n",
      "16    1193.72      75.472     62.500     68.376                                 \n",
      "17    1033.71      75.472     62.500     68.376                                 \n",
      "18    1065.17      80.769     65.625     72.414                                 \n",
      "19    1023.63      79.245     65.625     71.795                                 \n",
      "20    1092.27      75.926     64.062     69.492                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.271   70.312    73.171\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.171\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model316.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1525.01      64.286     28.125     39.130                                 \n",
      " 2    1441.47      56.604     46.875     51.282                                 \n",
      " 3    1416.09      69.231     56.250     62.069                                 \n",
      " 4    1420.55      71.667     67.188     69.355                                 \n",
      " 5    1399.00      71.667     67.188     69.355                                 \n",
      " 6    1378.22      70.588     56.250     62.609                                 \n",
      " 7    1340.76      65.455     56.250     60.504                                 \n",
      " 8    1230.35      70.588     56.250     62.609                                 \n",
      " 9    1205.18      73.333     68.750     70.968                                 \n",
      "10    1203.80      73.333     68.750     70.968                                 \n",
      "11    1177.70      73.333     68.750     70.968                                 \n",
      "12    1252.92      72.881     67.188     69.919                                 \n",
      "13    1183.71      72.881     67.188     69.919                                 \n",
      "14    1118.17      73.214     64.062     68.333                                 \n",
      "15    1089.51      73.214     64.062     68.333                                 \n",
      "16    1112.39      70.909     60.938     65.546                                 \n",
      "17    1046.05      71.429     62.500     66.667                                 \n",
      "18    1061.96      69.643     60.938     65.000                                 \n",
      "19    1030.58      70.690     64.062     67.213                                 \n",
      "20    1077.70      69.492     64.062     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.333   68.750    70.968\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.968\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model319.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1497.22      71.429     23.438     35.294                                 \n",
      " 2    1420.67      55.556     39.062     45.872                                 \n",
      " 3    1446.14      68.966     62.500     65.574                                 \n",
      " 4    1378.82      67.241     60.938     63.934                                 \n",
      " 5    1469.40      76.786     67.188     71.667                                 \n",
      " 6    1393.67      75.862     68.750     72.131                                 \n",
      " 7    1398.09      77.193     68.750     72.727                                 \n",
      " 8    1279.05      76.271     70.312     73.171                                 \n",
      " 9    1278.44      70.690     64.062     67.213                                 \n",
      "10    1267.46      70.175     62.500     66.116                                 \n",
      "11    1214.03      73.214     64.062     68.333                                 \n",
      "12    1276.89      74.138     67.188     70.492                                 \n",
      "13    1159.33      75.000     65.625     70.000                                 \n",
      "14    1112.74      75.926     64.062     69.492                                 \n",
      "15    1102.18      74.074     62.500     67.797                                 \n",
      "16    1147.70      72.727     62.500     67.227                                 \n",
      "17    1084.70      72.727     62.500     67.227                                 \n",
      "18    1071.70      72.727     62.500     67.227                                 \n",
      "19    1067.85      73.214     64.062     68.333                                 \n",
      "20    1111.30      73.684     65.625     69.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.271   70.312    73.171\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.171\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model322.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1515.87      53.659     34.375     41.905                                 \n",
      " 2    1491.23      50.000     43.750     46.667                                 \n",
      " 3    1444.48      58.182     50.000     53.782                                 \n",
      " 4    1493.63      63.793     57.812     60.656                                 \n",
      " 5    1441.77      65.000     60.938     62.903                                 \n",
      " 6    1337.14      62.903     60.938     61.905                                 \n",
      " 7    1281.15      66.667     65.625     66.142                                 \n",
      " 8    1260.49      67.742     65.625     66.667                                 \n",
      " 9    1269.83      67.742     65.625     66.667                                 \n",
      "10    1165.16      67.213     64.062     65.600                                 \n",
      "11    1112.84      66.667     62.500     64.516                                 \n",
      "12    1270.68      67.213     64.062     65.600                                 \n",
      "13    1184.69      68.333     64.062     66.129                                 \n",
      "14    1168.95      68.333     64.062     66.129                                 \n",
      "15    1137.69      68.254     67.188     67.717                                 \n",
      "16    1127.41      70.690     64.062     67.213                                 \n",
      "17    1052.17      67.797     62.500     65.041                                 \n",
      "18    1117.67      67.797     62.500     65.041                                 \n",
      "19    1031.94      67.797     62.500     65.041                                 \n",
      "20    1082.53      67.797     62.500     65.041                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      68.254   67.188    67.717\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.717\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model325.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1504.03      53.659     34.375     41.905                                 \n",
      " 2    1409.05      56.863     45.312     50.435                                 \n",
      " 3    1399.38      62.500     46.875     53.571                                 \n",
      " 4    1376.80      69.231     56.250     62.069                                 \n",
      " 5    1342.14      78.182     67.188     72.269                                 \n",
      " 6    1323.05      75.439     67.188     71.074                                 \n",
      " 7    1319.94      66.667     53.125     59.130                                 \n",
      " 8    1221.33      70.000     54.688     61.404                                 \n",
      " 9    1197.58      68.000     53.125     59.649                                 \n",
      "10    1177.89      69.388     53.125     60.177                                 \n",
      "11    1108.58      76.786     67.188     71.667                                 \n",
      "12    1198.08      74.138     67.188     70.492                                 \n",
      "13    1167.87      72.131     68.750     70.400                                 \n",
      "14    1141.26      72.131     68.750     70.400                                 \n",
      "15    1098.50      72.131     68.750     70.400                                 \n",
      "16    1088.40      74.576     68.750     71.545                                 \n",
      "17    1043.09      75.862     68.750     72.131                                 \n",
      "18    1055.90      75.862     68.750     72.131                                 \n",
      "19    1036.34      75.439     67.188     71.074                                 \n",
      "20    1128.24      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1491.40      69.444     39.062     50.000                                 \n",
      " 2    1538.71      54.000     42.188     47.368                                 \n",
      " 3    1510.63      57.377     54.688     56.000                                 \n",
      " 4    1474.80      63.793     57.812     60.656                                 \n",
      " 5    1444.72      74.000     57.812     64.912                                 \n",
      " 6    1459.54      75.556     53.125     62.385                                 \n",
      " 7    1401.52      73.077     59.375     65.517                                 \n",
      " 8    1252.44      70.000     54.688     61.404                                 \n",
      " 9    1226.72      68.421     60.938     64.463                                 \n",
      "10    1207.80      75.000     60.938     67.241                                 \n",
      "11    1212.30      76.471     60.938     67.826                                 \n",
      "12    1277.22      74.000     57.812     64.912                                 \n",
      "13    1212.97      72.222     60.938     66.102                                 \n",
      "14    1176.95      75.000     65.625     70.000                                 \n",
      "15    1104.33      75.000     65.625     70.000                                 \n",
      "16    1226.78      75.472     62.500     68.376                                 \n",
      "17    1093.30      70.909     60.938     65.546                                 \n",
      "18    1085.89      70.175     62.500     66.116                                 \n",
      "19    1064.22      70.175     62.500     66.116                                 \n",
      "20    1087.84      71.429     62.500     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   65.625    70.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model331.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1490.35      65.789     39.062     49.020                                 \n",
      " 2    1395.18      60.870     43.750     50.909                                 \n",
      " 3    1421.04      73.214     64.062     68.333                                 \n",
      " 4    1427.42      73.585     60.938     66.667                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5    1382.70      71.667     67.188     69.355                                 \n",
      " 6    1334.54      73.684     65.625     69.421                                 \n",
      " 7    1310.78      74.138     67.188     70.492                                 \n",
      " 8    1225.78      72.881     67.188     69.919                                 \n",
      " 9    1178.12      74.074     62.500     67.797                                 \n",
      "10    1150.85      75.472     62.500     68.376                                 \n",
      "11    1130.27      75.926     64.062     69.492                                 \n",
      "12    1221.05      77.778     65.625     71.186                                 \n",
      "13    1173.35      77.778     65.625     71.186                                 \n",
      "14    1117.11      76.364     65.625     70.588                                 \n",
      "15    1087.97      76.364     65.625     70.588                                 \n",
      "16    1102.23      75.000     65.625     70.000                                 \n",
      "17    1041.93      72.881     67.188     69.919                                 \n",
      "18    1079.17      72.881     67.188     69.919                                 \n",
      "19    1024.51      72.881     67.188     69.919                                 \n",
      "20    1070.08      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.778   65.625    71.186\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.186\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model334.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1483.42      67.647     35.938     46.939                                 \n",
      " 2    1437.08      51.613     50.000     50.794                                 \n",
      " 3    1444.43      75.472     62.500     68.376                                 \n",
      " 4    1379.16      70.370     59.375     64.407                                 \n",
      " 5    1422.62      80.000     62.500     70.175                                 \n",
      " 6    1320.15      79.630     67.188     72.881                                 \n",
      " 7    1373.90      79.310     71.875     75.410                                 \n",
      " 8    1283.61      75.862     68.750     72.131                                 \n",
      " 9    1215.63      79.630     67.188     72.881                                 \n",
      "10    1176.07      76.364     65.625     70.588                                 \n",
      "11    1140.37      78.182     67.188     72.269                                 \n",
      "12    1217.24      78.571     68.750     73.333                                 \n",
      "13    1203.73      78.182     67.188     72.269                                 \n",
      "14    1205.44      79.630     67.188     72.881                                 \n",
      "15    1122.55      81.132     67.188     73.504                                 \n",
      "16    1127.57      81.132     67.188     73.504                                 \n",
      "17    1093.40      82.692     67.188     74.138                                 \n",
      "18    1059.69      81.481     68.750     74.576                                 \n",
      "19    1052.47      78.182     67.188     72.269                                 \n",
      "20    1074.00      75.000     70.312     72.581                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.310   71.875    75.410\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.410\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model337.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1477.15      60.714     26.562     36.957                                 \n",
      " 2    1473.12      67.925     56.250     61.538                                 \n",
      " 3    1452.64      72.222     60.938     66.102                                 \n",
      " 4    1420.44      67.797     62.500     65.041                                 \n",
      " 5    1543.70      67.213     64.062     65.600                                 \n",
      " 6    1332.96      68.519     57.812     62.712                                 \n",
      " 7    1316.47      71.429     62.500     66.667                                 \n",
      " 8    1264.89      69.492     64.062     66.667                                 \n",
      " 9    1229.54      66.667     65.625     66.142                                 \n",
      "10    1180.15      65.625     65.625     65.625                                 \n",
      "11    1138.45      64.615     65.625     65.116                                 \n",
      "12    1237.58      65.152     67.188     66.154                                 \n",
      "13    1150.96      67.213     64.062     65.600                                 \n",
      "14    1136.33      68.333     64.062     66.129                                 \n",
      "15    1103.48      67.213     64.062     65.600                                 \n",
      "16    1072.58      66.102     60.938     63.415                                 \n",
      "17    1027.61      65.517     59.375     62.295                                 \n",
      "18    1098.72      69.643     60.938     65.000                                 \n",
      "19    1055.53      69.643     60.938     65.000                                 \n",
      "20    1121.09      70.175     62.500     66.116                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      69.492   64.062    66.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model340.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1506.37      56.410     34.375     42.718                                 \n",
      " 2    1442.06      52.459     50.000     51.200                                 \n",
      " 3    1408.79      70.370     59.375     64.407                                 \n",
      " 4    1378.64      70.690     64.062     67.213                                 \n",
      " 5    1349.86      67.213     64.062     65.600                                 \n",
      " 6    1348.24      70.000     65.625     67.742                                 \n",
      " 7    1321.57      70.690     64.062     67.213                                 \n",
      " 8    1185.18      70.690     64.062     67.213                                 \n",
      " 9    1197.26      68.966     62.500     65.574                                 \n",
      "10    1214.56      70.175     62.500     66.116                                 \n",
      "11    1175.05      73.684     65.625     69.421                                 \n",
      "12    1260.73      70.690     64.062     67.213                                 \n",
      "13    1185.12      73.684     65.625     69.421                                 \n",
      "14    1116.87      71.930     64.062     67.769                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    1081.60      71.930     64.062     67.769                                 \n",
      "16    1082.05      71.930     64.062     67.769                                 \n",
      "17    1057.24      71.930     64.062     67.769                                 \n",
      "18    1055.70      73.684     65.625     69.421                                 \n",
      "19    1034.63      77.358     64.062     70.085                                 \n",
      "20    1095.07      77.358     64.062     70.085                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   64.062    70.085\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.085\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model343.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1485.80      80.952     26.562     40.000                                 \n",
      " 2    1390.16      60.377     50.000     54.701                                 \n",
      " 3    1437.21      69.091     59.375     63.866                                 \n",
      " 4    1434.79      78.431     62.500     69.565                                 \n",
      " 5    1474.70      71.429     62.500     66.667                                 \n",
      " 6    1306.02      76.364     65.625     70.588                                 \n",
      " 7    1373.94      76.786     67.188     71.667                                 \n",
      " 8    1264.69      82.353     65.625     73.043                                 \n",
      " 9    1238.51      75.472     62.500     68.376                                 \n",
      "10    1220.45      75.472     62.500     68.376                                 \n",
      "11    1121.00      72.222     60.938     66.102                                 \n",
      "12    1191.37      72.222     60.938     66.102                                 \n",
      "13    1200.29      73.585     60.938     66.667                                 \n",
      "14    1133.67      73.585     60.938     66.667                                 \n",
      "15    1110.36      75.472     62.500     68.376                                 \n",
      "16    1076.23      76.471     60.938     67.826                                 \n",
      "17    1040.55      76.471     60.938     67.826                                 \n",
      "18    1070.13      75.000     60.938     67.241                                 \n",
      "19    1055.77      75.000     60.938     67.241                                 \n",
      "20    1090.11      74.510     59.375     66.087                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      82.353   65.625    73.043\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.043\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model346.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1522.31      65.789     39.062     49.020                                 \n",
      " 2    1385.58      56.250     56.250     56.250                                 \n",
      " 3    1425.39      62.500     54.688     58.333                                 \n",
      " 4    1450.77      70.492     67.188     68.800                                 \n",
      " 5    1402.89      74.576     68.750     71.545                                 \n",
      " 6    1319.46      68.333     64.062     66.129                                 \n",
      " 7    1327.65      67.188     67.188     67.188                                 \n",
      " 8    1239.46      68.254     67.188     67.717                                 \n",
      " 9    1158.49      67.742     65.625     66.667                                 \n",
      "10    1148.49      68.333     64.062     66.129                                 \n",
      "11    1094.99      70.690     64.062     67.213                                 \n",
      "12    1211.36      74.545     64.062     68.908                                 \n",
      "13    1177.81      74.545     64.062     68.908                                 \n",
      "14    1136.87      73.585     60.938     66.667                                 \n",
      "15    1117.66      72.222     60.938     66.102                                 \n",
      "16    1109.42      71.698     59.375     64.957                                 \n",
      "17    1053.65      72.222     60.938     66.102                                 \n",
      "18    1055.98      72.727     62.500     67.227                                 \n",
      "19    1042.33      71.429     62.500     66.667                                 \n",
      "20    1071.00      71.429     62.500     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model349.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1491.81      74.074     31.250     43.956                                 \n",
      " 2    1378.58      56.000     43.750     49.123                                 \n",
      " 3    1395.82      67.213     64.062     65.600                                 \n",
      " 4    1347.36      69.811     57.812     63.248                                 \n",
      " 5    1348.11      66.667     59.375     62.810                                 \n",
      " 6    1329.93      67.213     64.062     65.600                                 \n",
      " 7    1336.74      66.667     62.500     64.516                                 \n",
      " 8    1236.48      68.254     67.188     67.717                                 \n",
      " 9    1133.20      67.742     65.625     66.667                                 \n",
      "10    1165.31      67.742     65.625     66.667                                 \n",
      "11    1132.37      72.131     68.750     70.400                                 \n",
      "12    1199.91      70.492     67.188     68.800                                 \n",
      "13    1131.93      70.000     65.625     67.742                                 \n",
      "14    1158.19      69.643     60.938     65.000                                 \n",
      "15    1086.05      67.241     60.938     63.934                                 \n",
      "16    1077.17      68.750     68.750     68.750                                 \n",
      "17    1042.51      68.750     68.750     68.750                                 \n",
      "18    1065.59      69.841     68.750     69.291                                 \n",
      "19    1054.19      70.968     68.750     69.841                                 \n",
      "20    1134.29      71.186     65.625     68.293                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.131   68.750    70.400\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.400\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model352.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1501.57      67.742     32.812     44.211                                 \n",
      " 2    1396.89      56.452     54.688     55.556                                 \n",
      " 3    1375.31      68.966     62.500     65.574                                 \n",
      " 4    1390.81      75.000     65.625     70.000                                 \n",
      " 5    1321.72      73.214     64.062     68.333                                 \n",
      " 6    1338.10      71.429     62.500     66.667                                 \n",
      " 7    1332.88      70.000     65.625     67.742                                 \n",
      " 8    1290.72      71.186     65.625     68.293                                 \n",
      " 9    1204.20      67.213     64.062     65.600                                 \n",
      "10    1223.62      68.333     64.062     66.129                                 \n",
      "11    1144.31      69.492     64.062     66.667                                 \n",
      "12    1235.73      70.000     65.625     67.742                                 \n",
      "13    1198.85      68.254     67.188     67.717                                 \n",
      "14    1152.42      69.355     67.188     68.254                                 \n",
      "15    1102.75      69.355     67.188     68.254                                 \n",
      "16    1095.48      73.333     68.750     70.968                                 \n",
      "17    1051.79      73.333     68.750     70.968                                 \n",
      "18    1080.34      73.333     68.750     70.968                                 \n",
      "19    1051.04      74.138     67.188     70.492                                 \n",
      "20    1097.52      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.333   68.750    70.968\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.968\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model355.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1459.26      73.529     39.062     51.020                                 \n",
      " 2    1407.96      55.357     48.438     51.667                                 \n",
      " 3    1394.40      64.516     62.500     63.492                                 \n",
      " 4    1432.92      67.797     62.500     65.041                                 \n",
      " 5    1433.82      72.131     68.750     70.400                                 \n",
      " 6    1359.35      68.254     67.188     67.717                                 \n",
      " 7    1331.39      72.131     68.750     70.400                                 \n",
      " 8    1287.15      69.355     67.188     68.254                                 \n",
      " 9    1173.47      69.643     60.938     65.000                                 \n",
      "10    1179.82      67.273     57.812     62.185                                 \n",
      "11    1165.31      67.241     60.938     63.934                                 \n",
      "12    1244.11      69.091     59.375     63.866                                 \n",
      "13    1149.95      69.091     59.375     63.866                                 \n",
      "14    1150.14      72.727     62.500     67.227                                 \n",
      "15    1089.74      72.727     62.500     67.227                                 \n",
      "16    1113.01      72.222     60.938     66.102                                 \n",
      "17    1010.74      72.222     60.938     66.102                                 \n",
      "18    1074.95      72.727     62.500     67.227                                 \n",
      "19    1051.31      72.727     62.500     67.227                                 \n",
      "20    1102.22      74.074     62.500     67.797                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.131   68.750    70.400\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.400\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model358.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1497.01      82.143     35.938     50.000                                 \n",
      " 2    1506.69      56.604     46.875     51.282                                 \n",
      " 3    1442.95      70.175     62.500     66.116                                 \n",
      " 4    1530.79      70.175     62.500     66.116                                 \n",
      " 5    1415.23      69.841     68.750     69.291                                 \n",
      " 6    1351.17      74.576     68.750     71.545                                 \n",
      " 7    1369.47      76.271     70.312     73.171                                 \n",
      " 8    1290.59      73.770     70.312     72.000                                 \n",
      " 9    1231.80      69.355     67.188     68.254                                 \n",
      "10    1211.95      74.138     67.188     70.492                                 \n",
      "11    1128.15      74.545     64.062     68.908                                 \n",
      "12    1228.08      75.472     62.500     68.376                                 \n",
      "13    1160.52      73.684     65.625     69.421                                 \n",
      "14    1158.76      73.214     64.062     68.333                                 \n",
      "15    1091.58      71.186     65.625     68.293                                 \n",
      "16    1095.38      71.186     65.625     68.293                                 \n",
      "17    1095.36      70.690     64.062     67.213                                 \n",
      "18    1057.63      71.930     64.062     67.769                                 \n",
      "19    1041.77      72.222     60.938     66.102                                 \n",
      "20    1085.03      72.727     62.500     67.227                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.271   70.312    73.171\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.171\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model361.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1468.62      75.000     28.125     40.909                                 \n",
      " 2    1403.44      56.604     46.875     51.282                                 \n",
      " 3    1433.60      72.727     62.500     67.227                                 \n",
      " 4    1343.53      71.429     62.500     66.667                                 \n",
      " 5    1400.90      75.000     65.625     70.000                                 \n",
      " 6    1284.86      69.388     53.125     60.177                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7    1354.79      69.492     64.062     66.667                                 \n",
      " 8    1216.38      70.000     65.625     67.742                                 \n",
      " 9    1191.40      71.930     64.062     67.769                                 \n",
      "10    1213.28      69.492     64.062     66.667                                 \n",
      "11    1120.01      72.414     65.625     68.852                                 \n",
      "12    1184.18      70.690     64.062     67.213                                 \n",
      "13    1168.83      70.000     65.625     67.742                                 \n",
      "14    1137.41      71.186     65.625     68.293                                 \n",
      "15    1096.33      72.881     67.188     69.919                                 \n",
      "16    1110.22      72.881     67.188     69.919                                 \n",
      "17    1042.73      70.000     65.625     67.742                                 \n",
      "18    1085.84      70.000     65.625     67.742                                 \n",
      "19    1051.89      71.186     65.625     68.293                                 \n",
      "20    1122.25      70.000     65.625     67.742                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   65.625    70.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model364.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1475.85      73.913     26.562     39.080                                 \n",
      " 2    1395.30      60.345     54.688     57.377                                 \n",
      " 3    1466.56      63.492     62.500     62.992                                 \n",
      " 4    1458.31      65.079     64.062     64.567                                 \n",
      " 5    1387.25      69.841     68.750     69.291                                 \n",
      " 6    1399.31      72.881     67.188     69.919                                 \n",
      " 7    1367.27      72.131     68.750     70.400                                 \n",
      " 8    1236.27      72.881     67.188     69.919                                 \n",
      " 9    1206.02      66.667     65.625     66.142                                 \n",
      "10    1152.49      66.154     67.188     66.667                                 \n",
      "11    1122.02      68.254     67.188     67.717                                 \n",
      "12    1203.39      67.647     71.875     69.697                                 \n",
      "13    1164.37      65.672     68.750     67.176                                 \n",
      "14    1100.32      66.667     68.750     67.692                                 \n",
      "15    1088.08      67.164     70.312     68.702                                 \n",
      "16    1098.71      67.188     67.188     67.188                                 \n",
      "17    1070.96      71.429     70.312     70.866                                 \n",
      "18    1063.42      70.769     71.875     71.318                                 \n",
      "19    1025.90      69.697     71.875     70.769                                 \n",
      "20    1108.97      68.657     71.875     70.229                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.769   71.875    71.318\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.318\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model367.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1473.31      60.526     35.938     45.098                                 \n",
      " 2    1423.92      59.259     50.000     54.237                                 \n",
      " 3    1375.16      66.667     65.625     66.142                                 \n",
      " 4    1432.01      76.364     65.625     70.588                                 \n",
      " 5    1326.26      70.312     70.312     70.312                                 \n",
      " 6    1312.24      75.472     62.500     68.376                                 \n",
      " 7    1292.21      71.930     64.062     67.769                                 \n",
      " 8    1239.29      69.492     64.062     66.667                                 \n",
      " 9    1292.43      70.175     62.500     66.116                                 \n",
      "10    1259.72      67.241     60.938     63.934                                 \n",
      "11    1139.84      67.241     60.938     63.934                                 \n",
      "12    1227.23      67.241     60.938     63.934                                 \n",
      "13    1174.76      68.421     60.938     64.463                                 \n",
      "14    1143.80      65.517     59.375     62.295                                 \n",
      "15    1075.25      66.071     57.812     61.667                                 \n",
      "16    1080.32      67.273     57.812     62.185                                 \n",
      "17    1028.64      67.273     57.812     62.185                                 \n",
      "18    1074.71      67.857     59.375     63.333                                 \n",
      "19    1030.35      67.273     57.812     62.185                                 \n",
      "20    1082.85      66.071     57.812     61.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model370.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1494.61      82.143     35.938     50.000                                 \n",
      " 2    1508.43      55.769     45.312     50.000                                 \n",
      " 3    1374.25      66.667     62.500     64.516                                 \n",
      " 4    1382.22      68.421     60.938     64.463                                 \n",
      " 5    1390.63      63.333     59.375     61.290                                 \n",
      " 6    1343.73      68.333     64.062     66.129                                 \n",
      " 7    1376.89      69.492     64.062     66.667                                 \n",
      " 8    1202.91      68.333     64.062     66.129                                 \n",
      " 9    1185.85      64.615     65.625     65.116                                 \n",
      "10    1172.75      64.062     64.062     64.062                                 \n",
      "11    1131.93      64.062     64.062     64.062                                 \n",
      "12    1217.74      68.333     64.062     66.129                                 \n",
      "13    1136.11      68.333     64.062     66.129                                 \n",
      "14    1119.97      68.333     64.062     66.129                                 \n",
      "15    1108.13      67.213     64.062     65.600                                 \n",
      "16    1087.58      67.742     65.625     66.667                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    1061.78      71.186     65.625     68.293                                 \n",
      "18    1051.42      65.079     64.062     64.567                                 \n",
      "19    1030.53      62.500     62.500     62.500                                 \n",
      "20    1079.54      62.500     62.500     62.500                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.186   65.625    68.293\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.293\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model373.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1479.95      80.000     25.000     38.095                                 \n",
      " 2    1463.46      58.621     53.125     55.738                                 \n",
      " 3    1436.31      70.769     71.875     71.318                                 \n",
      " 4    1401.12      67.742     65.625     66.667                                 \n",
      " 5    1463.03      71.429     62.500     66.667                                 \n",
      " 6    1367.25      71.930     64.062     67.769                                 \n",
      " 7    1305.11      73.684     65.625     69.421                                 \n",
      " 8    1319.25      75.439     67.188     71.074                                 \n",
      " 9    1279.53      69.355     67.188     68.254                                 \n",
      "10    1179.43      68.254     67.188     67.717                                 \n",
      "11    1149.79      70.000     65.625     67.742                                 \n",
      "12    1195.89      71.930     64.062     67.769                                 \n",
      "13    1183.69      72.727     62.500     67.227                                 \n",
      "14    1125.26      72.727     62.500     67.227                                 \n",
      "15    1092.42      73.214     64.062     68.333                                 \n",
      "16    1110.40      75.000     65.625     70.000                                 \n",
      "17    1055.49      76.364     65.625     70.588                                 \n",
      "18    1082.35      74.545     64.062     68.908                                 \n",
      "19    1032.87      74.074     62.500     67.797                                 \n",
      "20    1095.61      74.545     64.062     68.908                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.769   71.875    71.318\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.318\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model376.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1490.79      74.194     35.938     48.421                                 \n",
      " 2    1486.89      58.929     51.562     55.000                                 \n",
      " 3    1428.10      69.355     67.188     68.254                                 \n",
      " 4    1436.83      75.926     64.062     69.492                                 \n",
      " 5    1360.91      70.000     65.625     67.742                                 \n",
      " 6    1379.54      78.182     67.188     72.269                                 \n",
      " 7    1373.37      75.439     67.188     71.074                                 \n",
      " 8    1265.91      76.364     65.625     70.588                                 \n",
      " 9    1222.62      75.000     65.625     70.000                                 \n",
      "10    1190.72      75.000     65.625     70.000                                 \n",
      "11    1135.42      72.881     67.188     69.919                                 \n",
      "12    1243.38      74.138     67.188     70.492                                 \n",
      "13    1152.59      72.881     67.188     69.919                                 \n",
      "14    1140.85      69.355     67.188     68.254                                 \n",
      "15    1120.23      70.000     65.625     67.742                                 \n",
      "16    1103.56      70.492     67.188     68.800                                 \n",
      "17    1079.51      69.355     67.188     68.254                                 \n",
      "18    1078.24      71.667     67.188     69.355                                 \n",
      "19    1054.98      70.690     64.062     67.213                                 \n",
      "20    1097.00      73.684     65.625     69.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model379.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1508.48      61.765     32.812     42.857                                 \n",
      " 2    1391.73      52.542     48.438     50.407                                 \n",
      " 3    1447.84      60.714     53.125     56.667                                 \n",
      " 4    1385.72      75.000     65.625     70.000                                 \n",
      " 5    1366.87      71.698     59.375     64.957                                 \n",
      " 6    1379.19      71.186     65.625     68.293                                 \n",
      " 7    1377.68      68.333     64.062     66.129                                 \n",
      " 8    1272.24      66.667     65.625     66.142                                 \n",
      " 9    1196.80      67.213     64.062     65.600                                 \n",
      "10    1207.74      67.742     65.625     66.667                                 \n",
      "11    1121.40      68.333     64.062     66.129                                 \n",
      "12    1190.79      70.690     64.062     67.213                                 \n",
      "13    1167.20      69.492     64.062     66.667                                 \n",
      "14    1125.79      67.797     62.500     65.041                                 \n",
      "15    1086.65      74.074     62.500     67.797                                 \n",
      "16    1106.11      71.429     62.500     66.667                                 \n",
      "17    1049.52      67.273     57.812     62.185                                 \n",
      "18    1091.41      68.421     60.938     64.463                                 \n",
      "19    1038.40      68.966     62.500     65.574                                 \n",
      "20    1106.13      66.667     59.375     62.810                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   65.625    70.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model382.bin\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1452.25      76.923     31.250     44.444                                 \n",
      " 2    1457.58      58.182     50.000     53.782                                 \n",
      " 3    1478.05      55.738     53.125     54.400                                 \n",
      " 4    1438.49      69.492     64.062     66.667                                 \n",
      " 5    1347.63      71.667     67.188     69.355                                 \n",
      " 6    1348.81      70.690     64.062     67.213                                 \n",
      " 7    1324.75      70.690     64.062     67.213                                 \n",
      " 8    1294.85      70.690     64.062     67.213                                 \n",
      " 9    1210.03      70.909     60.938     65.546                                 \n",
      "10    1158.22      70.909     60.938     65.546                                 \n",
      "11    1129.47      73.214     64.062     68.333                                 \n",
      "12    1222.24      71.930     64.062     67.769                                 \n",
      "13    1182.98      73.214     64.062     68.333                                 \n",
      "14    1148.04      72.222     60.938     66.102                                 \n",
      "15    1098.01      68.966     62.500     65.574                                 \n",
      "16    1113.09      70.175     62.500     66.116                                 \n",
      "17    1055.99      70.175     62.500     66.116                                 \n",
      "18    1080.18      73.214     64.062     68.333                                 \n",
      "19    1062.66      76.364     65.625     70.588                                 \n",
      "20    1082.50      73.684     65.625     69.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model385.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1474.43      68.750     34.375     45.833                                 \n",
      " 2    1427.21      61.538     50.000     55.172                                 \n",
      " 3    1363.23      64.286     56.250     60.000                                 \n",
      " 4    1454.41      69.355     67.188     68.254                                 \n",
      " 5    1426.09      68.000     53.125     59.649                                 \n",
      " 6    1354.08      69.388     53.125     60.177                                 \n",
      " 7    1358.31      73.214     64.062     68.333                                 \n",
      " 8    1262.54      70.909     60.938     65.546                                 \n",
      " 9    1225.14      74.510     59.375     66.087                                 \n",
      "10    1164.95      72.727     62.500     67.227                                 \n",
      "11    1108.85      73.214     64.062     68.333                                 \n",
      "12    1222.88      73.684     65.625     69.421                                 \n",
      "13    1190.25      73.684     65.625     69.421                                 \n",
      "14    1171.69      75.439     67.188     71.074                                 \n",
      "15    1088.32      73.684     65.625     69.421                                 \n",
      "16    1076.67      74.545     64.062     68.908                                 \n",
      "17    1077.19      75.000     65.625     70.000                                 \n",
      "18    1082.58      74.545     64.062     68.908                                 \n",
      "19    1043.95      74.545     64.062     68.908                                 \n",
      "20    1085.81      72.222     60.938     66.102                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.439   67.188    71.074\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.074\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model388.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1472.32      79.167     29.688     43.182                                 \n",
      " 2    1442.49      50.943     42.188     46.154                                 \n",
      " 3    1423.21      73.684     65.625     69.421                                 \n",
      " 4    1469.38      70.492     67.188     68.800                                 \n",
      " 5    1347.15      76.786     67.188     71.667                                 \n",
      " 6    1467.34      68.333     64.062     66.129                                 \n",
      " 7    1330.76      71.930     64.062     67.769                                 \n",
      " 8    1221.78      73.684     65.625     69.421                                 \n",
      " 9    1160.02      71.186     65.625     68.293                                 \n",
      "10    1194.90      69.492     64.062     66.667                                 \n",
      "11    1135.90      67.797     62.500     65.041                                 \n",
      "12    1217.29      70.690     64.062     67.213                                 \n",
      "13    1187.73      71.930     64.062     67.769                                 \n",
      "14    1137.46      74.138     67.188     70.492                                 \n",
      "15    1093.86      75.862     68.750     72.131                                 \n",
      "16    1074.42      75.862     68.750     72.131                                 \n",
      "17    1076.17      77.193     68.750     72.727                                 \n",
      "18    1085.80      77.193     68.750     72.727                                 \n",
      "19    1036.47      75.862     68.750     72.131                                 \n",
      "20    1077.45      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.193   68.750    72.727\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.727\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model391.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1484.32      55.556     39.062     45.872                                 \n",
      " 2    1426.46      60.870     43.750     50.909                                 \n",
      " 3    1362.96      75.000     65.625     70.000                                 \n",
      " 4    1395.35      70.968     68.750     69.841                                 \n",
      " 5    1302.74      74.138     67.188     70.492                                 \n",
      " 6    1288.90      71.930     64.062     67.769                                 \n",
      " 7    1303.88      72.414     65.625     68.852                                 \n",
      " 8    1220.91      70.000     65.625     67.742                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9    1182.15      71.930     64.062     67.769                                 \n",
      "10    1244.71      72.881     67.188     69.919                                 \n",
      "11    1107.36      70.492     67.188     68.800                                 \n",
      "12    1196.49      72.131     68.750     70.400                                 \n",
      "13    1168.93      75.000     70.312     72.581                                 \n",
      "14    1169.17      76.271     70.312     73.171                                 \n",
      "15    1097.94      75.000     70.312     72.581                                 \n",
      "16    1106.83      75.000     70.312     72.581                                 \n",
      "17    1035.00      76.667     71.875     74.194                                 \n",
      "18    1086.49      75.000     70.312     72.581                                 \n",
      "19    1051.42      76.271     70.312     73.171                                 \n",
      "20    1094.91      71.667     67.188     69.355                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.667   71.875    74.194\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.194\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model394.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1498.20      77.778     32.812     46.154                                 \n",
      " 2    1535.97      62.162     35.938     45.545                                 \n",
      " 3    1400.64      64.583     48.438     55.357                                 \n",
      " 4    1484.71      67.797     62.500     65.041                                 \n",
      " 5    1401.62      67.241     60.938     63.934                                 \n",
      " 6    1353.39      71.930     64.062     67.769                                 \n",
      " 7    1346.21      71.186     65.625     68.293                                 \n",
      " 8    1293.39      71.429     70.312     70.866                                 \n",
      " 9    1292.20      76.364     65.625     70.588                                 \n",
      "10    1230.99      76.364     65.625     70.588                                 \n",
      "11    1160.98      74.138     67.188     70.492                                 \n",
      "12    1237.24      70.492     67.188     68.800                                 \n",
      "13    1176.61      72.131     68.750     70.400                                 \n",
      "14    1148.12      73.333     68.750     70.968                                 \n",
      "15    1125.37      72.881     67.188     69.919                                 \n",
      "16    1085.59      72.881     67.188     69.919                                 \n",
      "17    1077.11      72.414     65.625     68.852                                 \n",
      "18    1098.44      71.930     64.062     67.769                                 \n",
      "19    1069.67      72.414     65.625     68.852                                 \n",
      "20    1059.42      71.930     64.062     67.769                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.333   68.750    70.968\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.968\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model397.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1477.52      59.574     43.750     50.450                                 \n",
      " 2    1500.55      57.143     56.250     56.693                                 \n",
      " 3    1443.05      65.000     60.938     62.903                                 \n",
      " 4    1407.70      73.214     64.062     68.333                                 \n",
      " 5    1355.74      66.667     59.375     62.810                                 \n",
      " 6    1403.46      76.364     65.625     70.588                                 \n",
      " 7    1333.86      77.193     68.750     72.727                                 \n",
      " 8    1251.28      73.214     64.062     68.333                                 \n",
      " 9    1190.67      71.429     62.500     66.667                                 \n",
      "10    1201.75      68.333     64.062     66.129                                 \n",
      "11    1126.88      74.138     67.188     70.492                                 \n",
      "12    1232.06      76.364     65.625     70.588                                 \n",
      "13    1205.92      74.545     64.062     68.908                                 \n",
      "14    1153.98      75.000     65.625     70.000                                 \n",
      "15    1102.53      75.000     65.625     70.000                                 \n",
      "16    1135.46      77.778     65.625     71.186                                 \n",
      "17    1069.66      76.786     67.188     71.667                                 \n",
      "18    1073.51      74.545     64.062     68.908                                 \n",
      "19    1036.94      76.364     65.625     70.588                                 \n",
      "20    1070.94      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.193   68.750    72.727\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.727\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model4.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1591.72      57.143     18.750     28.235                                 \n",
      " 2    1430.54      60.976     39.062     47.619                                 \n",
      " 3    1431.12      76.087     54.688     63.636                                 \n",
      " 4    1447.46      73.333     51.562     60.550                                 \n",
      " 5    1405.81      75.000     65.625     70.000                                 \n",
      " 6    1360.50      81.132     67.188     73.504                                 \n",
      " 7    1350.34      78.431     62.500     69.565                                 \n",
      " 8    1295.07      75.000     56.250     64.286                                 \n",
      " 9    1306.47      77.358     64.062     70.085                                 \n",
      "10    1206.40      73.684     65.625     69.421                                 \n",
      "11    1224.72      74.510     59.375     66.087                                 \n",
      "12    1314.89      73.077     59.375     65.517                                 \n",
      "13    1219.40      73.077     59.375     65.517                                 \n",
      "14    1193.32      71.698     59.375     64.957                                 \n",
      "15    1119.57      71.154     57.812     63.793                                 \n",
      "16    1117.24      70.588     56.250     62.609                                 \n",
      "17    1067.36      68.627     54.688     60.870                                 \n",
      "18    1087.17      68.627     54.688     60.870                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    1049.51      70.000     54.688     61.404                                 \n",
      "20    1108.60      67.925     56.250     61.538                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.132   67.188    73.504\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.504\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model402.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1488.26      58.140     39.062     46.729                                 \n",
      " 2    1421.99      70.833     53.125     60.714                                 \n",
      " 3    1426.83      79.592     60.938     69.027                                 \n",
      " 4    1391.90      74.074     62.500     67.797                                 \n",
      " 5    1380.14      73.770     70.312     72.000                                 \n",
      " 6    1300.70      67.925     56.250     61.538                                 \n",
      " 7    1358.52      73.770     70.312     72.000                                 \n",
      " 8    1299.68      68.254     67.188     67.717                                 \n",
      " 9    1183.21      72.881     67.188     69.919                                 \n",
      "10    1179.75      73.333     68.750     70.968                                 \n",
      "11    1170.85      72.881     67.188     69.919                                 \n",
      "12    1229.42      71.930     64.062     67.769                                 \n",
      "13    1201.75      73.684     65.625     69.421                                 \n",
      "14    1129.39      74.545     64.062     68.908                                 \n",
      "15    1091.21      73.214     64.062     68.333                                 \n",
      "16    1070.32      77.358     64.062     70.085                                 \n",
      "17    1049.59      74.545     64.062     68.908                                 \n",
      "18    1049.31      73.214     64.062     68.333                                 \n",
      "19    1011.39      73.214     64.062     68.333                                 \n",
      "20    1071.92      71.930     64.062     67.769                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.770   70.312    72.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model405.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1491.61      72.727     37.500     49.485                                 \n",
      " 2    1443.71      64.583     48.438     55.357                                 \n",
      " 3    1411.57      66.102     60.938     63.415                                 \n",
      " 4    1467.63      72.000     56.250     63.158                                 \n",
      " 5    1387.82      66.129     64.062     65.079                                 \n",
      " 6    1341.81      70.968     68.750     69.841                                 \n",
      " 7    1343.37      74.545     64.062     68.908                                 \n",
      " 8    1235.93      74.074     62.500     67.797                                 \n",
      " 9    1228.95      75.000     60.938     67.241                                 \n",
      "10    1219.95      76.923     62.500     68.966                                 \n",
      "11    1132.14      74.074     62.500     67.797                                 \n",
      "12    1209.13      72.222     60.938     66.102                                 \n",
      "13    1188.35      69.091     59.375     63.866                                 \n",
      "14    1143.57      69.811     57.812     63.248                                 \n",
      "15    1119.70      69.231     56.250     62.069                                 \n",
      "16    1095.23      69.231     56.250     62.069                                 \n",
      "17    1032.31      67.857     59.375     63.333                                 \n",
      "18    1095.17      67.308     54.688     60.345                                 \n",
      "19    1041.82      67.925     56.250     61.538                                 \n",
      "20    1086.15      68.519     57.812     62.712                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.968   68.750    69.841\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.841\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# run training for a selected models, use every skip_models-th file\n",
    "skip_models = 3\n",
    "abs_models_dir = Path('models/tok2vec_abs_sci_ALL_gpu')\n",
    "\n",
    "models = sorted(os.listdir(abs_models_dir))\n",
    "\n",
    "for idx, model_file in enumerate(models):\n",
    "    if idx % skip_models == 0:\n",
    "        model_path = abs_models_dir / model_file\n",
    "        !prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg \\\n",
    "            --eval-split 0.2 --n-iter 20 --init-tok2vec $model_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
