{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.28 (Sat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model: spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_web_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 86 total examples\n",
      "Using 43 train / 43 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2260.23       3.822      5.714      4.580                                 \n",
      " 2     304.20      96.203     72.381     82.609                                 \n",
      " 3      35.94      93.069     89.524     91.262                                 \n",
      " 4       7.71      91.262     89.524     90.385                                 \n",
      " 5       6.89      94.000     89.524     91.707                                 \n",
      " 6       6.26      94.949     89.524     92.157                                 \n",
      " 7       4.15      94.000     89.524     91.707                                 \n",
      " 8      10.58      92.157     89.524     90.821                                 \n",
      " 9       1.78      92.157     89.524     90.821                                 \n",
      "10       0.00      93.069     89.524     91.262                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.949   89.524    92.157\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m92.157\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_28_match/en_rf_web_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_match models/en_core_web_lg_no_ner --output models/2020_03_28_match/en_rf_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model: scispaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 86 total examples\n",
      "Using 43 train / 43 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1864.33       3.333      2.941      3.125                                 \n",
      " 2     303.79      93.902     75.490     83.696                                 \n",
      " 3      22.39      92.784     88.235     90.452                                 \n",
      " 4      17.47      94.792     89.216     91.919                                 \n",
      " 5       5.36      93.814     89.216     91.457                                 \n",
      " 6       6.78      92.857     89.216     91.000                                 \n",
      " 7       6.09      93.814     89.216     91.457                                 \n",
      " 8       4.87      94.792     89.216     91.919                                 \n",
      " 9       9.64      93.814     89.216     91.457                                 \n",
      "10       4.02      94.792     89.216     91.919                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.792   89.216    91.919\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m91.919\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_28_match/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_match models/en_core_sci_lg_no_ner --output models/2020_03_28_match/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.29 (Sun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model trained on Sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "def test_model(model_path):\n",
    "    warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "    \n",
    "    nlp = spacy.load(model_path)\n",
    "    texts = [\n",
    "    \"Known risk factors for the disease are: older age, male gender, diabetes and leukemia. Female patiens and children are less susceptible.\",\n",
    "    \"Diabetes is a known risk factor.\",\n",
    "    \"Leukemia is a risk factor, too.\"\n",
    "    ]\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "\n",
    "        spacy.displacy.render(doc, style='ent', jupyter=True)\n",
    "        pprint([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Known risk factors for the disease are: older \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    age\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    male\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " gender, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " and leukemia. Female patiens and children are less susceptible.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('age', 'RISK_FACTOR'), ('male', 'RISK_FACTOR'), ('diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " is a known risk factor.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Leukemia is a risk factor, too.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_model(\"models/2020_03_28_match/en_rf_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the factors that appeared during the training are detected. _Leukemia_ is **not highlighed** and that means that the NER model did not learn to recognize risk factors based on the sentence structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train new models after the `teach` session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_web_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 393 total examples\n",
      "Using 197 train / 196 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     333.36      89.669     92.735     91.176                                 \n",
      " 2      64.66      92.982     90.598     91.775                                 \n",
      " 3      53.47      94.492     95.299     94.894                                 \n",
      " 4      45.26      94.492     95.299     94.894                                 \n",
      " 5      29.42      94.958     96.581     95.763                                 \n",
      " 6      30.44      96.170     96.581     96.375                                 \n",
      " 7      23.82      95.745     96.154     95.949                                 \n",
      " 8       5.78      95.319     95.726     95.522                                 \n",
      " 9       4.12      95.299     95.299     95.299                                 \n",
      "10       5.46      96.137     95.726     95.931                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      96.170   96.581    96.375\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m96.375\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_29_teach/en_rf_web_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_teach models/en_core_web_lg_no_ner --output models/2020_03_29_teach/en_rf_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 393 total examples\n",
      "Using 197 train / 196 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     289.28      90.991     91.818     91.403                                 \n",
      " 2      54.12      92.237     91.818     92.027                                 \n",
      " 3      84.39      91.593     94.091     92.825                                 \n",
      " 4      46.45      93.213     93.636     93.424                                 \n",
      " 5      19.43      95.000     95.000     95.000                                 \n",
      " 6      15.25      93.665     94.091     93.878                                 \n",
      " 7       4.07      93.363     95.909     94.619                                 \n",
      " 8      11.23      93.722     95.000     94.357                                 \n",
      " 9      10.13      94.595     95.455     95.023                                 \n",
      "10       6.20      94.595     95.455     95.023                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.595   95.455    95.023\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m95.023\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_29_teach/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_teach models/en_core_sci_lg_no_ner --output models/2020_03_29_teach/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Known risk factors for the disease are: older \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    age\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    male gender\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " and leukemia. Female patiens and children are less susceptible.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('age', 'RISK_FACTOR'),\n",
      " ('male gender', 'RISK_FACTOR'),\n",
      " ('diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " is a known risk factor.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Leukemia is a risk factor, too.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_model(\"models/2020_03_29_teach/en_rf_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better model scores, but _leukemia_ still **not detected**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.30 (Mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`strict`)\n",
    "\n",
    "Terms like _male_ or _age_ will only be marked, when they are mentioned in the context of COVID-19 risk factors, i.e. not in articles about animals or children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_abstracts_strict to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 41 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_abstracts_strict\n",
      "Session ID: 2020-03-30_20-24-26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual cord_19_abstracts_strict models/en_core_sci_lg_no_ner data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR --patterns patterns/RF_list_2020.03.17.20037572.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 41 total examples\n",
      "Using 21 train / 20 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1737.49       0.000      0.000      0.000                                 \n",
      " 2      25.99       0.000      0.000      0.000                                 \n",
      " 3     115.63       0.000      0.000      0.000                                 \n",
      " 4      24.86       0.000      0.000      0.000                                 \n",
      " 5      22.36       0.000      0.000      0.000                                 \n",
      " 6      18.33       0.000      0.000      0.000                                 \n",
      " 7      20.52       0.000      0.000      0.000                                 \n",
      " 8      28.45       0.000      0.000      0.000                                 \n",
      " 9      18.38       0.000      0.000      0.000                                 \n",
      "10       7.78       0.000      0.000      0.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR       0.000    0.000     0.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m0.000\u001b[0m\n",
      "Baseline       0.000             \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_30_strict/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_strict models/en_core_sci_lg_no_ner --output models/2020_03_30_strict/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`all RF`)\n",
    "\n",
    "Highlight all risk factors - for any disease or species - but only is sentences that clear say it is a risk factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!prodigy ner.manual cord_19_abstracts_all_rf models/en_core_sci_lg_no_ner data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR --patterns patterns/RF_highlight_factor_phrases.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 58 total examples\n",
      "Using 29 train / 29 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1960.54       0.000      0.000      0.000                                 \n",
      " 2      95.38       0.000      0.000      0.000                                 \n",
      " 3     161.78     100.000      2.128      4.167                                 \n",
      " 4      88.78      40.000      4.255      7.692                                 \n",
      " 5      97.87      33.333      4.255      7.547                                 \n",
      " 6      87.81      37.500      6.383     10.909                                 \n",
      " 7     341.72      25.000      2.128      3.922                                 \n",
      " 8     169.64      40.000      4.255      7.692                                 \n",
      " 9      79.07      30.000      6.383     10.526                                 \n",
      "10     268.87      33.333      6.383     10.714                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      37.500    6.383    10.909\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m10.909\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_30_all_RF/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_abstracts_all_rf models/en_core_sci_lg_no_ner --output models/2020_03_30_all_RF/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "\n",
      "✨  Starting the web server at http://localhost:8081 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 7 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_abstracts_all_rf\n",
      "Session ID: 2020-03-30_22-01-26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.teach cord_19_abstracts_all_rf models/2020_03_30_all_RF/en_rf_sci_lg data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.06 (Mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`RF sentences`)\n",
    "\n",
    "Following the official guide:\n",
    "- https://www.youtube.com/watch?v=59BKHO_xBPA\n",
    "- https://github.com/explosion/projects/tree/master/ner-food-ingredients#data-creation-and-training-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 102 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences\n",
      "Session ID: 2020-04-06_22-08-56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual cord_19_rf_sentences blank:en data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     389.18       0.000      0.000      0.000                                 \n",
      " 2     191.03      25.000      4.000      6.897                                 \n",
      " 3     265.45      35.294     24.000     28.571                                 \n",
      " 4     246.57      28.571     24.000     26.087                                 \n",
      " 5     239.21      22.727     20.000     21.277                                 \n",
      " 6     215.80      42.857     24.000     30.769                                 \n",
      " 7     258.40      42.105     32.000     36.364                                 \n",
      " 8     237.19      50.000     32.000     39.024                                 \n",
      " 9     208.67      62.500     40.000     48.780                                 \n",
      "10     141.30      66.667     40.000     50.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667   40.000    50.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m50.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1421.81       0.000      0.000      0.000                                 \n",
      " 2    1245.16       0.000      0.000      0.000                                 \n",
      " 3    1262.77       0.000      0.000      0.000                                 \n",
      " 4    1249.04       0.000      0.000      0.000                                 \n",
      " 5    1262.46       0.000      0.000      0.000                                 \n",
      " 6    1205.26       0.000      0.000      0.000                                 \n",
      " 7    1137.92       0.000      0.000      0.000                                 \n",
      " 8    1131.84       0.000      0.000      0.000                                 \n",
      " 9    1058.85       0.000      0.000      0.000                                 \n",
      "10    1143.62       0.000      0.000      0.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "GPE               0.000    0.000     0.000\n",
      "RISK_FACTOR       0.000    0.000     0.000\n",
      "CARDINAL          0.000    0.000     0.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m0.000\u001b[0m\n",
      "Baseline       0.000             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⁉️ Why is `en_core_web_lg` producing no results at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     559.17       0.000      0.000      0.000                                 \n",
      " 2     550.33      33.333      8.000     12.903                                 \n",
      " 3     538.43      50.000     24.000     32.432                                 \n",
      " 4     457.89      52.632     40.000     45.455                                 \n",
      " 5     452.06      50.000     36.000     41.860                                 \n",
      " 6     415.01      60.000     48.000     53.333                                 \n",
      " 7     489.45      47.826     44.000     45.833                                 \n",
      " 8     461.13      45.000     36.000     40.000                                 \n",
      " 9     486.03      47.619     40.000     43.478                                 \n",
      "10     406.83      54.545     48.000     51.064                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   48.000    53.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m53.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_06_rf_sentences\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 --output models/2020_04_06_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "embed_rows: 2000 | require_vectors: True | cnn_maxout_pieces: 3 |\n",
      "token_vector_width: 96 | conv_depth: 4 | nr_feature_tokens: 3 |\n",
      "pretrained_vectors: en_vectors_web_lg.vectors\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     339.88       0.000      0.000      0.000                                 \n",
      " 2     199.85      50.000     16.000     24.242                                 \n",
      " 3     128.26      50.000     28.000     35.897                                 \n",
      " 4      76.43      42.857     24.000     30.769                                 \n",
      " 5      63.28      60.000     36.000     45.000                                 \n",
      " 6      29.70      53.333     32.000     40.000                                 \n",
      " 7      21.18      56.250     36.000     43.902                                 \n",
      " 8      36.86      50.000     36.000     41.860                                 \n",
      " 9      13.28      52.941     36.000     42.857                                 \n",
      "10       7.74      52.941     36.000     42.857                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   36.000    45.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m45.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2055.18       0.000      0.000      0.000                                 \n",
      " 2    1808.48       0.000      0.000      0.000                                 \n",
      " 3    1624.76       0.000      0.000      0.000                                 \n",
      " 4    1443.31       0.000      0.000      0.000                                 \n",
      " 5    1652.93       0.000      0.000      0.000                                 \n",
      " 6    1470.22       0.000      0.000      0.000                                 \n",
      " 7    1345.14       0.000      0.000      0.000                                 \n",
      " 8    1403.16      50.000      4.000      7.407                                 \n",
      " 9    1249.90      66.667      8.000     14.286                                 \n",
      "10    1357.22      66.667      8.000     14.286                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667    8.000    14.286\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m14.286\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     536.68       0.000      0.000      0.000                                 \n",
      " 2     631.61       0.000      0.000      0.000                                 \n",
      " 3     539.99      40.000     24.000     30.000                                 \n",
      " 4     505.27      47.619     40.000     43.478                                 \n",
      " 5     508.05      45.000     36.000     40.000                                 \n",
      " 6     461.69      52.941     36.000     42.857                                 \n",
      " 7     473.25      45.000     36.000     40.000                                 \n",
      " 8     571.35      61.111     44.000     51.163                                 \n",
      " 9     465.27      55.556     40.000     46.512                                 \n",
      "10     455.26      43.750     28.000     34.146                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      61.111   44.000    51.163\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m51.163\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label more data by correcting the model's predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model so far will be used: `Best F-Score   53.333`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_rf_sentences_correct to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 220 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences_correct\n",
      "Session ID: 2020-04-06_23-58-48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.correct cord_19_rf_sentences_correct models/2020_04_06_rf_sentences data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR --exclude cord_19_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For futher training, only `en_core_sci_lg` will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1554.25      61.538     37.500     46.602                                 \n",
      " 2    1346.09      64.407     59.375     61.789                                 \n",
      " 3    1407.15      66.667     50.000     57.143                                 \n",
      " 4    1411.73      72.727     50.000     59.259                                 \n",
      " 5    1412.81      73.913     53.125     61.818                                 \n",
      " 6    1319.96      73.913     53.125     61.818                                 \n",
      " 7    1378.05      72.917     54.688     62.500                                 \n",
      " 8    1208.99      72.727     62.500     67.227                                 \n",
      " 9    1177.16      73.077     59.375     65.517                                 \n",
      "10    1211.40      72.549     57.812     64.348                                 \n",
      "11    1142.34      74.510     59.375     66.087                                 \n",
      "12    1196.27      72.000     56.250     63.158                                 \n",
      "13    1153.93      72.000     56.250     63.158                                 \n",
      "14    1149.78      72.549     57.812     64.348                                 \n",
      "15    1154.34      69.231     56.250     62.069                                 \n",
      "16    1104.68      69.231     56.250     62.069                                 \n",
      "17    1062.17      68.627     54.688     60.870                                 \n",
      "18    1063.28      68.627     54.688     60.870                                 \n",
      "19    1048.51      68.627     54.688     60.870                                 \n",
      "20    1120.40      68.627     54.688     60.870                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.727   62.500    67.227\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.227\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1578.16      64.000     25.000     35.955                                 \n",
      " 2    1439.61      55.319     40.625     46.847                                 \n",
      " 3    1528.20      72.222     60.938     66.102                                 \n",
      " 4    1429.18      71.154     57.812     63.793                                 \n",
      " 5    1414.46      69.388     53.125     60.177                                 \n",
      " 6    1344.69      75.472     62.500     68.376                                 \n",
      " 7    1472.62      70.909     60.938     65.546                                 \n",
      " 8    1296.39      74.545     64.062     68.908                                 \n",
      " 9    1285.11      68.966     62.500     65.574                                 \n",
      "10    1236.84      70.175     62.500     66.116                                 \n",
      "11    1181.13      71.429     62.500     66.667                                 \n",
      "12    1235.60      70.909     60.938     65.546                                 \n",
      "13    1238.99      76.923     62.500     68.966                                 \n",
      "14    1151.94      75.926     64.062     69.492                                 \n",
      "15    1151.25      75.926     64.062     69.492                                 \n",
      "16    1218.30      78.000     60.938     68.421                                 \n",
      "17    1074.01      75.926     64.062     69.492                                 \n",
      "18    1121.71      76.364     65.625     70.588                                 \n",
      "19    1084.27      77.358     64.062     70.085                                 \n",
      "20    1106.32      76.471     60.938     67.826                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_07_rf_sentences_corrected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin --output models/2020_04_07_rf_sentences_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.28      62.500     23.438     34.091                                 \n",
      " 2    1397.40      59.091     40.625     48.148                                 \n",
      " 3    1485.47      70.833     53.125     60.714                                 \n",
      " 4    1445.56      68.293     43.750     53.333                                 \n",
      " 5    1431.31      64.000     50.000     56.140                                 \n",
      " 6    1339.87      70.833     53.125     60.714                                 \n",
      " 7    1387.07      72.340     53.125     61.261                                 \n",
      " 8    1232.74      76.596     56.250     64.865                                 \n",
      " 9    1207.39      72.340     53.125     61.261                                 \n",
      "10    1231.53      75.926     64.062     69.492                                 \n",
      "11    1154.22      74.545     64.062     68.908                                 \n",
      "12    1304.76      75.472     62.500     68.376                                 \n",
      "13    1155.21      69.811     57.812     63.248                                 \n",
      "14    1158.97      67.273     57.812     62.185                                 \n",
      "15    1092.88      69.811     57.812     63.248                                 \n",
      "16    1134.04      68.627     54.688     60.870                                 \n",
      "17    1055.42      66.667     56.250     61.017                                 \n",
      "18    1071.15      66.667     56.250     61.017                                 \n",
      "19    1060.90      69.231     56.250     62.069                                 \n",
      "20    1063.32      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model989.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.09 (Thu)\n",
    "## Experiments with new `tok2vec` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1577.68      57.895     34.375     43.137                                 \n",
      " 2    1386.95      67.308     54.688     60.345                                 \n",
      " 3    1455.49      76.596     56.250     64.865                                 \n",
      " 4    1457.04      79.592     60.938     69.027                                 \n",
      " 5    1413.30      78.431     62.500     69.565                                 \n",
      " 6    1351.85      76.923     62.500     68.966                                 \n",
      " 7    1304.38      78.000     60.938     68.421                                 \n",
      " 8    1255.67      76.471     60.938     67.826                                 \n",
      " 9    1219.66      78.431     62.500     69.565                                 \n",
      "10    1203.83      74.545     64.062     68.908                                 \n",
      "11    1125.02      74.545     64.062     68.908                                 \n",
      "12    1224.65      74.074     62.500     67.797                                 \n",
      "13    1173.56      75.000     60.938     67.241                                 \n",
      "14    1170.88      75.000     60.938     67.241                                 \n",
      "15    1074.42      71.154     57.812     63.793                                 \n",
      "16    1144.97      75.000     60.938     67.241                                 \n",
      "17    1041.02      73.077     59.375     65.517                                 \n",
      "18    1094.32      74.510     59.375     66.087                                 \n",
      "19    1051.65      74.510     59.375     66.087                                 \n",
      "20    1099.61      78.000     60.938     68.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.431   62.500    69.565\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.565\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model978_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1630.03      55.556     23.438     32.967                                 \n",
      " 2    1442.41      55.556     46.875     50.847                                 \n",
      " 3    1429.19      65.957     48.438     55.856                                 \n",
      " 4    1467.20      65.455     56.250     60.504                                 \n",
      " 5    1467.20      69.643     60.938     65.000                                 \n",
      " 6    1376.49      67.241     60.938     63.934                                 \n",
      " 7    1324.06      73.585     60.938     66.667                                 \n",
      " 8    1261.74      75.472     62.500     68.376                                 \n",
      " 9    1229.62      77.358     64.062     70.085                                 \n",
      "10    1162.35      74.545     64.062     68.908                                 \n",
      "11    1129.31      72.727     62.500     67.227                                 \n",
      "12    1226.05      73.684     65.625     69.421                                 \n",
      "13    1154.44      73.684     65.625     69.421                                 \n",
      "14    1146.38      69.492     64.062     66.667                                 \n",
      "15    1157.15      70.175     62.500     66.116                                 \n",
      "16    1122.06      72.549     57.812     64.348                                 \n",
      "17    1069.36      70.909     60.938     65.546                                 \n",
      "18    1112.07      71.930     64.062     67.769                                 \n",
      "19    1040.95      70.370     59.375     64.407                                 \n",
      "20    1074.33      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   64.062    70.085\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.085\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model997_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1587.95      62.963     26.562     37.363                                 \n",
      " 2    1500.37      60.784     48.438     53.913                                 \n",
      " 3    1510.36      63.492     62.500     62.992                                 \n",
      " 4    1519.20      60.000     56.250     58.065                                 \n",
      " 5    1521.26      65.574     62.500     64.000                                 \n",
      " 6    1495.73      64.912     57.812     61.157                                 \n",
      " 7    1386.50      65.517     59.375     62.295                                 \n",
      " 8    1225.63      65.574     62.500     64.000                                 \n",
      " 9    1277.40      65.079     64.062     64.567                                 \n",
      "10    1258.71      62.903     60.938     61.905                                 \n",
      "11    1151.32      61.905     60.938     61.417                                 \n",
      "12    1249.35      63.793     57.812     60.656                                 \n",
      "13    1169.56      67.241     60.938     63.934                                 \n",
      "14    1163.40      65.517     59.375     62.295                                 \n",
      "15    1137.84      65.517     59.375     62.295                                 \n",
      "16    1137.22      67.241     60.938     63.934                                 \n",
      "17    1094.24      67.857     59.375     63.333                                 \n",
      "18    1079.29      63.793     57.812     60.656                                 \n",
      "19    1028.63      63.158     56.250     59.504                                 \n",
      "20    1096.86      63.158     56.250     59.504                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.079   64.062    64.567\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.567\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_abs_fil_sci_model975_gpu.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.10 (Fri)\n",
    "## Experiments with new `tok2vec` models (cont.)\n",
    "\n",
    "The Kaggle notebook training models for the full set of abstracts (i.e. `cord_19_abstracts.jsonl`) crashed, so I have only partial results and no loss metrics for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model100.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.29      43.478     31.250     36.364                                 \n",
      " 2    1421.36      59.574     43.750     50.450                                 \n",
      " 3    1486.19      68.519     57.812     62.712                                 \n",
      " 4    1477.14      70.000     54.688     61.404                                 \n",
      " 5    1389.42      73.469     56.250     63.717                                 \n",
      " 6    1377.87      70.000     54.688     61.404                                 \n",
      " 7    1379.27      65.385     53.125     58.621                                 \n",
      " 8    1256.60      64.151     53.125     58.120                                 \n",
      " 9    1242.36      66.038     54.688     59.829                                 \n",
      "10    1237.03      63.636     54.688     58.824                                 \n",
      "11    1130.25      65.385     53.125     58.621                                 \n",
      "12    1249.05      65.455     56.250     60.504                                 \n",
      "13    1186.25      68.519     57.812     62.712                                 \n",
      "14    1166.91      68.519     57.812     62.712                                 \n",
      "15    1119.23      66.071     57.812     61.667                                 \n",
      "16    1100.72      67.925     56.250     61.538                                 \n",
      "17    1057.66      74.576     68.750     71.545                                 \n",
      "18    1086.26      74.138     67.188     70.492                                 \n",
      "19    1057.49      69.841     68.750     69.291                                 \n",
      "20    1090.37      73.684     65.625     69.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model111.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1600.67      48.837     32.812     39.252                                 \n",
      " 2    1421.59      58.000     45.312     50.877                                 \n",
      " 3    1410.70      67.925     56.250     61.538                                 \n",
      " 4    1482.27      72.000     56.250     63.158                                 \n",
      " 5    1404.18      68.519     57.812     62.712                                 \n",
      " 6    1417.36      75.862     68.750     72.131                                 \n",
      " 7    1375.52      74.138     67.188     70.492                                 \n",
      " 8    1230.33      73.214     64.062     68.333                                 \n",
      " 9    1212.75      70.175     62.500     66.116                                 \n",
      "10    1148.32      67.213     64.062     65.600                                 \n",
      "11    1162.51      70.175     62.500     66.116                                 \n",
      "12    1222.32      69.492     64.062     66.667                                 \n",
      "13    1173.88      71.930     64.062     67.769                                 \n",
      "14    1140.76      69.643     60.938     65.000                                 \n",
      "15    1103.26      72.222     60.938     66.102                                 \n",
      "16    1172.52      71.429     62.500     66.667                                 \n",
      "17    1056.63      70.909     60.938     65.546                                 \n",
      "18    1088.43      67.273     57.812     62.185                                 \n",
      "19    1048.49      69.811     57.812     63.248                                 \n",
      "20    1090.09      73.469     56.250     63.717                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.862   68.750    72.131\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.131\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model122.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1592.72      46.809     34.375     39.640                                 \n",
      " 2    1389.56      58.000     45.312     50.877                                 \n",
      " 3    1486.58      67.241     60.938     63.934                                 \n",
      " 4    1488.30      66.667     59.375     62.810                                 \n",
      " 5    1412.28      67.273     57.812     62.185                                 \n",
      " 6    1380.28      70.213     51.562     59.459                                 \n",
      " 7    1371.51      69.565     50.000     58.182                                 \n",
      " 8    1348.14      69.565     50.000     58.182                                 \n",
      " 9    1231.75      70.213     51.562     59.459                                 \n",
      "10    1266.15      68.750     51.562     58.929                                 \n",
      "11    1180.40      71.154     57.812     63.793                                 \n",
      "12    1248.50      69.811     57.812     63.248                                 \n",
      "13    1189.91      66.038     54.688     59.829                                 \n",
      "14    1171.11      66.667     62.500     64.516                                 \n",
      "15    1130.89      70.000     65.625     67.742                                 \n",
      "16    1133.67      73.214     64.062     68.333                                 \n",
      "17    1064.69      74.138     67.188     70.492                                 \n",
      "18    1089.44      73.684     65.625     69.421                                 \n",
      "19    1037.00      74.138     67.188     70.492                                 \n",
      "20    1083.52      71.667     67.188     69.355                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.138   67.188    70.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model133.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1609.26      73.077     29.688     42.222                                 \n",
      " 2    1408.47      47.826     34.375     40.000                                 \n",
      " 3    1522.52      62.500     54.688     58.333                                 \n",
      " 4    1498.41      69.091     59.375     63.866                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5    1425.16      71.429     54.688     61.947                                 \n",
      " 6    1396.93      66.667     46.875     55.046                                 \n",
      " 7    1355.34      65.385     53.125     58.621                                 \n",
      " 8    1260.26      72.340     53.125     61.261                                 \n",
      " 9    1208.47      69.643     60.938     65.000                                 \n",
      "10    1174.20      70.175     62.500     66.116                                 \n",
      "11    1190.00      68.519     57.812     62.712                                 \n",
      "12    1224.78      69.811     57.812     63.248                                 \n",
      "13    1148.77      66.667     59.375     62.810                                 \n",
      "14    1130.10      68.966     62.500     65.574                                 \n",
      "15    1096.57      69.643     60.938     65.000                                 \n",
      "16    1122.88      70.909     60.938     65.546                                 \n",
      "17    1034.40      70.909     60.938     65.546                                 \n",
      "18    1068.79      70.909     60.938     65.546                                 \n",
      "19    1052.84      64.286     56.250     60.000                                 \n",
      "20    1115.99      68.852     65.625     67.200                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      68.852   65.625    67.200\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.200\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model144.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1609.58      52.941     28.125     36.735                                 \n",
      " 2    1467.02      56.818     39.062     46.296                                 \n",
      " 3    1456.72      57.407     48.438     52.542                                 \n",
      " 4    1451.96      66.667     56.250     61.017                                 \n",
      " 5    1464.37      63.265     48.438     54.867                                 \n",
      " 6    1389.30      72.340     53.125     61.261                                 \n",
      " 7    1360.13      69.388     53.125     60.177                                 \n",
      " 8    1287.76      70.000     65.625     67.742                                 \n",
      " 9    1193.71      71.186     65.625     68.293                                 \n",
      "10    1259.71      68.852     65.625     67.200                                 \n",
      "11    1190.79      72.131     68.750     70.400                                 \n",
      "12    1222.92      70.492     67.188     68.800                                 \n",
      "13    1160.43      67.213     64.062     65.600                                 \n",
      "14    1165.51      67.213     64.062     65.600                                 \n",
      "15    1086.70      64.062     64.062     64.062                                 \n",
      "16    1113.51      65.574     62.500     64.000                                 \n",
      "17    1040.96      66.071     57.812     61.667                                 \n",
      "18    1093.67      66.102     60.938     63.415                                 \n",
      "19    1044.10      63.793     57.812     60.656                                 \n",
      "20    1073.29      65.000     60.938     62.903                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.131   68.750    70.400\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.400\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model155.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1548.15      54.762     35.938     43.396                                 \n",
      " 2    1474.25      64.444     45.312     53.211                                 \n",
      " 3    1415.75      71.698     59.375     64.957                                 \n",
      " 4    1411.82      69.492     64.062     66.667                                 \n",
      " 5    1325.54      68.627     54.688     60.870                                 \n",
      " 6    1366.72      66.667     50.000     57.143                                 \n",
      " 7    1348.37      67.308     54.688     60.345                                 \n",
      " 8    1252.10      67.925     56.250     61.538                                 \n",
      " 9    1248.23      68.000     53.125     59.649                                 \n",
      "10    1226.51      68.627     54.688     60.870                                 \n",
      "11    1133.42      68.627     54.688     60.870                                 \n",
      "12    1212.67      68.627     54.688     60.870                                 \n",
      "13    1209.52      68.000     53.125     59.649                                 \n",
      "14    1141.26      69.091     59.375     63.866                                 \n",
      "15    1120.54      68.519     57.812     62.712                                 \n",
      "16    1090.22      69.811     57.812     63.248                                 \n",
      "17    1052.45      71.154     57.812     63.793                                 \n",
      "18    1070.63      70.370     59.375     64.407                                 \n",
      "19    1041.70      70.909     60.938     65.546                                 \n",
      "20    1092.55      69.643     60.938     65.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      69.492   64.062    66.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model166.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1536.93      57.692     46.875     51.724                                 \n",
      " 2    1410.91      56.522     40.625     47.273                                 \n",
      " 3    1433.99      63.934     60.938     62.400                                 \n",
      " 4    1468.00      61.404     54.688     57.851                                 \n",
      " 5    1449.58      61.818     53.125     57.143                                 \n",
      " 6    1442.79      62.000     48.438     54.386                                 \n",
      " 7    1395.36      64.151     53.125     58.120                                 \n",
      " 8    1235.31      62.500     54.688     58.333                                 \n",
      " 9    1256.24      66.038     54.688     59.829                                 \n",
      "10    1201.33      68.627     54.688     60.870                                 \n",
      "11    1151.51      69.811     57.812     63.248                                 \n",
      "12    1253.82      69.841     68.750     69.291                                 \n",
      "13    1270.55      68.852     65.625     67.200                                 \n",
      "14    1153.98      65.517     59.375     62.295                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    1086.22      67.797     62.500     65.041                                 \n",
      "16    1081.04      68.966     62.500     65.574                                 \n",
      "17    1053.39      71.429     62.500     66.667                                 \n",
      "18    1084.77      71.429     62.500     66.667                                 \n",
      "19    1106.04      68.966     62.500     65.574                                 \n",
      "20    1065.52      67.797     62.500     65.041                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      69.841   68.750    69.291\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.291\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model177.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1534.07      70.833     26.562     38.636                                 \n",
      " 2    1369.45      66.667     50.000     57.143                                 \n",
      " 3    1394.77      69.811     57.812     63.248                                 \n",
      " 4    1452.52      64.000     50.000     56.140                                 \n",
      " 5    1475.89      63.462     51.562     56.897                                 \n",
      " 6    1445.58      71.429     62.500     66.667                                 \n",
      " 7    1385.24      60.417     45.312     51.786                                 \n",
      " 8    1282.13      63.265     48.438     54.867                                 \n",
      " 9    1244.65      66.000     51.562     57.895                                 \n",
      "10    1164.81      66.000     51.562     57.895                                 \n",
      "11    1148.62      68.966     62.500     65.574                                 \n",
      "12    1259.69      68.421     60.938     64.463                                 \n",
      "13    1195.99      67.857     59.375     63.333                                 \n",
      "14    1153.09      68.519     57.812     62.712                                 \n",
      "15    1123.18      69.091     59.375     63.866                                 \n",
      "16    1097.37      70.909     60.938     65.546                                 \n",
      "17    1054.26      70.909     60.938     65.546                                 \n",
      "18    1076.10      70.175     62.500     66.116                                 \n",
      "19    1051.69      70.175     62.500     66.116                                 \n",
      "20    1105.81      70.690     64.062     67.213                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.690   64.062    67.213\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.213\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model188.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1574.34      63.636     32.812     43.299                                 \n",
      " 2    1388.41      56.250     42.188     48.214                                 \n",
      " 3    1441.31      63.934     60.938     62.400                                 \n",
      " 4    1446.99      78.261     56.250     65.455                                 \n",
      " 5    1440.63      69.388     53.125     60.177                                 \n",
      " 6    1393.08      75.000     65.625     70.000                                 \n",
      " 7    1348.86      74.138     67.188     70.492                                 \n",
      " 8    1242.61      72.131     68.750     70.400                                 \n",
      " 9    1251.14      66.038     54.688     59.829                                 \n",
      "10    1198.76      73.214     64.062     68.333                                 \n",
      "11    1164.05      70.690     64.062     67.213                                 \n",
      "12    1216.98      71.930     64.062     67.769                                 \n",
      "13    1165.02      70.690     64.062     67.213                                 \n",
      "14    1141.76      70.000     65.625     67.742                                 \n",
      "15    1118.86      69.841     68.750     69.291                                 \n",
      "16    1117.72      70.492     67.188     68.800                                 \n",
      "17    1064.85      70.000     65.625     67.742                                 \n",
      "18    1104.38      68.852     65.625     67.200                                 \n",
      "19    1043.32      70.492     67.188     68.800                                 \n",
      "20    1081.44      69.355     67.188     68.254                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.138   67.188    70.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model199.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1533.41      45.238     29.688     35.849                                 \n",
      " 2    1426.40      58.696     42.188     49.091                                 \n",
      " 3    1474.62      60.000     46.875     52.632                                 \n",
      " 4    1489.01      64.583     48.438     55.357                                 \n",
      " 5    1507.60      68.519     57.812     62.712                                 \n",
      " 6    1310.45      74.000     57.812     64.912                                 \n",
      " 7    1350.66      74.468     54.688     63.063                                 \n",
      " 8    1237.33      74.510     59.375     66.087                                 \n",
      " 9    1168.20      73.585     60.938     66.667                                 \n",
      "10    1237.18      74.545     64.062     68.908                                 \n",
      "11    1158.58      71.698     59.375     64.957                                 \n",
      "12    1256.12      73.077     59.375     65.517                                 \n",
      "13    1179.84      72.000     56.250     63.158                                 \n",
      "14    1109.52      71.429     54.688     61.947                                 \n",
      "15    1107.24      74.074     62.500     67.797                                 \n",
      "16    1129.53      73.077     59.375     65.517                                 \n",
      "17    1025.24      71.154     57.812     63.793                                 \n",
      "18    1097.39      70.588     56.250     62.609                                 \n",
      "19    1053.17      73.077     59.375     65.517                                 \n",
      "20    1118.76      71.698     59.375     64.957                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   64.062    68.908\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.908\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model210.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1538.59      46.341     29.688     36.190                                 \n",
      " 2    1497.52      65.909     45.312     53.704                                 \n",
      " 3    1548.69      62.712     57.812     60.163                                 \n",
      " 4    1467.46      68.966     62.500     65.574                                 \n",
      " 5    1514.45      70.175     62.500     66.116                                 \n",
      " 6    1389.12      75.862     68.750     72.131                                 \n",
      " 7    1354.19      69.355     67.188     68.254                                 \n",
      " 8    1304.19      69.492     64.062     66.667                                 \n",
      " 9    1241.96      70.690     64.062     67.213                                 \n",
      "10    1183.35      69.492     64.062     66.667                                 \n",
      "11    1125.54      68.966     62.500     65.574                                 \n",
      "12    1192.21      68.519     57.812     62.712                                 \n",
      "13    1162.25      65.306     50.000     56.637                                 \n",
      "14    1154.34      69.643     60.938     65.000                                 \n",
      "15    1154.08      68.421     60.938     64.463                                 \n",
      "16    1117.25      69.643     60.938     65.000                                 \n",
      "17    1056.52      68.421     60.938     64.463                                 \n",
      "18    1073.90      71.429     62.500     66.667                                 \n",
      "19    1049.82      70.690     64.062     67.213                                 \n",
      "20    1099.26      71.186     65.625     68.293                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.862   68.750    72.131\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.131\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model221.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1556.19      58.537     37.500     45.714                                 \n",
      " 2    1445.07      63.830     46.875     54.054                                 \n",
      " 3    1430.22      64.815     54.688     59.322                                 \n",
      " 4    1399.56      64.407     59.375     61.789                                 \n",
      " 5    1395.78      64.151     53.125     58.120                                 \n",
      " 6    1403.21      72.881     67.188     69.919                                 \n",
      " 7    1362.20      73.333     68.750     70.968                                 \n",
      " 8    1234.29      75.000     70.312     72.581                                 \n",
      " 9    1252.03      72.881     67.188     69.919                                 \n",
      "10    1210.32      68.333     64.062     66.129                                 \n",
      "11    1168.55      74.138     67.188     70.492                                 \n",
      "12    1205.02      76.364     65.625     70.588                                 \n",
      "13    1195.12      74.138     67.188     70.492                                 \n",
      "14    1140.79      73.333     68.750     70.968                                 \n",
      "15    1115.93      74.576     68.750     71.545                                 \n",
      "16    1109.78      73.684     65.625     69.421                                 \n",
      "17    1035.76      75.000     65.625     70.000                                 \n",
      "18    1070.47      75.862     68.750     72.131                                 \n",
      "19    1044.43      75.862     68.750     72.131                                 \n",
      "20    1110.71      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   70.312    72.581\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.581\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model232.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1539.27      52.273     35.938     42.593                                 \n",
      " 2    1433.36      62.500     54.688     58.333                                 \n",
      " 3    1399.92      63.265     48.438     54.867                                 \n",
      " 4    1434.45      64.000     50.000     56.140                                 \n",
      " 5    1451.77      77.083     57.812     66.071                                 \n",
      " 6    1418.35      71.667     67.188     69.355                                 \n",
      " 7    1376.29      69.492     64.062     66.667                                 \n",
      " 8    1264.11      71.186     65.625     68.293                                 \n",
      " 9    1236.19      72.727     62.500     67.227                                 \n",
      "10    1244.57      71.429     62.500     66.667                                 \n",
      "11    1141.35      71.186     65.625     68.293                                 \n",
      "12    1222.22      70.690     64.062     67.213                                 \n",
      "13    1181.51      70.909     60.938     65.546                                 \n",
      "14    1118.67      67.925     56.250     61.538                                 \n",
      "15    1091.06      68.519     57.812     62.712                                 \n",
      "16    1068.61      68.519     57.812     62.712                                 \n",
      "17    1037.87      69.091     59.375     63.866                                 \n",
      "18    1097.08      69.091     59.375     63.866                                 \n",
      "19    1029.20      67.857     59.375     63.333                                 \n",
      "20    1108.46      66.071     57.812     61.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.667   67.188    69.355\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.355\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model243.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1511.24      72.000     28.125     40.449                                 \n",
      " 2    1438.49      60.784     48.438     53.913                                 \n",
      " 3    1436.51      69.643     60.938     65.000                                 \n",
      " 4    1509.60      66.102     60.938     63.415                                 \n",
      " 5    1540.57      66.129     64.062     65.079                                 \n",
      " 6    1377.66      66.667     53.125     59.130                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7    1324.55      73.684     65.625     69.421                                 \n",
      " 8    1321.93      69.355     67.188     68.254                                 \n",
      " 9    1203.07      69.841     68.750     69.291                                 \n",
      "10    1180.82      70.492     67.188     68.800                                 \n",
      "11    1123.77      69.355     67.188     68.254                                 \n",
      "12    1239.00      69.355     67.188     68.254                                 \n",
      "13    1148.78      68.750     68.750     68.750                                 \n",
      "14    1158.82      67.692     68.750     68.217                                 \n",
      "15    1085.99      68.254     67.188     67.717                                 \n",
      "16    1131.41      67.742     65.625     66.667                                 \n",
      "17    1055.09      70.690     64.062     67.213                                 \n",
      "18    1065.59      71.930     64.062     67.769                                 \n",
      "19    1040.85      71.930     64.062     67.769                                 \n",
      "20    1082.37      70.175     62.500     66.116                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model254.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1547.11      68.182     23.438     34.884                                 \n",
      " 2    1509.08      46.774     45.312     46.032                                 \n",
      " 3    1435.33      64.912     57.812     61.157                                 \n",
      " 4    1477.74      66.071     57.812     61.667                                 \n",
      " 5    1446.98      73.585     60.938     66.667                                 \n",
      " 6    1342.16      75.439     67.188     71.074                                 \n",
      " 7    1339.97      74.545     64.062     68.908                                 \n",
      " 8    1210.88      74.074     62.500     67.797                                 \n",
      " 9    1196.38      69.643     60.938     65.000                                 \n",
      "10    1197.09      72.222     60.938     66.102                                 \n",
      "11    1158.15      72.727     62.500     67.227                                 \n",
      "12    1211.30      73.214     64.062     68.333                                 \n",
      "13    1161.61      72.414     65.625     68.852                                 \n",
      "14    1146.31      71.429     62.500     66.667                                 \n",
      "15    1100.22      71.930     64.062     67.769                                 \n",
      "16    1088.03      71.429     62.500     66.667                                 \n",
      "17    1046.87      73.214     64.062     68.333                                 \n",
      "18    1088.35      72.727     62.500     67.227                                 \n",
      "19    1059.16      71.154     57.812     63.793                                 \n",
      "20    1106.76      69.231     56.250     62.069                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.439   67.188    71.074\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.074\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model265.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1531.88      68.750     34.375     45.833                                 \n",
      " 2    1455.28      58.000     45.312     50.877                                 \n",
      " 3    1453.16      66.667     56.250     61.017                                 \n",
      " 4    1365.60      68.750     51.562     58.929                                 \n",
      " 5    1352.72      68.519     57.812     62.712                                 \n",
      " 6    1373.20      71.930     64.062     67.769                                 \n",
      " 7    1332.78      75.000     65.625     70.000                                 \n",
      " 8    1228.07      74.576     68.750     71.545                                 \n",
      " 9    1188.04      78.846     64.062     70.690                                 \n",
      "10    1230.43      77.358     64.062     70.085                                 \n",
      "11    1159.47      77.358     64.062     70.085                                 \n",
      "12    1242.90      77.778     65.625     71.186                                 \n",
      "13    1162.09      77.778     65.625     71.186                                 \n",
      "14    1151.17      75.926     64.062     69.492                                 \n",
      "15    1105.87      75.926     64.062     69.492                                 \n",
      "16    1085.36      74.545     64.062     68.908                                 \n",
      "17    1060.54      74.545     64.062     68.908                                 \n",
      "18    1091.96      75.000     65.625     70.000                                 \n",
      "19    1054.22      77.778     65.625     71.186                                 \n",
      "20    1098.06      72.414     65.625     68.852                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model276.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.61      51.220     32.812     40.000                                 \n",
      " 2    1443.32      55.319     40.625     46.847                                 \n",
      " 3    1433.40      63.934     60.938     62.400                                 \n",
      " 4    1497.64      64.407     59.375     61.789                                 \n",
      " 5    1443.33      67.925     56.250     61.538                                 \n",
      " 6    1381.04      73.214     64.062     68.333                                 \n",
      " 7    1386.76      71.930     64.062     67.769                                 \n",
      " 8    1230.33      71.930     64.062     67.769                                 \n",
      " 9    1238.10      67.857     59.375     63.333                                 \n",
      "10    1145.51      72.727     62.500     67.227                                 \n",
      "11    1133.79      75.000     65.625     70.000                                 \n",
      "12    1183.54      78.182     67.188     72.269                                 \n",
      "13    1179.29      76.364     65.625     70.588                                 \n",
      "14    1120.10      72.414     65.625     68.852                                 \n",
      "15    1090.31      72.881     67.188     69.919                                 \n",
      "16    1106.72      75.000     65.625     70.000                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    1039.16      75.926     64.062     69.492                                 \n",
      "18    1056.95      77.778     65.625     71.186                                 \n",
      "19    1028.96      75.926     64.062     69.492                                 \n",
      "20    1072.91      75.926     64.062     69.492                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model287.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1483.02      65.714     35.938     46.465                                 \n",
      " 2    1420.33      53.704     45.312     49.153                                 \n",
      " 3    1447.86      67.742     65.625     66.667                                 \n",
      " 4    1348.37      60.714     53.125     56.667                                 \n",
      " 5    1411.98      63.333     59.375     61.290                                 \n",
      " 6    1345.71      61.538     50.000     55.172                                 \n",
      " 7    1355.99      66.667     53.125     59.130                                 \n",
      " 8    1176.75      69.091     59.375     63.866                                 \n",
      " 9    1237.13      65.574     62.500     64.000                                 \n",
      "10    1194.26      65.625     65.625     65.625                                 \n",
      "11    1136.49      65.079     64.062     64.567                                 \n",
      "12    1223.17      66.667     62.500     64.516                                 \n",
      "13    1142.57      68.966     62.500     65.574                                 \n",
      "14    1157.22      70.909     60.938     65.546                                 \n",
      "15    1106.45      74.545     64.062     68.908                                 \n",
      "16    1084.26      73.684     65.625     69.421                                 \n",
      "17    1043.93      72.414     65.625     68.852                                 \n",
      "18    1088.39      75.926     64.062     69.492                                 \n",
      "19    1107.51      74.545     64.062     68.908                                 \n",
      "20    1086.38      74.545     64.062     68.908                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model298.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1487.51      66.667     37.500     48.000                                 \n",
      " 2    1433.38      57.895     51.562     54.545                                 \n",
      " 3    1406.38      66.667     62.500     64.516                                 \n",
      " 4    1390.68      70.690     64.062     67.213                                 \n",
      " 5    1387.24      80.000     68.750     73.950                                 \n",
      " 6    1345.31      80.000     68.750     73.950                                 \n",
      " 7    1358.42      75.862     68.750     72.131                                 \n",
      " 8    1277.19      77.193     68.750     72.727                                 \n",
      " 9    1251.72      72.881     67.188     69.919                                 \n",
      "10    1175.26      75.439     67.188     71.074                                 \n",
      "11    1151.42      78.182     67.188     72.269                                 \n",
      "12    1183.31      75.439     67.188     71.074                                 \n",
      "13    1187.71      75.439     67.188     71.074                                 \n",
      "14    1122.01      77.193     68.750     72.727                                 \n",
      "15    1114.62      78.571     68.750     73.333                                 \n",
      "16    1093.52      78.571     68.750     73.333                                 \n",
      "17    1084.97      77.193     68.750     72.727                                 \n",
      "18    1091.87      75.862     68.750     72.131                                 \n",
      "19    1052.42      76.786     67.188     71.667                                 \n",
      "20    1099.33      74.545     64.062     68.908                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      80.000   68.750    73.950\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.950\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model309.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1502.57      58.537     37.500     45.714                                 \n",
      " 2    1425.32      56.863     45.312     50.435                                 \n",
      " 3    1417.60      68.421     60.938     64.463                                 \n",
      " 4    1379.87      66.667     65.625     66.142                                 \n",
      " 5    1412.00      72.414     65.625     68.852                                 \n",
      " 6    1342.03      71.667     67.188     69.355                                 \n",
      " 7    1324.42      71.186     65.625     68.293                                 \n",
      " 8    1226.64      73.684     65.625     69.421                                 \n",
      " 9    1181.48      72.727     62.500     67.227                                 \n",
      "10    1238.02      72.727     62.500     67.227                                 \n",
      "11    1107.39      72.727     62.500     67.227                                 \n",
      "12    1202.85      70.909     60.938     65.546                                 \n",
      "13    1143.89      71.186     65.625     68.293                                 \n",
      "14    1125.81      70.000     65.625     67.742                                 \n",
      "15    1072.69      70.492     67.188     68.800                                 \n",
      "16    1078.41      72.881     67.188     69.919                                 \n",
      "17    1072.62      72.881     67.188     69.919                                 \n",
      "18    1063.55      70.690     64.062     67.213                                 \n",
      "19    1040.67      73.684     65.625     69.421                                 \n",
      "20    1087.10      76.364     65.625     70.588                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model320.bin\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.47      63.158     37.500     47.059                                 \n",
      " 2    1456.42      52.941     56.250     54.545                                 \n",
      " 3    1476.13      63.333     59.375     61.290                                 \n",
      " 4    1420.24      70.000     65.625     67.742                                 \n",
      " 5    1400.02      73.684     65.625     69.421                                 \n",
      " 6    1311.08      68.333     64.062     66.129                                 \n",
      " 7    1344.93      67.742     65.625     66.667                                 \n",
      " 8    1280.66      62.500     62.500     62.500                                 \n",
      " 9    1193.59      67.241     60.938     63.934                                 \n",
      "10    1220.08      73.684     65.625     69.421                                 \n",
      "11    1168.89      75.472     62.500     68.376                                 \n",
      "12    1197.31      74.074     62.500     67.797                                 \n",
      "13    1170.88      75.472     62.500     68.376                                 \n",
      "14    1139.78      75.472     62.500     68.376                                 \n",
      "15    1089.92      71.154     57.812     63.793                                 \n",
      "16    1076.84      70.588     56.250     62.609                                 \n",
      "17    1018.46      72.000     56.250     63.158                                 \n",
      "18    1058.02      72.000     56.250     63.158                                 \n",
      "19    1055.30      72.549     57.812     64.348                                 \n",
      "20    1067.80      70.588     56.250     62.609                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model331.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1490.35      65.789     39.062     49.020                                 \n",
      " 2    1395.18      60.870     43.750     50.909                                 \n",
      " 3    1421.04      73.214     64.062     68.333                                 \n",
      " 4    1427.42      73.585     60.938     66.667                                 \n",
      " 5    1382.70      71.667     67.188     69.355                                 \n",
      " 6    1334.54      73.684     65.625     69.421                                 \n",
      " 7    1310.78      74.138     67.188     70.492                                 \n",
      " 8    1225.78      72.881     67.188     69.919                                 \n",
      " 9    1178.12      74.074     62.500     67.797                                 \n",
      "10    1150.85      75.472     62.500     68.376                                 \n",
      "11    1130.27      75.926     64.062     69.492                                 \n",
      "12    1221.05      77.778     65.625     71.186                                 \n",
      "13    1173.35      77.778     65.625     71.186                                 \n",
      "14    1117.11      76.364     65.625     70.588                                 \n",
      "15    1087.97      76.364     65.625     70.588                                 \n",
      "16    1102.23      75.000     65.625     70.000                                 \n",
      "17    1041.93      72.881     67.188     69.919                                 \n",
      "18    1079.17      72.881     67.188     69.919                                 \n",
      "19    1024.51      72.881     67.188     69.919                                 \n",
      "20    1070.08      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.778   65.625    71.186\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.186\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model342.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1481.10      72.727     25.000     37.209                                 \n",
      " 2    1464.08      53.846     43.750     48.276                                 \n",
      " 3    1427.63      64.912     57.812     61.157                                 \n",
      " 4    1482.27      64.706     51.562     57.391                                 \n",
      " 5    1358.59      63.636     54.688     58.824                                 \n",
      " 6    1352.92      70.690     64.062     67.213                                 \n",
      " 7    1335.44      68.852     65.625     67.200                                 \n",
      " 8    1242.74      70.000     65.625     67.742                                 \n",
      " 9    1190.13      74.138     67.188     70.492                                 \n",
      "10    1150.73      70.000     65.625     67.742                                 \n",
      "11    1134.71      73.684     65.625     69.421                                 \n",
      "12    1219.12      73.214     64.062     68.333                                 \n",
      "13    1177.08      72.414     65.625     68.852                                 \n",
      "14    1122.20      68.852     65.625     67.200                                 \n",
      "15    1063.67      68.852     65.625     67.200                                 \n",
      "16    1077.28      74.138     67.188     70.492                                 \n",
      "17    1071.54      73.684     65.625     69.421                                 \n",
      "18    1053.13      70.690     64.062     67.213                                 \n",
      "19    1050.98      70.690     64.062     67.213                                 \n",
      "20    1086.36      73.214     64.062     68.333                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.138   67.188    70.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model353.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1476.19      68.000     26.562     38.202                                 \n",
      " 2    1375.13      56.452     54.688     55.556                                 \n",
      " 3    1415.65      66.667     62.500     64.516                                 \n",
      " 4    1474.03      68.519     57.812     62.712                                 \n",
      " 5    1430.99      68.519     57.812     62.712                                 \n",
      " 6    1357.69      67.273     57.812     62.185                                 \n",
      " 7    1320.78      72.549     57.812     64.348                                 \n",
      " 8    1247.09      74.074     62.500     67.797                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9    1184.03      75.439     67.188     71.074                                 \n",
      "10    1189.83      68.852     65.625     67.200                                 \n",
      "11    1143.42      68.852     65.625     67.200                                 \n",
      "12    1221.10      74.576     68.750     71.545                                 \n",
      "13    1219.15      73.214     64.062     68.333                                 \n",
      "14    1151.90      73.214     64.062     68.333                                 \n",
      "15    1118.57      76.364     65.625     70.588                                 \n",
      "16    1111.06      77.778     65.625     71.186                                 \n",
      "17    1048.72      75.472     62.500     68.376                                 \n",
      "18    1047.09      74.545     64.062     68.908                                 \n",
      "19    1051.75      74.545     64.062     68.908                                 \n",
      "20    1129.21      70.909     60.938     65.546                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model364.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1475.85      73.913     26.562     39.080                                 \n",
      " 2    1395.30      60.345     54.688     57.377                                 \n",
      " 3    1466.56      63.492     62.500     62.992                                 \n",
      " 4    1458.31      65.079     64.062     64.567                                 \n",
      " 5    1387.25      69.841     68.750     69.291                                 \n",
      " 6    1399.31      72.881     67.188     69.919                                 \n",
      " 7    1367.27      72.131     68.750     70.400                                 \n",
      " 8    1236.27      72.881     67.188     69.919                                 \n",
      " 9    1206.02      66.667     65.625     66.142                                 \n",
      "10    1152.49      66.154     67.188     66.667                                 \n",
      "11    1122.02      68.254     67.188     67.717                                 \n",
      "12    1203.39      67.647     71.875     69.697                                 \n",
      "13    1164.37      65.672     68.750     67.176                                 \n",
      "14    1100.32      66.667     68.750     67.692                                 \n",
      "15    1088.08      67.164     70.312     68.702                                 \n",
      "16    1098.71      67.188     67.188     67.188                                 \n",
      "17    1070.96      71.429     70.312     70.866                                 \n",
      "18    1063.42      70.769     71.875     71.318                                 \n",
      "19    1025.90      69.697     71.875     70.769                                 \n",
      "20    1108.97      68.657     71.875     70.229                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.769   71.875    71.318\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.318\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model375.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1480.95      64.103     39.062     48.544                                 \n",
      " 2    1440.45      58.000     45.312     50.877                                 \n",
      " 3    1442.34      70.370     59.375     64.407                                 \n",
      " 4    1425.50      76.364     65.625     70.588                                 \n",
      " 5    1400.26      76.786     67.188     71.667                                 \n",
      " 6    1316.36      76.271     70.312     73.171                                 \n",
      " 7    1329.35      72.581     70.312     71.429                                 \n",
      " 8    1263.81      72.131     68.750     70.400                                 \n",
      " 9    1228.54      74.138     67.188     70.492                                 \n",
      "10    1236.07      74.138     67.188     70.492                                 \n",
      "11    1143.11      72.881     67.188     69.919                                 \n",
      "12    1245.40      71.667     67.188     69.355                                 \n",
      "13    1223.82      73.333     68.750     70.968                                 \n",
      "14    1157.58      73.333     68.750     70.968                                 \n",
      "15    1118.46      72.881     67.188     69.919                                 \n",
      "16    1089.57      70.968     68.750     69.841                                 \n",
      "17    1047.15      69.492     64.062     66.667                                 \n",
      "18    1096.20      69.492     64.062     66.667                                 \n",
      "19    1050.15      73.684     65.625     69.421                                 \n",
      "20    1104.31      72.414     65.625     68.852                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.271   70.312    73.171\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.171\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2Kading 'en_core_sci_lg'...\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model386.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1481.04      77.273     26.562     39.535                                 \n",
      " 2    1443.40      56.604     46.875     51.282                                 \n",
      " 3    1417.97      73.214     64.062     68.333                                 \n",
      " 4    1352.21      69.355     67.188     68.254                                 \n",
      " 5    1402.85      66.667     62.500     64.516                                 \n",
      " 6    1313.22      78.571     68.750     73.333                                 \n",
      " 7    1345.62      77.193     68.750     72.727                                 \n",
      " 8    1217.45      76.364     65.625     70.588                                 \n",
      " 9    1176.15      76.786     67.188     71.667                                 \n",
      "10    1161.80      73.684     65.625     69.421                                 \n",
      "11    1109.51      70.492     67.188     68.800                                 \n",
      "12    1203.64      76.364     65.625     70.588                                 \n",
      "13    1168.50      72.881     67.188     69.919                                 \n",
      "14    1149.29      72.881     67.188     69.919                                 \n",
      "15    1099.32      71.186     65.625     68.293                                 \n",
      "16    1098.75      72.881     67.188     69.919                                 \n",
      "17    1038.38      72.881     67.188     69.919                                 \n",
      "18    1073.96      71.186     65.625     68.293                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    1058.22      71.186     65.625     68.293                                 \n",
      "20    1091.36      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.571   68.750    73.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model397.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1477.52      59.574     43.750     50.450                                 \n",
      " 2    1500.55      57.143     56.250     56.693                                 \n",
      " 3    1443.05      65.000     60.938     62.903                                 \n",
      " 4    1407.70      73.214     64.062     68.333                                 \n",
      " 5    1355.74      66.667     59.375     62.810                                 \n",
      " 6    1403.46      76.364     65.625     70.588                                 \n",
      " 7    1333.86      77.193     68.750     72.727                                 \n",
      " 8    1251.28      73.214     64.062     68.333                                 \n",
      " 9    1190.67      71.429     62.500     66.667                                 \n",
      "10    1201.75      68.333     64.062     66.129                                 \n",
      "11    1126.88      74.138     67.188     70.492                                 \n",
      "12    1232.06      76.364     65.625     70.588                                 \n",
      "13    1205.92      74.545     64.062     68.908                                 \n",
      "14    1153.98      75.000     65.625     70.000                                 \n",
      "15    1102.53      75.000     65.625     70.000                                 \n",
      "16    1135.46      77.778     65.625     71.186                                 \n",
      "17    1069.66      76.786     67.188     71.667                                 \n",
      "18    1073.51      74.545     64.062     68.908                                 \n",
      "19    1036.94      76.364     65.625     70.588                                 \n",
      "20    1070.94      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.193   68.750    72.727\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.727\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# run training for a selected models, use every skip_models-th file\n",
    "skip_models = 11\n",
    "abs_models_dir = Path('models/tok2vec_abs_sci_ALL_gpu')\n",
    "\n",
    "models = sorted(os.listdir(abs_models_dir))\n",
    "\n",
    "for idx, model_file in enumerate(models):\n",
    "    if idx % skip_models == 0:\n",
    "        model_path = abs_models_dir / model_file\n",
    "        !prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg \\\n",
    "            --eval-split 0.2 --n-iter 20 --init-tok2vec $model_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
