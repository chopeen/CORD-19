{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.28 (Sat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model: spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_web_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 86 total examples\n",
      "Using 43 train / 43 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2260.23       3.822      5.714      4.580                                 \n",
      " 2     304.20      96.203     72.381     82.609                                 \n",
      " 3      35.94      93.069     89.524     91.262                                 \n",
      " 4       7.71      91.262     89.524     90.385                                 \n",
      " 5       6.89      94.000     89.524     91.707                                 \n",
      " 6       6.26      94.949     89.524     92.157                                 \n",
      " 7       4.15      94.000     89.524     91.707                                 \n",
      " 8      10.58      92.157     89.524     90.821                                 \n",
      " 9       1.78      92.157     89.524     90.821                                 \n",
      "10       0.00      93.069     89.524     91.262                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.949   89.524    92.157\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m92.157\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_28_match/en_rf_web_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_match models/en_core_web_lg_no_ner --output models/2020_03_28_match/en_rf_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model: scispaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 86 total examples\n",
      "Using 43 train / 43 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1864.33       3.333      2.941      3.125                                 \n",
      " 2     303.79      93.902     75.490     83.696                                 \n",
      " 3      22.39      92.784     88.235     90.452                                 \n",
      " 4      17.47      94.792     89.216     91.919                                 \n",
      " 5       5.36      93.814     89.216     91.457                                 \n",
      " 6       6.78      92.857     89.216     91.000                                 \n",
      " 7       6.09      93.814     89.216     91.457                                 \n",
      " 8       4.87      94.792     89.216     91.919                                 \n",
      " 9       9.64      93.814     89.216     91.457                                 \n",
      "10       4.02      94.792     89.216     91.919                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.792   89.216    91.919\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m91.919\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_28_match/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_match models/en_core_sci_lg_no_ner --output models/2020_03_28_match/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.29 (Sun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model trained on Sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "def test_model(model_path):\n",
    "    warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "    \n",
    "    nlp = spacy.load(model_path)\n",
    "    texts = [\n",
    "    \"Known risk factors for the disease are: older age, male gender, diabetes and leukemia. Female patiens and children are less susceptible.\",\n",
    "    \"Diabetes is a known risk factor.\",\n",
    "    \"Leukemia is a risk factor, too.\"\n",
    "    ]\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "\n",
    "        spacy.displacy.render(doc, style='ent', jupyter=True)\n",
    "        pprint([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Known risk factors for the disease are: older \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    age\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    male\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " gender, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " and leukemia. Female patiens and children are less susceptible.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('age', 'RISK_FACTOR'), ('male', 'RISK_FACTOR'), ('diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " is a known risk factor.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Leukemia is a risk factor, too.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_model(\"models/2020_03_28_match/en_rf_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the factors that appeared during the training are detected. _Leukemia_ is **not highlighed** and that means that the NER model did not learn to recognize risk factors based on the sentence structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train new models after the `teach` session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_web_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 393 total examples\n",
      "Using 197 train / 196 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     333.36      89.669     92.735     91.176                                 \n",
      " 2      64.66      92.982     90.598     91.775                                 \n",
      " 3      53.47      94.492     95.299     94.894                                 \n",
      " 4      45.26      94.492     95.299     94.894                                 \n",
      " 5      29.42      94.958     96.581     95.763                                 \n",
      " 6      30.44      96.170     96.581     96.375                                 \n",
      " 7      23.82      95.745     96.154     95.949                                 \n",
      " 8       5.78      95.319     95.726     95.522                                 \n",
      " 9       4.12      95.299     95.299     95.299                                 \n",
      "10       5.46      96.137     95.726     95.931                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      96.170   96.581    96.375\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m96.375\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_29_teach/en_rf_web_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_teach models/en_core_web_lg_no_ner --output models/2020_03_29_teach/en_rf_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 393 total examples\n",
      "Using 197 train / 196 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     289.28      90.991     91.818     91.403                                 \n",
      " 2      54.12      92.237     91.818     92.027                                 \n",
      " 3      84.39      91.593     94.091     92.825                                 \n",
      " 4      46.45      93.213     93.636     93.424                                 \n",
      " 5      19.43      95.000     95.000     95.000                                 \n",
      " 6      15.25      93.665     94.091     93.878                                 \n",
      " 7       4.07      93.363     95.909     94.619                                 \n",
      " 8      11.23      93.722     95.000     94.357                                 \n",
      " 9      10.13      94.595     95.455     95.023                                 \n",
      "10       6.20      94.595     95.455     95.023                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.595   95.455    95.023\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m95.023\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_29_teach/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_teach models/en_core_sci_lg_no_ner --output models/2020_03_29_teach/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Known risk factors for the disease are: older \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    age\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    male gender\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " and leukemia. Female patiens and children are less susceptible.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('age', 'RISK_FACTOR'),\n",
      " ('male gender', 'RISK_FACTOR'),\n",
      " ('diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " is a known risk factor.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Leukemia is a risk factor, too.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_model(\"models/2020_03_29_teach/en_rf_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better model scores, but _leukemia_ still **not detected**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.30 (Mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`strict`)\n",
    "\n",
    "Terms like _male_ or _age_ will only be marked, when they are mentioned in the context of COVID-19 risk factors, i.e. not in articles about animals or children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_abstracts_strict to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 41 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_abstracts_strict\n",
      "Session ID: 2020-03-30_20-24-26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual cord_19_abstracts_strict models/en_core_sci_lg_no_ner data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR --patterns patterns/RF_list_2020.03.17.20037572.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 41 total examples\n",
      "Using 21 train / 20 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1737.49       0.000      0.000      0.000                                 \n",
      " 2      25.99       0.000      0.000      0.000                                 \n",
      " 3     115.63       0.000      0.000      0.000                                 \n",
      " 4      24.86       0.000      0.000      0.000                                 \n",
      " 5      22.36       0.000      0.000      0.000                                 \n",
      " 6      18.33       0.000      0.000      0.000                                 \n",
      " 7      20.52       0.000      0.000      0.000                                 \n",
      " 8      28.45       0.000      0.000      0.000                                 \n",
      " 9      18.38       0.000      0.000      0.000                                 \n",
      "10       7.78       0.000      0.000      0.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR       0.000    0.000     0.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m0.000\u001b[0m\n",
      "Baseline       0.000             \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_30_strict/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_strict models/en_core_sci_lg_no_ner --output models/2020_03_30_strict/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`all RF`)\n",
    "\n",
    "Highlight all risk factors - for any disease or species - but only is sentences that clear say it is a risk factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!prodigy ner.manual cord_19_abstracts_all_rf models/en_core_sci_lg_no_ner data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR --patterns patterns/RF_highlight_factor_phrases.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 58 total examples\n",
      "Using 29 train / 29 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1960.54       0.000      0.000      0.000                                 \n",
      " 2      95.38       0.000      0.000      0.000                                 \n",
      " 3     161.78     100.000      2.128      4.167                                 \n",
      " 4      88.78      40.000      4.255      7.692                                 \n",
      " 5      97.87      33.333      4.255      7.547                                 \n",
      " 6      87.81      37.500      6.383     10.909                                 \n",
      " 7     341.72      25.000      2.128      3.922                                 \n",
      " 8     169.64      40.000      4.255      7.692                                 \n",
      " 9      79.07      30.000      6.383     10.526                                 \n",
      "10     268.87      33.333      6.383     10.714                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      37.500    6.383    10.909\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m10.909\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_30_all_RF/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_abstracts_all_rf models/en_core_sci_lg_no_ner --output models/2020_03_30_all_RF/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "\n",
      "✨  Starting the web server at http://localhost:8081 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 7 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_abstracts_all_rf\n",
      "Session ID: 2020-03-30_22-01-26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.teach cord_19_abstracts_all_rf models/2020_03_30_all_RF/en_rf_sci_lg data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.06 (Mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`RF sentences`)\n",
    "\n",
    "Following the official guide:\n",
    "- https://www.youtube.com/watch?v=59BKHO_xBPA\n",
    "- https://github.com/explosion/projects/tree/master/ner-food-ingredients#data-creation-and-training-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 102 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences\n",
      "Session ID: 2020-04-06_22-08-56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual cord_19_rf_sentences blank:en data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     389.18       0.000      0.000      0.000                                 \n",
      " 2     191.03      25.000      4.000      6.897                                 \n",
      " 3     265.45      35.294     24.000     28.571                                 \n",
      " 4     246.57      28.571     24.000     26.087                                 \n",
      " 5     239.21      22.727     20.000     21.277                                 \n",
      " 6     215.80      42.857     24.000     30.769                                 \n",
      " 7     258.40      42.105     32.000     36.364                                 \n",
      " 8     237.19      50.000     32.000     39.024                                 \n",
      " 9     208.67      62.500     40.000     48.780                                 \n",
      "10     141.30      66.667     40.000     50.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667   40.000    50.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m50.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1421.81       0.000      0.000      0.000                                 \n",
      " 2    1245.16       0.000      0.000      0.000                                 \n",
      " 3    1262.77       0.000      0.000      0.000                                 \n",
      " 4    1249.04       0.000      0.000      0.000                                 \n",
      " 5    1262.46       0.000      0.000      0.000                                 \n",
      " 6    1205.26       0.000      0.000      0.000                                 \n",
      " 7    1137.92       0.000      0.000      0.000                                 \n",
      " 8    1131.84       0.000      0.000      0.000                                 \n",
      " 9    1058.85       0.000      0.000      0.000                                 \n",
      "10    1143.62       0.000      0.000      0.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "GPE               0.000    0.000     0.000\n",
      "RISK_FACTOR       0.000    0.000     0.000\n",
      "CARDINAL          0.000    0.000     0.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m0.000\u001b[0m\n",
      "Baseline       0.000             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⁉️ Why is `en_core_web_lg` producing no results at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     559.17       0.000      0.000      0.000                                 \n",
      " 2     550.33      33.333      8.000     12.903                                 \n",
      " 3     538.43      50.000     24.000     32.432                                 \n",
      " 4     457.89      52.632     40.000     45.455                                 \n",
      " 5     452.06      50.000     36.000     41.860                                 \n",
      " 6     415.01      60.000     48.000     53.333                                 \n",
      " 7     489.45      47.826     44.000     45.833                                 \n",
      " 8     461.13      45.000     36.000     40.000                                 \n",
      " 9     486.03      47.619     40.000     43.478                                 \n",
      "10     406.83      54.545     48.000     51.064                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   48.000    53.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m53.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_06_rf_sentences\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 --output models/2020_04_06_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "embed_rows: 2000 | require_vectors: True | cnn_maxout_pieces: 3 |\n",
      "token_vector_width: 96 | conv_depth: 4 | nr_feature_tokens: 3 |\n",
      "pretrained_vectors: en_vectors_web_lg.vectors\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     339.88       0.000      0.000      0.000                                 \n",
      " 2     199.85      50.000     16.000     24.242                                 \n",
      " 3     128.26      50.000     28.000     35.897                                 \n",
      " 4      76.43      42.857     24.000     30.769                                 \n",
      " 5      63.28      60.000     36.000     45.000                                 \n",
      " 6      29.70      53.333     32.000     40.000                                 \n",
      " 7      21.18      56.250     36.000     43.902                                 \n",
      " 8      36.86      50.000     36.000     41.860                                 \n",
      " 9      13.28      52.941     36.000     42.857                                 \n",
      "10       7.74      52.941     36.000     42.857                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   36.000    45.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m45.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2055.18       0.000      0.000      0.000                                 \n",
      " 2    1808.48       0.000      0.000      0.000                                 \n",
      " 3    1624.76       0.000      0.000      0.000                                 \n",
      " 4    1443.31       0.000      0.000      0.000                                 \n",
      " 5    1652.93       0.000      0.000      0.000                                 \n",
      " 6    1470.22       0.000      0.000      0.000                                 \n",
      " 7    1345.14       0.000      0.000      0.000                                 \n",
      " 8    1403.16      50.000      4.000      7.407                                 \n",
      " 9    1249.90      66.667      8.000     14.286                                 \n",
      "10    1357.22      66.667      8.000     14.286                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667    8.000    14.286\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m14.286\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     536.68       0.000      0.000      0.000                                 \n",
      " 2     631.61       0.000      0.000      0.000                                 \n",
      " 3     539.99      40.000     24.000     30.000                                 \n",
      " 4     505.27      47.619     40.000     43.478                                 \n",
      " 5     508.05      45.000     36.000     40.000                                 \n",
      " 6     461.69      52.941     36.000     42.857                                 \n",
      " 7     473.25      45.000     36.000     40.000                                 \n",
      " 8     571.35      61.111     44.000     51.163                                 \n",
      " 9     465.27      55.556     40.000     46.512                                 \n",
      "10     455.26      43.750     28.000     34.146                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      61.111   44.000    51.163\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m51.163\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔥 Top model so far: `53.333` 🔥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label more data by correcting the model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_rf_sentences_correct to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 220 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences_correct\n",
      "Session ID: 2020-04-06_23-58-48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.correct cord_19_rf_sentences_correct models/2020_04_06_rf_sentences data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR --exclude cord_19_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For futher training, only `en_core_sci_lg` will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1554.25      61.538     37.500     46.602                                 \n",
      " 2    1346.09      64.407     59.375     61.789                                 \n",
      " 3    1407.15      66.667     50.000     57.143                                 \n",
      " 4    1411.73      72.727     50.000     59.259                                 \n",
      " 5    1412.81      73.913     53.125     61.818                                 \n",
      " 6    1319.96      73.913     53.125     61.818                                 \n",
      " 7    1378.05      72.917     54.688     62.500                                 \n",
      " 8    1208.99      72.727     62.500     67.227                                 \n",
      " 9    1177.16      73.077     59.375     65.517                                 \n",
      "10    1211.40      72.549     57.812     64.348                                 \n",
      "11    1142.34      74.510     59.375     66.087                                 \n",
      "12    1196.27      72.000     56.250     63.158                                 \n",
      "13    1153.93      72.000     56.250     63.158                                 \n",
      "14    1149.78      72.549     57.812     64.348                                 \n",
      "15    1154.34      69.231     56.250     62.069                                 \n",
      "16    1104.68      69.231     56.250     62.069                                 \n",
      "17    1062.17      68.627     54.688     60.870                                 \n",
      "18    1063.28      68.627     54.688     60.870                                 \n",
      "19    1048.51      68.627     54.688     60.870                                 \n",
      "20    1120.40      68.627     54.688     60.870                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.727   62.500    67.227\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.227\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1578.16      64.000     25.000     35.955                                 \n",
      " 2    1439.61      55.319     40.625     46.847                                 \n",
      " 3    1528.20      72.222     60.938     66.102                                 \n",
      " 4    1429.18      71.154     57.812     63.793                                 \n",
      " 5    1414.46      69.388     53.125     60.177                                 \n",
      " 6    1344.69      75.472     62.500     68.376                                 \n",
      " 7    1472.62      70.909     60.938     65.546                                 \n",
      " 8    1296.39      74.545     64.062     68.908                                 \n",
      " 9    1285.11      68.966     62.500     65.574                                 \n",
      "10    1236.84      70.175     62.500     66.116                                 \n",
      "11    1181.13      71.429     62.500     66.667                                 \n",
      "12    1235.60      70.909     60.938     65.546                                 \n",
      "13    1238.99      76.923     62.500     68.966                                 \n",
      "14    1151.94      75.926     64.062     69.492                                 \n",
      "15    1151.25      75.926     64.062     69.492                                 \n",
      "16    1218.30      78.000     60.938     68.421                                 \n",
      "17    1074.01      75.926     64.062     69.492                                 \n",
      "18    1121.71      76.364     65.625     70.588                                 \n",
      "19    1084.27      77.358     64.062     70.085                                 \n",
      "20    1106.32      76.471     60.938     67.826                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_07_rf_sentences_corrected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin --output models/2020_04_07_rf_sentences_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.28      62.500     23.438     34.091                                 \n",
      " 2    1397.40      59.091     40.625     48.148                                 \n",
      " 3    1485.47      70.833     53.125     60.714                                 \n",
      " 4    1445.56      68.293     43.750     53.333                                 \n",
      " 5    1431.31      64.000     50.000     56.140                                 \n",
      " 6    1339.87      70.833     53.125     60.714                                 \n",
      " 7    1387.07      72.340     53.125     61.261                                 \n",
      " 8    1232.74      76.596     56.250     64.865                                 \n",
      " 9    1207.39      72.340     53.125     61.261                                 \n",
      "10    1231.53      75.926     64.062     69.492                                 \n",
      "11    1154.22      74.545     64.062     68.908                                 \n",
      "12    1304.76      75.472     62.500     68.376                                 \n",
      "13    1155.21      69.811     57.812     63.248                                 \n",
      "14    1158.97      67.273     57.812     62.185                                 \n",
      "15    1092.88      69.811     57.812     63.248                                 \n",
      "16    1134.04      68.627     54.688     60.870                                 \n",
      "17    1055.42      66.667     56.250     61.017                                 \n",
      "18    1071.15      66.667     56.250     61.017                                 \n",
      "19    1060.90      69.231     56.250     62.069                                 \n",
      "20    1063.32      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model989.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.09 (Thu)\n",
    "## Experiments with new `tok2vec` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1577.68      57.895     34.375     43.137                                 \n",
      " 2    1386.95      67.308     54.688     60.345                                 \n",
      " 3    1455.49      76.596     56.250     64.865                                 \n",
      " 4    1457.04      79.592     60.938     69.027                                 \n",
      " 5    1413.30      78.431     62.500     69.565                                 \n",
      " 6    1351.85      76.923     62.500     68.966                                 \n",
      " 7    1304.38      78.000     60.938     68.421                                 \n",
      " 8    1255.67      76.471     60.938     67.826                                 \n",
      " 9    1219.66      78.431     62.500     69.565                                 \n",
      "10    1203.83      74.545     64.062     68.908                                 \n",
      "11    1125.02      74.545     64.062     68.908                                 \n",
      "12    1224.65      74.074     62.500     67.797                                 \n",
      "13    1173.56      75.000     60.938     67.241                                 \n",
      "14    1170.88      75.000     60.938     67.241                                 \n",
      "15    1074.42      71.154     57.812     63.793                                 \n",
      "16    1144.97      75.000     60.938     67.241                                 \n",
      "17    1041.02      73.077     59.375     65.517                                 \n",
      "18    1094.32      74.510     59.375     66.087                                 \n",
      "19    1051.65      74.510     59.375     66.087                                 \n",
      "20    1099.61      78.000     60.938     68.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.431   62.500    69.565\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.565\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model978_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1630.03      55.556     23.438     32.967                                 \n",
      " 2    1442.41      55.556     46.875     50.847                                 \n",
      " 3    1429.19      65.957     48.438     55.856                                 \n",
      " 4    1467.20      65.455     56.250     60.504                                 \n",
      " 5    1467.20      69.643     60.938     65.000                                 \n",
      " 6    1376.49      67.241     60.938     63.934                                 \n",
      " 7    1324.06      73.585     60.938     66.667                                 \n",
      " 8    1261.74      75.472     62.500     68.376                                 \n",
      " 9    1229.62      77.358     64.062     70.085                                 \n",
      "10    1162.35      74.545     64.062     68.908                                 \n",
      "11    1129.31      72.727     62.500     67.227                                 \n",
      "12    1226.05      73.684     65.625     69.421                                 \n",
      "13    1154.44      73.684     65.625     69.421                                 \n",
      "14    1146.38      69.492     64.062     66.667                                 \n",
      "15    1157.15      70.175     62.500     66.116                                 \n",
      "16    1122.06      72.549     57.812     64.348                                 \n",
      "17    1069.36      70.909     60.938     65.546                                 \n",
      "18    1112.07      71.930     64.062     67.769                                 \n",
      "19    1040.95      70.370     59.375     64.407                                 \n",
      "20    1074.33      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   64.062    70.085\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.085\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model997_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1587.95      62.963     26.562     37.363                                 \n",
      " 2    1500.37      60.784     48.438     53.913                                 \n",
      " 3    1510.36      63.492     62.500     62.992                                 \n",
      " 4    1519.20      60.000     56.250     58.065                                 \n",
      " 5    1521.26      65.574     62.500     64.000                                 \n",
      " 6    1495.73      64.912     57.812     61.157                                 \n",
      " 7    1386.50      65.517     59.375     62.295                                 \n",
      " 8    1225.63      65.574     62.500     64.000                                 \n",
      " 9    1277.40      65.079     64.062     64.567                                 \n",
      "10    1258.71      62.903     60.938     61.905                                 \n",
      "11    1151.32      61.905     60.938     61.417                                 \n",
      "12    1249.35      63.793     57.812     60.656                                 \n",
      "13    1169.56      67.241     60.938     63.934                                 \n",
      "14    1163.40      65.517     59.375     62.295                                 \n",
      "15    1137.84      65.517     59.375     62.295                                 \n",
      "16    1137.22      67.241     60.938     63.934                                 \n",
      "17    1094.24      67.857     59.375     63.333                                 \n",
      "18    1079.29      63.793     57.812     60.656                                 \n",
      "19    1028.63      63.158     56.250     59.504                                 \n",
      "20    1096.86      63.158     56.250     59.504                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.079   64.062    64.567\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.567\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_abs_fil_sci_model975_gpu.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.10 (Fri)\n",
    "## Experiments with new `tok2vec` models (cont.)\n",
    "\n",
    "The Kaggle notebook training models for the full set of abstracts (i.e. `cord_19_abstracts.jsonl`) crashed, so I have only partial results and no loss metrics for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model100.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.29      43.478     31.250     36.364                                 \n",
      " 2    1421.36      59.574     43.750     50.450                                 \n",
      " 3    1486.19      68.519     57.812     62.712                                 \n",
      " 4    1477.14      70.000     54.688     61.404                                 \n",
      " 5    1389.42      73.469     56.250     63.717                                 \n",
      " 6    1377.87      70.000     54.688     61.404                                 \n",
      " 7    1379.27      65.385     53.125     58.621                                 \n",
      " 8    1256.60      64.151     53.125     58.120                                 \n",
      " 9    1242.36      66.038     54.688     59.829                                 \n",
      "10    1237.03      63.636     54.688     58.824                                 \n",
      "11    1130.25      65.385     53.125     58.621                                 \n",
      "12    1249.05      65.455     56.250     60.504                                 \n",
      "13    1186.25      68.519     57.812     62.712                                 \n",
      "14    1166.91      68.519     57.812     62.712                                 \n",
      "15    1119.23      66.071     57.812     61.667                                 \n",
      "16    1100.72      67.925     56.250     61.538                                 \n",
      "17    1057.66      74.576     68.750     71.545                                 \n",
      "18    1086.26      74.138     67.188     70.492                                 \n",
      "19    1057.49      69.841     68.750     69.291                                 \n",
      "20    1090.37      73.684     65.625     69.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model113.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1576.82      54.167     40.625     46.429                                 \n",
      " 2    1441.99      56.522     40.625     47.273                                 \n",
      " 3    1413.20      71.429     62.500     66.667                                 \n",
      " 4    1530.83      68.519     57.812     62.712                                 \n",
      " 5    1508.39      70.968     68.750     69.841                                 \n",
      " 6    1418.20      71.930     64.062     67.769                                 \n",
      " 7    1390.90      74.576     68.750     71.545                                 \n",
      " 8    1306.18      69.492     64.062     66.667                                 \n",
      " 9    1288.81      69.355     67.188     68.254                                 \n",
      "10    1235.70      67.692     68.750     68.217                                 \n",
      "11    1176.14      68.852     65.625     67.200                                 \n",
      "12    1225.75      71.186     65.625     68.293                                 \n",
      "13    1223.52      71.186     65.625     68.293                                 \n",
      "14    1144.79      70.370     59.375     64.407                                 \n",
      "15    1097.53      71.429     62.500     66.667                                 \n",
      "16    1107.15      71.429     62.500     66.667                                 \n",
      "17    1077.94      69.643     60.938     65.000                                 \n",
      "18    1110.78      72.222     60.938     66.102                                 \n",
      "19    1034.04      71.698     59.375     64.957                                 \n",
      "20    1096.63      71.429     62.500     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model126.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1606.39      43.636     37.500     40.336                                 \n",
      " 2    1452.80      60.000     51.562     55.462                                 \n",
      " 3    1437.93      59.677     57.812     58.730                                 \n",
      " 4    1419.75      63.043     45.312     52.727                                 \n",
      " 5    1400.15      67.925     56.250     61.538                                 \n",
      " 6    1396.64      68.750     51.562     58.929                                 \n",
      " 7    1385.28      66.667     59.375     62.810                                 \n",
      " 8    1260.33      66.667     59.375     62.810                                 \n",
      " 9    1228.95      69.231     56.250     62.069                                 \n",
      "10    1247.29      66.667     56.250     61.017                                 \n",
      "11    1176.21      66.102     60.938     63.415                                 \n",
      "12    1288.26      66.667     59.375     62.810                                 \n",
      "13    1179.91      69.091     59.375     63.866                                 \n",
      "14    1154.00      70.175     62.500     66.116                                 \n",
      "15    1152.69      68.966     62.500     65.574                                 \n",
      "16    1109.37      68.966     62.500     65.574                                 \n",
      "17    1050.43      67.857     59.375     63.333                                 \n",
      "18    1085.32      68.421     60.938     64.463                                 \n",
      "19    1029.84      64.706     51.562     57.391                                 \n",
      "20    1096.32      67.347     51.562     58.407                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.175   62.500    66.116\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.116\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model139.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1563.29      51.020     39.062     44.248                                 \n",
      " 2    1501.66      58.333     43.750     50.000                                 \n",
      " 3    1542.60      67.188     67.188     67.188                                 \n",
      " 4    1474.47      72.222     60.938     66.102                                 \n",
      " 5    1509.19      75.000     56.250     64.286                                 \n",
      " 6    1413.26      68.000     53.125     59.649                                 \n",
      " 7    1335.99      68.627     54.688     60.870                                 \n",
      " 8    1413.31      64.706     51.562     57.391                                 \n",
      " 9    1186.98      66.667     56.250     61.017                                 \n",
      "10    1248.32      69.231     56.250     62.069                                 \n",
      "11    1140.08      69.388     53.125     60.177                                 \n",
      "12    1236.78      68.750     51.562     58.929                                 \n",
      "13    1175.07      65.385     53.125     58.621                                 \n",
      "14    1142.11      65.385     53.125     58.621                                 \n",
      "15    1129.54      66.038     54.688     59.829                                 \n",
      "16    1106.93      68.750     51.562     58.929                                 \n",
      "17    1070.87      70.213     51.562     59.459                                 \n",
      "18    1088.39      70.213     51.562     59.459                                 \n",
      "19    1034.52      70.213     51.562     59.459                                 \n",
      "20    1128.90      68.750     51.562     58.929                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      67.188   67.188    67.188\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.188\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model152.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1571.39      58.140     39.062     46.729                                 \n",
      " 2    1510.07      60.000     46.875     52.632                                 \n",
      " 3    1489.39      72.917     54.688     62.500                                 \n",
      " 4    1469.38      69.643     60.938     65.000                                 \n",
      " 5    1444.18      70.833     53.125     60.714                                 \n",
      " 6    1500.48      68.085     50.000     57.658                                 \n",
      " 7    1316.60      68.085     50.000     57.658                                 \n",
      " 8    1286.18      68.750     51.562     58.929                                 \n",
      " 9    1264.42      71.429     54.688     61.947                                 \n",
      "10    1190.15      73.913     53.125     61.818                                 \n",
      "11    1131.21      75.510     57.812     65.487                                 \n",
      "12    1242.04      76.923     62.500     68.966                                 \n",
      "13    1185.61      72.340     53.125     61.261                                 \n",
      "14    1145.75      72.340     53.125     61.261                                 \n",
      "15    1116.77      75.472     62.500     68.376                                 \n",
      "16    1116.36      75.472     62.500     68.376                                 \n",
      "17    1059.02      73.585     60.938     66.667                                 \n",
      "18    1068.08      73.585     60.938     66.667                                 \n",
      "19    1059.03      75.472     62.500     68.376                                 \n",
      "20    1074.62      75.000     60.938     67.241                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.923   62.500    68.966\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.966\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model165.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1547.07      74.194     35.938     48.421                                 \n",
      " 2    1462.56      62.069     56.250     59.016                                 \n",
      " 3    1496.71      70.690     64.062     67.213                                 \n",
      " 4    1449.38      74.074     62.500     67.797                                 \n",
      " 5    1418.87      77.358     64.062     70.085                                 \n",
      " 6    1337.26      75.926     64.062     69.492                                 \n",
      " 7    1383.02      72.414     65.625     68.852                                 \n",
      " 8    1291.23      68.852     65.625     67.200                                 \n",
      " 9    1266.25      71.186     65.625     68.293                                 \n",
      "10    1185.12      69.355     67.188     68.254                                 \n",
      "11    1158.02      72.881     67.188     69.919                                 \n",
      "12    1188.67      73.333     68.750     70.968                                 \n",
      "13    1160.96      73.214     64.062     68.333                                 \n",
      "14    1138.56      71.930     64.062     67.769                                 \n",
      "15    1126.51      72.881     67.188     69.919                                 \n",
      "16    1089.93      71.186     65.625     68.293                                 \n",
      "17    1036.84      70.175     62.500     66.116                                 \n",
      "18    1102.04      69.643     60.938     65.000                                 \n",
      "19    1049.66      69.643     60.938     65.000                                 \n",
      "20    1071.79      68.421     60.938     64.463                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.333   68.750    70.968\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.968\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2Kading 'en_core_sci_lg'...\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model178.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1548.43      60.976     39.062     47.619                                 \n",
      " 2    1396.43      63.043     45.312     52.727                                 \n",
      " 3    1488.35      68.085     50.000     57.658                                 \n",
      " 4    1412.67      69.565     50.000     58.182                                 \n",
      " 5    1416.63      65.957     48.438     55.856                                 \n",
      " 6    1373.68      71.111     50.000     58.716                                 \n",
      " 7    1388.35      75.472     62.500     68.376                                 \n",
      " 8    1260.08      69.388     53.125     60.177                                 \n",
      " 9    1297.26      71.429     54.688     61.947                                 \n",
      "10    1221.41      71.429     54.688     61.947                                 \n",
      "11    1112.34      76.364     65.625     70.588                                 \n",
      "12    1259.60      67.857     59.375     63.333                                 \n",
      "13    1150.64      66.071     57.812     61.667                                 \n",
      "14    1120.27      67.308     54.688     60.345                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    1143.57      69.231     56.250     62.069                                 \n",
      "16    1108.60      69.091     59.375     63.866                                 \n",
      "17    1037.24      66.667     59.375     62.810                                 \n",
      "18    1059.90      67.857     59.375     63.333                                 \n",
      "19    1029.31      65.517     59.375     62.295                                 \n",
      "20    1091.05      67.797     62.500     65.041                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model191.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1531.35      54.839     26.562     35.789                                 \n",
      " 2    1411.43      65.909     45.312     53.704                                 \n",
      " 3    1398.77      67.391     48.438     56.364                                 \n",
      " 4    1362.76      66.667     56.250     61.017                                 \n",
      " 5    1381.48      70.909     60.938     65.546                                 \n",
      " 6    1355.07      76.364     65.625     70.588                                 \n",
      " 7    1335.37      73.585     60.938     66.667                                 \n",
      " 8    1285.76      68.750     51.562     58.929                                 \n",
      " 9    1227.28      77.778     65.625     71.186                                 \n",
      "10    1201.31      78.182     67.188     72.269                                 \n",
      "11    1149.59      73.469     56.250     63.717                                 \n",
      "12    1275.63      73.469     56.250     63.717                                 \n",
      "13    1207.65      76.364     65.625     70.588                                 \n",
      "14    1130.14      74.576     68.750     71.545                                 \n",
      "15    1099.09      71.186     65.625     68.293                                 \n",
      "16    1126.79      70.690     64.062     67.213                                 \n",
      "17    1046.66      71.930     64.062     67.769                                 \n",
      "18    1065.97      71.186     65.625     68.293                                 \n",
      "19    1034.82      72.414     65.625     68.852                                 \n",
      "20    1099.55      72.414     65.625     68.852                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model204.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1559.76      60.606     31.250     41.237                                 \n",
      " 2    1453.45      50.820     48.438     49.600                                 \n",
      " 3    1409.66      65.079     64.062     64.567                                 \n",
      " 4    1475.36      73.684     65.625     69.421                                 \n",
      " 5    1361.59      71.186     65.625     68.293                                 \n",
      " 6    1355.81      71.186     65.625     68.293                                 \n",
      " 7    1318.82      73.585     60.938     66.667                                 \n",
      " 8    1249.84      68.627     54.688     60.870                                 \n",
      " 9    1261.36      71.667     67.188     69.355                                 \n",
      "10    1192.93      70.690     64.062     67.213                                 \n",
      "11    1132.25      71.667     67.188     69.355                                 \n",
      "12    1208.10      68.333     64.062     66.129                                 \n",
      "13    1172.95      67.213     64.062     65.600                                 \n",
      "14    1127.60      71.930     64.062     67.769                                 \n",
      "15    1129.79      68.852     65.625     67.200                                 \n",
      "16    1101.97      71.186     65.625     68.293                                 \n",
      "17    1044.06      72.414     65.625     68.852                                 \n",
      "18    1063.17      73.684     65.625     69.421                                 \n",
      "19    1053.16      70.175     62.500     66.116                                 \n",
      "20    1088.13      69.643     60.938     65.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model217.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1588.40      50.000     34.375     40.741                                 \n",
      " 2    1381.86      64.444     45.312     53.211                                 \n",
      " 3    1377.05      72.549     57.812     64.348                                 \n",
      " 4    1447.86      79.592     60.938     69.027                                 \n",
      " 5    1434.80      77.193     68.750     72.727                                 \n",
      " 6    1396.29      76.667     71.875     74.194                                 \n",
      " 7    1305.60      76.667     71.875     74.194                                 \n",
      " 8    1262.80      71.429     70.312     70.866                                 \n",
      " 9    1177.84      69.231     70.312     69.767                                 \n",
      "10    1187.94      71.186     65.625     68.293                                 \n",
      "11    1123.51      71.930     64.062     67.769                                 \n",
      "12    1221.49      70.690     64.062     67.213                                 \n",
      "13    1162.42      73.214     64.062     68.333                                 \n",
      "14    1143.42      73.585     60.938     66.667                                 \n",
      "15    1102.69      69.643     60.938     65.000                                 \n",
      "16    1078.37      70.909     60.938     65.546                                 \n",
      "17    1052.39      72.222     60.938     66.102                                 \n",
      "18    1064.30      74.545     64.062     68.908                                 \n",
      "19    1045.06      74.545     64.062     68.908                                 \n",
      "20    1089.94      73.214     64.062     68.333                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.667   71.875    74.194\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.194\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model230.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1537.49      65.714     35.938     46.465                                 \n",
      " 2    1506.48      51.064     37.500     43.243                                 \n",
      " 3    1436.09      68.627     54.688     60.870                                 \n",
      " 4    1438.86      67.925     56.250     61.538                                 \n",
      " 5    1471.17      58.730     57.812     58.268                                 \n",
      " 6    1395.94      76.786     67.188     71.667                                 \n",
      " 7    1329.15      71.186     65.625     68.293                                 \n",
      " 8    1224.20      70.000     65.625     67.742                                 \n",
      " 9    1212.04      72.222     60.938     66.102                                 \n",
      "10    1220.04      74.074     62.500     67.797                                 \n",
      "11    1146.63      77.358     64.062     70.085                                 \n",
      "12    1201.44      78.846     64.062     70.690                                 \n",
      "13    1193.53      73.214     64.062     68.333                                 \n",
      "14    1151.32      73.214     64.062     68.333                                 \n",
      "15    1174.86      72.414     65.625     68.852                                 \n",
      "16    1132.91      75.000     65.625     70.000                                 \n",
      "17    1062.43      73.684     65.625     69.421                                 \n",
      "18    1104.23      74.545     64.062     68.908                                 \n",
      "19    1082.55      73.214     64.062     68.333                                 \n",
      "20    1089.93      71.930     64.062     67.769                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.786   67.188    71.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model243.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1511.24      72.000     28.125     40.449                                 \n",
      " 2    1438.49      60.784     48.438     53.913                                 \n",
      " 3    1436.51      69.643     60.938     65.000                                 \n",
      " 4    1509.60      66.102     60.938     63.415                                 \n",
      " 5    1540.57      66.129     64.062     65.079                                 \n",
      " 6    1377.66      66.667     53.125     59.130                                 \n",
      " 7    1324.55      73.684     65.625     69.421                                 \n",
      " 8    1321.93      69.355     67.188     68.254                                 \n",
      " 9    1203.07      69.841     68.750     69.291                                 \n",
      "10    1180.82      70.492     67.188     68.800                                 \n",
      "11    1123.77      69.355     67.188     68.254                                 \n",
      "12    1239.00      69.355     67.188     68.254                                 \n",
      "13    1148.78      68.750     68.750     68.750                                 \n",
      "14    1158.82      67.692     68.750     68.217                                 \n",
      "15    1085.99      68.254     67.188     67.717                                 \n",
      "16    1131.41      67.742     65.625     66.667                                 \n",
      "17    1055.09      70.690     64.062     67.213                                 \n",
      "18    1065.59      71.930     64.062     67.769                                 \n",
      "19    1040.85      71.930     64.062     67.769                                 \n",
      "20    1082.37      70.175     62.500     66.116                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model256.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1545.08      58.621     26.562     36.559                                 \n",
      " 2    1419.43      62.745     50.000     55.652                                 \n",
      " 3    1450.36      73.214     64.062     68.333                                 \n",
      " 4    1400.91      70.690     64.062     67.213                                 \n",
      " 5    1412.40      70.588     56.250     62.609                                 \n",
      " 6    1341.37      74.000     57.812     64.912                                 \n",
      " 7    1343.98      70.833     53.125     60.714                                 \n",
      " 8    1292.65      71.111     50.000     58.716                                 \n",
      " 9    1179.34      69.565     50.000     58.182                                 \n",
      "10    1247.50      70.213     51.562     59.459                                 \n",
      "11    1175.39      70.833     53.125     60.714                                 \n",
      "12    1229.61      75.472     62.500     68.376                                 \n",
      "13    1182.13      74.545     64.062     68.908                                 \n",
      "14    1167.71      72.222     60.938     66.102                                 \n",
      "15    1113.38      70.370     59.375     64.407                                 \n",
      "16    1094.86      74.074     62.500     67.797                                 \n",
      "17    1076.16      69.091     59.375     63.866                                 \n",
      "18    1109.22      62.500     46.875     53.571                                 \n",
      "19    1060.25      63.830     46.875     54.054                                 \n",
      "20    1087.38      63.830     46.875     54.054                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   64.062    68.908\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.908\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model269.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1520.36      78.947     23.438     36.145                                 \n",
      " 2    1397.99      65.574     62.500     64.000                                 \n",
      " 3    1442.61      75.000     65.625     70.000                                 \n",
      " 4    1391.94      71.698     59.375     64.957                                 \n",
      " 5    1394.91      71.930     64.062     67.769                                 \n",
      " 6    1356.89      68.421     60.938     64.463                                 \n",
      " 7    1364.08      69.231     56.250     62.069                                 \n",
      " 8    1270.54      71.698     59.375     64.957                                 \n",
      " 9    1203.23      70.909     60.938     65.546                                 \n",
      "10    1188.31      66.667     62.500     64.516                                 \n",
      "11    1153.89      69.492     64.062     66.667                                 \n",
      "12    1197.13      69.492     64.062     66.667                                 \n",
      "13    1194.79      71.698     59.375     64.957                                 \n",
      "14    1113.36      72.727     62.500     67.227                                 \n",
      "15    1105.46      73.585     60.938     66.667                                 \n",
      "16    1116.92      73.077     59.375     65.517                                 \n",
      "17    1031.77      74.510     59.375     66.087                                 \n",
      "18    1073.23      73.077     59.375     65.517                                 \n",
      "19    1062.78      71.698     59.375     64.957                                 \n",
      "20    1108.77      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   65.625    70.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model282.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1475.57      73.529     39.062     51.020                                 \n",
      " 2    1444.66      61.538     50.000     55.172                                 \n",
      " 3    1397.05      65.306     50.000     56.637                                 \n",
      " 4    1422.26      63.265     48.438     54.867                                 \n",
      " 5    1386.09      68.421     60.938     64.463                                 \n",
      " 6    1353.86      76.923     62.500     68.966                                 \n",
      " 7    1395.51      70.690     64.062     67.213                                 \n",
      " 8    1243.82      75.472     62.500     68.376                                 \n",
      " 9    1247.40      70.492     67.188     68.800                                 \n",
      "10    1174.12      72.414     65.625     68.852                                 \n",
      "11    1156.15      73.684     65.625     69.421                                 \n",
      "12    1239.20      73.214     64.062     68.333                                 \n",
      "13    1186.23      71.930     64.062     67.769                                 \n",
      "14    1136.16      71.930     64.062     67.769                                 \n",
      "15    1090.41      68.333     64.062     66.129                                 \n",
      "16    1081.16      67.797     62.500     65.041                                 \n",
      "17    1064.12      67.213     64.062     65.600                                 \n",
      "18    1071.57      66.667     65.625     66.142                                 \n",
      "19    1029.70      67.742     65.625     66.667                                 \n",
      "20    1097.97      66.667     62.500     64.516                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model295.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1523.41      65.517     29.688     40.860                                 \n",
      " 2    1468.56      58.824     46.875     52.174                                 \n",
      " 3    1469.97      65.306     50.000     56.637                                 \n",
      " 4    1435.29      66.667     53.125     59.130                                 \n",
      " 5    1517.71      66.667     53.125     59.130                                 \n",
      " 6    1426.38      78.182     67.188     72.269                                 \n",
      " 7    1363.57      74.545     64.062     68.908                                 \n",
      " 8    1204.75      72.131     68.750     70.400                                 \n",
      " 9    1215.02      70.000     65.625     67.742                                 \n",
      "10    1153.08      72.000     56.250     63.158                                 \n",
      "11    1153.13      75.000     65.625     70.000                                 \n",
      "12    1206.34      75.000     65.625     70.000                                 \n",
      "13    1186.23      74.074     62.500     67.797                                 \n",
      "14    1124.83      73.585     60.938     66.667                                 \n",
      "15    1125.46      72.727     62.500     67.227                                 \n",
      "16    1111.84      74.545     64.062     68.908                                 \n",
      "17    1060.41      75.000     65.625     70.000                                 \n",
      "18    1056.05      75.439     67.188     71.074                                 \n",
      "19    1054.58      75.439     67.188     71.074                                 \n",
      "20    1097.81      77.778     65.625     71.186                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model308.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.02      61.905     40.625     49.057                                 \n",
      " 2    1389.84      56.897     51.562     54.098                                 \n",
      " 3    1485.12      71.698     59.375     64.957                                 \n",
      " 4    1385.46      70.175     62.500     66.116                                 \n",
      " 5    1455.78      72.727     62.500     67.227                                 \n",
      " 6    1404.07      78.947     70.312     74.380                                 \n",
      " 7    1323.94      81.818     70.312     75.630                                 \n",
      " 8    1229.71      75.862     68.750     72.131                                 \n",
      " 9    1211.78      77.966     71.875     74.797                                 \n",
      "10    1249.24      76.786     67.188     71.667                                 \n",
      "11    1124.41      76.786     67.188     71.667                                 \n",
      "12    1227.59      75.926     64.062     69.492                                 \n",
      "13    1188.04      71.429     62.500     66.667                                 \n",
      "14    1126.55      77.358     64.062     70.085                                 \n",
      "15    1136.49      77.358     64.062     70.085                                 \n",
      "16    1146.76      78.431     62.500     69.565                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    1045.76      74.545     64.062     68.908                                 \n",
      "18    1047.72      74.545     64.062     68.908                                 \n",
      "19    1039.92      76.786     67.188     71.667                                 \n",
      "20    1076.51      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.818   70.312    75.630\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.630\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model321.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1510.93      68.421     40.625     50.980                                 \n",
      " 2    1444.88      54.545     46.875     50.420                                 \n",
      " 3    1377.60      68.519     57.812     62.712                                 \n",
      " 4    1388.17      70.690     64.062     67.213                                 \n",
      " 5    1384.22      70.968     68.750     69.841                                 \n",
      " 6    1382.66      70.968     68.750     69.841                                 \n",
      " 7    1300.98      69.355     67.188     68.254                                 \n",
      " 8    1268.51      65.000     60.938     62.903                                 \n",
      " 9    1194.28      68.333     64.062     66.129                                 \n",
      "10    1182.41      72.881     67.188     69.919                                 \n",
      "11    1179.37      75.926     64.062     69.492                                 \n",
      "12    1226.69      71.930     64.062     67.769                                 \n",
      "13    1214.25      70.690     64.062     67.213                                 \n",
      "14    1115.74      71.930     64.062     67.769                                 \n",
      "15    1076.93      70.000     65.625     67.742                                 \n",
      "16    1106.47      72.881     67.188     69.919                                 \n",
      "17    1046.70      72.881     67.188     69.919                                 \n",
      "18    1060.13      71.667     67.188     69.355                                 \n",
      "19    1050.26      71.667     67.188     69.355                                 \n",
      "20    1090.53      71.667     67.188     69.355                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.881   67.188    69.919\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.919\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model334.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1483.42      67.647     35.938     46.939                                 \n",
      " 2    1437.08      51.613     50.000     50.794                                 \n",
      " 3    1444.43      75.472     62.500     68.376                                 \n",
      " 4    1379.16      70.370     59.375     64.407                                 \n",
      " 5    1422.62      80.000     62.500     70.175                                 \n",
      " 6    1320.15      79.630     67.188     72.881                                 \n",
      " 7    1373.90      79.310     71.875     75.410                                 \n",
      " 8    1283.61      75.862     68.750     72.131                                 \n",
      " 9    1215.63      79.630     67.188     72.881                                 \n",
      "10    1176.07      76.364     65.625     70.588                                 \n",
      "11    1140.37      78.182     67.188     72.269                                 \n",
      "12    1217.24      78.571     68.750     73.333                                 \n",
      "13    1203.73      78.182     67.188     72.269                                 \n",
      "14    1205.44      79.630     67.188     72.881                                 \n",
      "15    1122.55      81.132     67.188     73.504                                 \n",
      "16    1127.57      81.132     67.188     73.504                                 \n",
      "17    1093.40      82.692     67.188     74.138                                 \n",
      "18    1059.69      81.481     68.750     74.576                                 \n",
      "19    1052.47      78.182     67.188     72.269                                 \n",
      "20    1074.00      75.000     70.312     72.581                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.310   71.875    75.410\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.410\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model347.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1491.38      73.077     29.688     42.222                                 \n",
      " 2    1383.10      54.098     51.562     52.800                                 \n",
      " 3    1424.20      67.857     59.375     63.333                                 \n",
      " 4    1404.94      71.154     57.812     63.793                                 \n",
      " 5    1405.28      68.254     67.188     67.717                                 \n",
      " 6    1394.99      77.778     65.625     71.186                                 \n",
      " 7    1317.99      74.138     67.188     70.492                                 \n",
      " 8    1188.57      65.517     59.375     62.295                                 \n",
      " 9    1200.68      68.333     64.062     66.129                                 \n",
      "10    1172.03      67.742     65.625     66.667                                 \n",
      "11    1117.81      67.742     65.625     66.667                                 \n",
      "12    1173.13      68.421     60.938     64.463                                 \n",
      "13    1186.30      68.421     60.938     64.463                                 \n",
      "14    1122.39      68.421     60.938     64.463                                 \n",
      "15    1108.01      68.966     62.500     65.574                                 \n",
      "16    1117.94      72.414     65.625     68.852                                 \n",
      "17    1022.12      70.690     64.062     67.213                                 \n",
      "18    1066.09      70.690     64.062     67.213                                 \n",
      "19    1051.72      71.930     64.062     67.769                                 \n",
      "20    1075.17      71.429     62.500     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.778   65.625    71.186\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.186\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model360.bin\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1483.42      63.415     40.625     49.524                                 \n",
      " 2    1529.89      60.000     60.938     60.465                                 \n",
      " 3    1444.98      66.154     67.188     66.667                                 \n",
      " 4    1448.20      68.421     60.938     64.463                                 \n",
      " 5    1388.45      67.692     68.750     68.217                                 \n",
      " 6    1309.81      65.574     62.500     64.000                                 \n",
      " 7    1318.09      68.852     65.625     67.200                                 \n",
      " 8    1223.92      66.667     65.625     66.142                                 \n",
      " 9    1219.50      68.254     67.188     67.717                                 \n",
      "10    1226.45      68.182     70.312     69.231                                 \n",
      "11    1153.58      72.581     70.312     71.429                                 \n",
      "12    1213.61      71.667     67.188     69.355                                 \n",
      "13    1173.91      69.492     64.062     66.667                                 \n",
      "14    1163.38      71.429     62.500     66.667                                 \n",
      "15    1121.68      69.492     64.062     66.667                                 \n",
      "16    1092.13      68.333     64.062     66.129                                 \n",
      "17    1037.37      69.492     64.062     66.667                                 \n",
      "18    1069.78      72.727     62.500     67.227                                 \n",
      "19    1053.63      74.074     62.500     67.797                                 \n",
      "20    1091.28      74.074     62.500     67.797                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.581   70.312    71.429\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.429\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model373.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1479.95      80.000     25.000     38.095                                 \n",
      " 2    1463.46      58.621     53.125     55.738                                 \n",
      " 3    1436.31      70.769     71.875     71.318                                 \n",
      " 4    1401.12      67.742     65.625     66.667                                 \n",
      " 5    1463.03      71.429     62.500     66.667                                 \n",
      " 6    1367.25      71.930     64.062     67.769                                 \n",
      " 7    1305.11      73.684     65.625     69.421                                 \n",
      " 8    1319.25      75.439     67.188     71.074                                 \n",
      " 9    1279.53      69.355     67.188     68.254                                 \n",
      "10    1179.43      68.254     67.188     67.717                                 \n",
      "11    1149.79      70.000     65.625     67.742                                 \n",
      "12    1195.89      71.930     64.062     67.769                                 \n",
      "13    1183.69      72.727     62.500     67.227                                 \n",
      "14    1125.26      72.727     62.500     67.227                                 \n",
      "15    1092.42      73.214     64.062     68.333                                 \n",
      "16    1110.40      75.000     65.625     70.000                                 \n",
      "17    1055.49      76.364     65.625     70.588                                 \n",
      "18    1082.35      74.545     64.062     68.908                                 \n",
      "19    1032.87      74.074     62.500     67.797                                 \n",
      "20    1095.61      74.545     64.062     68.908                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.769   71.875    71.318\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.318\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model386.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1481.04      77.273     26.562     39.535                                 \n",
      " 2    1443.40      56.604     46.875     51.282                                 \n",
      " 3    1417.97      73.214     64.062     68.333                                 \n",
      " 4    1352.21      69.355     67.188     68.254                                 \n",
      " 5    1402.85      66.667     62.500     64.516                                 \n",
      " 6    1313.22      78.571     68.750     73.333                                 \n",
      " 7    1345.62      77.193     68.750     72.727                                 \n",
      " 8    1217.45      76.364     65.625     70.588                                 \n",
      " 9    1176.15      76.786     67.188     71.667                                 \n",
      "10    1161.80      73.684     65.625     69.421                                 \n",
      "11    1109.51      70.492     67.188     68.800                                 \n",
      "12    1203.64      76.364     65.625     70.588                                 \n",
      "13    1168.50      72.881     67.188     69.919                                 \n",
      "14    1149.29      72.881     67.188     69.919                                 \n",
      "15    1099.32      71.186     65.625     68.293                                 \n",
      "16    1098.75      72.881     67.188     69.919                                 \n",
      "17    1038.38      72.881     67.188     69.919                                 \n",
      "18    1073.96      71.186     65.625     68.293                                 \n",
      "19    1058.22      71.186     65.625     68.293                                 \n",
      "20    1091.36      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.571   68.750    73.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model399.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1472.05      57.778     40.625     47.706                                 \n",
      " 2    1449.91      58.000     45.312     50.877                                 \n",
      " 3    1394.46      72.340     53.125     61.261                                 \n",
      " 4    1452.94      67.273     57.812     62.185                                 \n",
      " 5    1429.51      71.186     65.625     68.293                                 \n",
      " 6    1354.91      76.364     65.625     70.588                                 \n",
      " 7    1337.65      74.576     68.750     71.545                                 \n",
      " 8    1283.85      73.333     68.750     70.968                                 \n",
      " 9    1201.50      72.131     68.750     70.400                                 \n",
      "10    1195.83      70.690     64.062     67.213                                 \n",
      "11    1139.20      71.930     64.062     67.769                                 \n",
      "12    1221.27      70.175     62.500     66.116                                 \n",
      "13    1194.65      71.930     64.062     67.769                                 \n",
      "14    1123.81      71.930     64.062     67.769                                 \n",
      "15    1102.07      74.545     64.062     68.908                                 \n",
      "16    1086.01      75.439     67.188     71.074                                 \n",
      "17    1045.85      75.000     65.625     70.000                                 \n",
      "18    1073.74      75.000     65.625     70.000                                 \n",
      "19    1055.08      75.439     67.188     71.074                                 \n",
      "20    1070.98      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# run training for a selected models, use every skip_models-th file\n",
    "skip_models = 13\n",
    "abs_models_dir = Path('models/tok2vec_abs_sci_ALL_gpu')\n",
    "\n",
    "models = sorted(os.listdir(abs_models_dir))\n",
    "\n",
    "for idx, model_file in enumerate(models):\n",
    "    if idx % skip_models == 0:\n",
    "        model_path = abs_models_dir / model_file\n",
    "        !prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg \\\n",
    "            --eval-split 0.2 --n-iter 20 --init-tok2vec $model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training final models with selected `tok2vec` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def train_ner_with_every_tok2vec(datasets):\n",
    "    tok2vec_dir = Path('models')\n",
    "    tok2vecs = sorted(os.listdir(tok2vec_dir))\n",
    "    \n",
    "    for tok2vec_file in tok2vecs:\n",
    "        if \"_sci_\" not in tok2vec_file:\n",
    "            continue\n",
    "\n",
    "        tok2vec_path = tok2vec_dir / tok2vec_file\n",
    "        !prodigy train ner $datasets en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "            --init-tok2vec $tok2vec_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1587.95      62.963     26.562     37.363                                 \n",
      " 2    1500.37      60.784     48.438     53.913                                 \n",
      " 3    1510.36      63.492     62.500     62.992                                 \n",
      " 4    1519.20      60.000     56.250     58.065                                 \n",
      " 5    1521.26      65.574     62.500     64.000                                 \n",
      " 6    1495.73      64.912     57.812     61.157                                 \n",
      " 7    1386.50      65.517     59.375     62.295                                 \n",
      " 8    1225.63      65.574     62.500     64.000                                 \n",
      " 9    1277.40      65.079     64.062     64.567                                 \n",
      "10    1258.71      62.903     60.938     61.905                                 \n",
      "11    1151.32      61.905     60.938     61.417                                 \n",
      "12    1249.35      63.793     57.812     60.656                                 \n",
      "13    1169.56      67.241     60.938     63.934                                 \n",
      "14    1163.40      65.517     59.375     62.295                                 \n",
      "15    1137.84      65.517     59.375     62.295                                 \n",
      "16    1137.22      67.241     60.938     63.934                                 \n",
      "17    1094.24      67.857     59.375     63.333                                 \n",
      "18    1079.29      63.793     57.812     60.656                                 \n",
      "19    1028.63      63.158     56.250     59.504                                 \n",
      "20    1096.86      63.158     56.250     59.504                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.079   64.062    64.567\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.567\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model238_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1575.28      47.368     28.125     35.294                                 \n",
      " 2    1473.45      68.000     53.125     59.649                                 \n",
      " 3    1414.79      73.214     64.062     68.333                                 \n",
      " 4    1463.85      72.727     62.500     67.227                                 \n",
      " 5    1384.56      76.364     65.625     70.588                                 \n",
      " 6    1343.33      82.692     67.188     74.138                                 \n",
      " 7    1333.10      80.000     68.750     73.950                                 \n",
      " 8    1285.83      77.966     71.875     74.797                                 \n",
      " 9    1231.73      74.545     64.062     68.908                                 \n",
      "10    1147.56      68.333     64.062     66.129                                 \n",
      "11    1133.60      71.667     67.188     69.355                                 \n",
      "12    1186.93      71.186     65.625     68.293                                 \n",
      "13    1163.38      68.852     65.625     67.200                                 \n",
      "14    1152.35      72.414     65.625     68.852                                 \n",
      "15    1096.20      69.492     64.062     66.667                                 \n",
      "16    1076.68      69.492     64.062     66.667                                 \n",
      "17    1034.84      71.429     62.500     66.667                                 \n",
      "18    1071.06      73.214     64.062     68.333                                 \n",
      "19    1066.33      73.214     64.062     68.333                                 \n",
      "20    1082.98      72.727     62.500     67.227                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.966   71.875    74.797\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.797\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2400_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1496.09      71.429     31.250     43.478                                 \n",
      " 2    1428.07      60.976     39.062     47.619                                 \n",
      " 3    1414.88      70.690     64.062     67.213                                 \n",
      " 4    1394.45      68.333     64.062     66.129                                 \n",
      " 5    1386.77      80.000     62.500     70.175                                 \n",
      " 6    1337.78      78.846     64.062     70.690                                 \n",
      " 7    1308.50      79.245     65.625     71.795                                 \n",
      " 8    1229.83      74.074     62.500     67.797                                 \n",
      " 9    1189.92      75.000     65.625     70.000                                 \n",
      "10    1199.78      76.923     62.500     68.966                                 \n",
      "11    1130.30      76.923     62.500     68.966                                 \n",
      "12    1245.61      75.000     60.938     67.241                                 \n",
      "13    1170.87      72.222     60.938     66.102                                 \n",
      "14    1132.59      70.370     59.375     64.407                                 \n",
      "15    1118.17      69.643     60.938     65.000                                 \n",
      "16    1075.07      72.222     60.938     66.102                                 \n",
      "17    1055.17      70.909     60.938     65.546                                 \n",
      "18    1065.72      67.273     57.812     62.185                                 \n",
      "19    1108.23      69.091     59.375     63.866                                 \n",
      "20    1081.93      68.519     57.812     62.712                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.245   65.625    71.795\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.795\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2401_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1581.14      64.516     31.250     42.105                                 \n",
      " 2    1486.14      60.976     39.062     47.619                                 \n",
      " 3    1464.08      67.925     56.250     61.538                                 \n",
      " 4    1497.64      65.306     50.000     56.637                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5    1430.13      64.151     53.125     58.120                                 \n",
      " 6    1414.06      72.000     56.250     63.158                                 \n",
      " 7    1455.04      74.510     59.375     66.087                                 \n",
      " 8    1262.20      75.472     62.500     68.376                                 \n",
      " 9    1305.18      78.431     62.500     69.565                                 \n",
      "10    1269.22      79.630     67.188     72.881                                 \n",
      "11    1109.86      78.846     64.062     70.690                                 \n",
      "12    1294.03      80.000     62.500     70.175                                 \n",
      "13    1189.09      80.392     64.062     71.304                                 \n",
      "14    1183.32      78.431     62.500     69.565                                 \n",
      "15    1149.91      78.431     62.500     69.565                                 \n",
      "16    1237.89      78.431     62.500     69.565                                 \n",
      "17    1107.08      78.846     64.062     70.690                                 \n",
      "18    1170.77      78.846     64.062     70.690                                 \n",
      "19    1085.09      78.846     64.062     70.690                                 \n",
      "20    1126.38      77.778     65.625     71.186                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.630   67.188    72.881\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.881\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2402_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1522.07      50.000     15.625     23.810                                 \n",
      " 2    1434.56      58.974     35.938     44.660                                 \n",
      " 3    1439.36      75.676     43.750     55.446                                 \n",
      " 4    1392.42      65.909     45.312     53.704                                 \n",
      " 5    1351.52      82.222     57.812     67.890                                 \n",
      " 6    1424.66      70.175     62.500     66.116                                 \n",
      " 7    1342.50      74.545     64.062     68.908                                 \n",
      " 8    1259.57      71.154     57.812     63.793                                 \n",
      " 9    1268.84      70.370     59.375     64.407                                 \n",
      "10    1224.35      68.519     57.812     62.712                                 \n",
      "11    1221.88      68.519     57.812     62.712                                 \n",
      "12    1244.84      72.222     60.938     66.102                                 \n",
      "13    1158.82      73.077     59.375     65.517                                 \n",
      "14    1163.86      79.592     60.938     69.027                                 \n",
      "15    1179.30      80.000     62.500     70.175                                 \n",
      "16    1113.85      80.000     62.500     70.175                                 \n",
      "17    1081.04      78.000     60.938     68.421                                 \n",
      "18    1115.72      78.000     60.938     68.421                                 \n",
      "19    1060.52      75.000     60.938     67.241                                 \n",
      "20    1116.15      75.000     60.938     67.241                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      80.000   62.500    70.175\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.175\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model304_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1527.20      64.706     34.375     44.898                                 \n",
      " 2    1514.31      52.381     51.562     51.969                                 \n",
      " 3    1487.56      67.797     62.500     65.041                                 \n",
      " 4    1420.83      70.175     62.500     66.116                                 \n",
      " 5    1392.88      71.186     65.625     68.293                                 \n",
      " 6    1343.58      77.193     68.750     72.727                                 \n",
      " 7    1345.95      76.271     70.312     73.171                                 \n",
      " 8    1223.03      79.310     71.875     75.410                                 \n",
      " 9    1255.10      75.439     67.188     71.074                                 \n",
      "10    1219.86      76.786     67.188     71.667                                 \n",
      "11    1165.85      76.786     67.188     71.667                                 \n",
      "12    1215.02      77.778     65.625     71.186                                 \n",
      "13    1185.63      76.786     67.188     71.667                                 \n",
      "14    1128.99      75.000     65.625     70.000                                 \n",
      "15    1108.05      70.690     64.062     67.213                                 \n",
      "16    1113.84      74.138     67.188     70.492                                 \n",
      "17    1042.53      73.684     65.625     69.421                                 \n",
      "18    1074.24      73.684     65.625     69.421                                 \n",
      "19    1035.15      74.576     68.750     71.545                                 \n",
      "20    1101.89      71.186     65.625     68.293                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.310   71.875    75.410\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.410\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.02      61.905     40.625     49.057                                 \n",
      " 2    1389.84      56.897     51.562     54.098                                 \n",
      " 3    1485.12      71.698     59.375     64.957                                 \n",
      " 4    1385.46      70.175     62.500     66.116                                 \n",
      " 5    1455.78      72.727     62.500     67.227                                 \n",
      " 6    1404.07      78.947     70.312     74.380                                 \n",
      " 7    1323.94      81.818     70.312     75.630                                 \n",
      " 8    1229.71      75.862     68.750     72.131                                 \n",
      " 9    1211.78      77.966     71.875     74.797                                 \n",
      "10    1249.24      76.786     67.188     71.667                                 \n",
      "11    1124.41      76.786     67.188     71.667                                 \n",
      "12    1227.59      75.926     64.062     69.492                                 \n",
      "13    1188.04      71.429     62.500     66.667                                 \n",
      "14    1126.55      77.358     64.062     70.085                                 \n",
      "15    1136.49      77.358     64.062     70.085                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    1146.76      78.431     62.500     69.565                                 \n",
      "17    1045.76      74.545     64.062     68.908                                 \n",
      "18    1047.72      74.545     64.062     68.908                                 \n",
      "19    1039.92      76.786     67.188     71.667                                 \n",
      "20    1076.51      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.818   70.312    75.630\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.630\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model336_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1507.62      57.895     34.375     43.137                                 \n",
      " 2    1465.82      57.627     53.125     55.285                                 \n",
      " 3    1433.29      62.121     64.062     63.077                                 \n",
      " 4    1496.11      68.519     57.812     62.712                                 \n",
      " 5    1393.36      67.308     54.688     60.345                                 \n",
      " 6    1369.23      69.231     56.250     62.069                                 \n",
      " 7    1297.14      72.131     68.750     70.400                                 \n",
      " 8    1253.85      71.429     70.312     70.866                                 \n",
      " 9    1177.67      74.074     62.500     67.797                                 \n",
      "10    1182.16      68.750     51.562     58.929                                 \n",
      "11    1184.30      70.213     51.562     59.459                                 \n",
      "12    1228.26      68.627     54.688     60.870                                 \n",
      "13    1179.65      75.439     67.188     71.074                                 \n",
      "14    1169.15      75.439     67.188     71.074                                 \n",
      "15    1083.01      75.000     65.625     70.000                                 \n",
      "16    1106.40      74.545     64.062     68.908                                 \n",
      "17    1082.69      72.222     60.938     66.102                                 \n",
      "18    1068.73      72.222     60.938     66.102                                 \n",
      "19    1050.78      72.222     60.938     66.102                                 \n",
      "20    1081.67      72.222     60.938     66.102                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.439   67.188    71.074\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.074\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model4_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1591.72      57.143     18.750     28.235                                 \n",
      " 2    1430.54      60.976     39.062     47.619                                 \n",
      " 3    1431.12      76.087     54.688     63.636                                 \n",
      " 4    1447.46      73.333     51.562     60.550                                 \n",
      " 5    1405.81      75.000     65.625     70.000                                 \n",
      " 6    1360.50      81.132     67.188     73.504                                 \n",
      " 7    1350.34      78.431     62.500     69.565                                 \n",
      " 8    1295.07      75.000     56.250     64.286                                 \n",
      " 9    1306.47      77.358     64.062     70.085                                 \n",
      "10    1206.40      73.684     65.625     69.421                                 \n",
      "11    1224.72      74.510     59.375     66.087                                 \n",
      "12    1314.89      73.077     59.375     65.517                                 \n",
      "13    1219.40      73.077     59.375     65.517                                 \n",
      "14    1193.32      71.698     59.375     64.957                                 \n",
      "15    1119.57      71.154     57.812     63.793                                 \n",
      "16    1117.24      70.588     56.250     62.609                                 \n",
      "17    1067.36      68.627     54.688     60.870                                 \n",
      "18    1087.17      68.627     54.688     60.870                                 \n",
      "19    1049.51      70.000     54.688     61.404                                 \n",
      "20    1108.60      67.925     56.250     61.538                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.132   67.188    73.504\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.504\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1578.16      64.000     25.000     35.955                                 \n",
      " 2    1439.61      55.319     40.625     46.847                                 \n",
      " 3    1528.20      72.222     60.938     66.102                                 \n",
      " 4    1429.18      71.154     57.812     63.793                                 \n",
      " 5    1414.46      69.388     53.125     60.177                                 \n",
      " 6    1344.69      75.472     62.500     68.376                                 \n",
      " 7    1472.62      70.909     60.938     65.546                                 \n",
      " 8    1296.39      74.545     64.062     68.908                                 \n",
      " 9    1285.11      68.966     62.500     65.574                                 \n",
      "10    1236.84      70.175     62.500     66.116                                 \n",
      "11    1181.13      71.429     62.500     66.667                                 \n",
      "12    1235.60      70.909     60.938     65.546                                 \n",
      "13    1238.99      76.923     62.500     68.966                                 \n",
      "14    1151.94      75.926     64.062     69.492                                 \n",
      "15    1151.25      75.926     64.062     69.492                                 \n",
      "16    1218.30      78.000     60.938     68.421                                 \n",
      "17    1074.01      75.926     64.062     69.492                                 \n",
      "18    1121.71      76.364     65.625     70.588                                 \n",
      "19    1084.27      77.358     64.062     70.085                                 \n",
      "20    1106.32      76.471     60.938     67.826                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1577.68      57.895     34.375     43.137                                 \n",
      " 2    1386.95      67.308     54.688     60.345                                 \n",
      " 3    1455.49      76.596     56.250     64.865                                 \n",
      " 4    1457.04      79.592     60.938     69.027                                 \n",
      " 5    1413.30      78.431     62.500     69.565                                 \n",
      " 6    1351.85      76.923     62.500     68.966                                 \n",
      " 7    1304.38      78.000     60.938     68.421                                 \n",
      " 8    1255.67      76.471     60.938     67.826                                 \n",
      " 9    1219.66      78.431     62.500     69.565                                 \n",
      "10    1203.83      74.545     64.062     68.908                                 \n",
      "11    1125.02      74.545     64.062     68.908                                 \n",
      "12    1224.65      74.074     62.500     67.797                                 \n",
      "13    1173.56      75.000     60.938     67.241                                 \n",
      "14    1170.88      75.000     60.938     67.241                                 \n",
      "15    1074.42      71.154     57.812     63.793                                 \n",
      "16    1144.97      75.000     60.938     67.241                                 \n",
      "17    1041.02      73.077     59.375     65.517                                 \n",
      "18    1094.32      74.510     59.375     66.087                                 \n",
      "19    1051.65      74.510     59.375     66.087                                 \n",
      "20    1099.61      78.000     60.938     68.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.431   62.500    69.565\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.565\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.28      62.500     23.438     34.091                                 \n",
      " 2    1397.40      59.091     40.625     48.148                                 \n",
      " 3    1485.47      70.833     53.125     60.714                                 \n",
      " 4    1445.56      68.293     43.750     53.333                                 \n",
      " 5    1431.31      64.000     50.000     56.140                                 \n",
      " 6    1339.87      70.833     53.125     60.714                                 \n",
      " 7    1387.07      72.340     53.125     61.261                                 \n",
      " 8    1232.74      76.596     56.250     64.865                                 \n",
      " 9    1207.39      72.340     53.125     61.261                                 \n",
      "10    1231.53      75.926     64.062     69.492                                 \n",
      "11    1154.22      74.545     64.062     68.908                                 \n",
      "12    1304.76      75.472     62.500     68.376                                 \n",
      "13    1155.21      69.811     57.812     63.248                                 \n",
      "14    1158.97      67.273     57.812     62.185                                 \n",
      "15    1092.88      69.811     57.812     63.248                                 \n",
      "16    1134.04      68.627     54.688     60.870                                 \n",
      "17    1055.42      66.667     56.250     61.017                                 \n",
      "18    1071.15      66.667     56.250     61.017                                 \n",
      "19    1060.90      69.231     56.250     62.069                                 \n",
      "20    1063.32      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2Kading 'en_core_sci_lg'...\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1630.03      55.556     23.438     32.967                                 \n",
      " 2    1442.41      55.556     46.875     50.847                                 \n",
      " 3    1429.19      65.957     48.438     55.856                                 \n",
      " 4    1467.20      65.455     56.250     60.504                                 \n",
      " 5    1467.20      69.643     60.938     65.000                                 \n",
      " 6    1376.49      67.241     60.938     63.934                                 \n",
      " 7    1324.06      73.585     60.938     66.667                                 \n",
      " 8    1261.74      75.472     62.500     68.376                                 \n",
      " 9    1229.62      77.358     64.062     70.085                                 \n",
      "10    1162.35      74.545     64.062     68.908                                 \n",
      "11    1129.31      72.727     62.500     67.227                                 \n",
      "12    1226.05      73.684     65.625     69.421                                 \n",
      "13    1154.44      73.684     65.625     69.421                                 \n",
      "14    1146.38      69.492     64.062     66.667                                 \n",
      "15    1157.15      70.175     62.500     66.116                                 \n",
      "16    1122.06      72.549     57.812     64.348                                 \n",
      "17    1069.36      70.909     60.938     65.546                                 \n",
      "18    1112.07      71.930     64.062     67.769                                 \n",
      "19    1040.95      70.370     59.375     64.407                                 \n",
      "20    1074.33      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   64.062    70.085\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.085\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ner_with_every_tok2vec(\"cord_19_rf_sentences,cord_19_rf_sentences_correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔥 Top model so far: `75.630` 🔥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.02      61.905     40.625     49.057                                 \n",
      " 2    1389.84      56.897     51.562     54.098                                 \n",
      " 3    1485.12      71.698     59.375     64.957                                 \n",
      " 4    1385.46      70.175     62.500     66.116                                 \n",
      " 5    1455.78      72.727     62.500     67.227                                 \n",
      " 6    1404.07      78.947     70.312     74.380                                 \n",
      " 7    1323.94      81.818     70.312     75.630                                 \n",
      " 8    1229.71      75.862     68.750     72.131                                 \n",
      " 9    1211.78      77.966     71.875     74.797                                 \n",
      "10    1249.24      76.786     67.188     71.667                                 \n",
      "11    1124.41      76.786     67.188     71.667                                 \n",
      "12    1227.59      75.926     64.062     69.492                                 \n",
      "13    1188.04      71.429     62.500     66.667                                 \n",
      "14    1126.55      77.358     64.062     70.085                                 \n",
      "15    1136.49      77.358     64.062     70.085                                 \n",
      "16    1146.76      78.431     62.500     69.565                                 \n",
      "17    1045.76      74.545     64.062     68.908                                 \n",
      "18    1047.72      74.545     64.062     68.908                                 \n",
      "19    1039.92      76.786     67.188     71.667                                 \n",
      "20    1076.51      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.818   70.312    75.630\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.630\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_10_en_ner_rf_sm\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg \\\n",
    "#    --eval-split 0.2 --n-iter 20 --init-tok2vec models/tok2vec_abs_sci_model308_gpu.bin \\\n",
    "#    --output models/2020_04_10_en_ner_rf_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.13 (Mon)\n",
    "## Label more data by correcting the model's predictions (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_rf_sentences_correct_2 to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.correct cord_19_rf_sentences_correct_2 models/2020_04_10_en_ner_rf_sm data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR --exclude cord_19_rf_sentences,cord_19_rf_sentences_correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
