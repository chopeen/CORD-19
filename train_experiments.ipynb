{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.28 (Sat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model: spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_web_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 86 total examples\n",
      "Using 43 train / 43 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2260.23       3.822      5.714      4.580                                 \n",
      " 2     304.20      96.203     72.381     82.609                                 \n",
      " 3      35.94      93.069     89.524     91.262                                 \n",
      " 4       7.71      91.262     89.524     90.385                                 \n",
      " 5       6.89      94.000     89.524     91.707                                 \n",
      " 6       6.26      94.949     89.524     92.157                                 \n",
      " 7       4.15      94.000     89.524     91.707                                 \n",
      " 8      10.58      92.157     89.524     90.821                                 \n",
      " 9       1.78      92.157     89.524     90.821                                 \n",
      "10       0.00      93.069     89.524     91.262                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.949   89.524    92.157\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m92.157\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_28_match/en_rf_web_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_match models/en_core_web_lg_no_ner --output models/2020_03_28_match/en_rf_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model: scispaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 86 total examples\n",
      "Using 43 train / 43 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1864.33       3.333      2.941      3.125                                 \n",
      " 2     303.79      93.902     75.490     83.696                                 \n",
      " 3      22.39      92.784     88.235     90.452                                 \n",
      " 4      17.47      94.792     89.216     91.919                                 \n",
      " 5       5.36      93.814     89.216     91.457                                 \n",
      " 6       6.78      92.857     89.216     91.000                                 \n",
      " 7       6.09      93.814     89.216     91.457                                 \n",
      " 8       4.87      94.792     89.216     91.919                                 \n",
      " 9       9.64      93.814     89.216     91.457                                 \n",
      "10       4.02      94.792     89.216     91.919                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.792   89.216    91.919\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m91.919\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_28_match/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_match models/en_core_sci_lg_no_ner --output models/2020_03_28_match/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.29 (Sun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model trained on Sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "def test_model(model_path):\n",
    "    warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "    \n",
    "    nlp = spacy.load(model_path)\n",
    "    texts = [\n",
    "    \"Known risk factors for the disease are: older age, male gender, diabetes and leukemia. Female patiens and children are less susceptible.\",\n",
    "    \"Diabetes is a known risk factor.\",\n",
    "    \"Leukemia is a risk factor, too.\"\n",
    "    ]\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "\n",
    "        spacy.displacy.render(doc, style='ent', jupyter=True)\n",
    "        pprint([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Known risk factors for the disease are: older \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    age\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    male\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " gender, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " and leukemia. Female patiens and children are less susceptible.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('age', 'RISK_FACTOR'), ('male', 'RISK_FACTOR'), ('diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " is a known risk factor.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Leukemia is a risk factor, too.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_model(\"models/2020_03_28_match/en_rf_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the factors that appeared during the training are detected. _Leukemia_ is **not highlighed** and that means that the NER model did not learn to recognize risk factors based on the sentence structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train new models after the `teach` session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_web_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 393 total examples\n",
      "Using 197 train / 196 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     333.36      89.669     92.735     91.176                                 \n",
      " 2      64.66      92.982     90.598     91.775                                 \n",
      " 3      53.47      94.492     95.299     94.894                                 \n",
      " 4      45.26      94.492     95.299     94.894                                 \n",
      " 5      29.42      94.958     96.581     95.763                                 \n",
      " 6      30.44      96.170     96.581     96.375                                 \n",
      " 7      23.82      95.745     96.154     95.949                                 \n",
      " 8       5.78      95.319     95.726     95.522                                 \n",
      " 9       4.12      95.299     95.299     95.299                                 \n",
      "10       5.46      96.137     95.726     95.931                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      96.170   96.581    96.375\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m96.375\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_29_teach/en_rf_web_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_teach models/en_core_web_lg_no_ner --output models/2020_03_29_teach/en_rf_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 393 total examples\n",
      "Using 197 train / 196 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     289.28      90.991     91.818     91.403                                 \n",
      " 2      54.12      92.237     91.818     92.027                                 \n",
      " 3      84.39      91.593     94.091     92.825                                 \n",
      " 4      46.45      93.213     93.636     93.424                                 \n",
      " 5      19.43      95.000     95.000     95.000                                 \n",
      " 6      15.25      93.665     94.091     93.878                                 \n",
      " 7       4.07      93.363     95.909     94.619                                 \n",
      " 8      11.23      93.722     95.000     94.357                                 \n",
      " 9      10.13      94.595     95.455     95.023                                 \n",
      "10       6.20      94.595     95.455     95.023                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      94.595   95.455    95.023\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m95.023\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_29_teach/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_teach models/en_core_sci_lg_no_ner --output models/2020_03_29_teach/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Known risk factors for the disease are: older \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    age\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    male gender\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " and leukemia. Female patiens and children are less susceptible.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('age', 'RISK_FACTOR'),\n",
      " ('male gender', 'RISK_FACTOR'),\n",
      " ('diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">RISK_FACTOR</span>\n",
       "</mark>\n",
       " is a known risk factor.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Diabetes', 'RISK_FACTOR')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Leukemia is a risk factor, too.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_model(\"models/2020_03_29_teach/en_rf_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better model scores, but _leukemia_ still **not detected**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.03.30 (Mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`strict`)\n",
    "\n",
    "Terms like _male_ or _age_ will only be marked, when they are mentioned in the context of COVID-19 risk factors, i.e. not in articles about animals or children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_abstracts_strict to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 41 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_abstracts_strict\n",
      "Session ID: 2020-03-30_20-24-26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual cord_19_abstracts_strict models/en_core_sci_lg_no_ner data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR --patterns patterns/RF_list_2020.03.17.20037572.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 41 total examples\n",
      "Using 21 train / 20 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1737.49       0.000      0.000      0.000                                 \n",
      " 2      25.99       0.000      0.000      0.000                                 \n",
      " 3     115.63       0.000      0.000      0.000                                 \n",
      " 4      24.86       0.000      0.000      0.000                                 \n",
      " 5      22.36       0.000      0.000      0.000                                 \n",
      " 6      18.33       0.000      0.000      0.000                                 \n",
      " 7      20.52       0.000      0.000      0.000                                 \n",
      " 8      28.45       0.000      0.000      0.000                                 \n",
      " 9      18.38       0.000      0.000      0.000                                 \n",
      "10       7.78       0.000      0.000      0.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR       0.000    0.000     0.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m0.000\u001b[0m\n",
      "Baseline       0.000             \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_30_strict/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_abstracts_strict models/en_core_sci_lg_no_ner --output models/2020_03_30_strict/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`all RF`)\n",
    "\n",
    "Highlight all risk factors - for any disease or species - but only is sentences that clear say it is a risk factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!prodigy ner.manual cord_19_abstracts_all_rf models/en_core_sci_lg_no_ner data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR --patterns patterns/RF_highlight_factor_phrases.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'models/en_core_sci_lg_no_ner'\u001b[0m\n",
      "Created and merged data for 58 total examples\n",
      "Using 29 train / 29 eval (split 50%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1960.54       0.000      0.000      0.000                                 \n",
      " 2      95.38       0.000      0.000      0.000                                 \n",
      " 3     161.78     100.000      2.128      4.167                                 \n",
      " 4      88.78      40.000      4.255      7.692                                 \n",
      " 5      97.87      33.333      4.255      7.547                                 \n",
      " 6      87.81      37.500      6.383     10.909                                 \n",
      " 7     341.72      25.000      2.128      3.922                                 \n",
      " 8     169.64      40.000      4.255      7.692                                 \n",
      " 9      79.07      30.000      6.383     10.526                                 \n",
      "10     268.87      33.333      6.383     10.714                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      37.500    6.383    10.909\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m10.909\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_03_30_all_RF/en_rf_sci_lg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_abstracts_all_rf models/en_core_sci_lg_no_ner --output models/2020_03_30_all_RF/en_rf_sci_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "\n",
      "✨  Starting the web server at http://localhost:8081 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 7 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_abstracts_all_rf\n",
      "Session ID: 2020-03-30_22-01-26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.teach cord_19_abstracts_all_rf models/2020_03_30_all_RF/en_rf_sci_lg data/raw/cord_19_abstracts_filtered.jsonl \\\n",
    "  --label RISK_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.06 (Mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`RF sentences`)\n",
    "\n",
    "Following the official guide:\n",
    "- https://www.youtube.com/watch?v=59BKHO_xBPA\n",
    "- https://github.com/explosion/projects/tree/master/ner-food-ingredients#data-creation-and-training-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 102 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences\n",
      "Session ID: 2020-04-06_22-08-56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual cord_19_rf_sentences blank:en data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     389.18       0.000      0.000      0.000                                 \n",
      " 2     191.03      25.000      4.000      6.897                                 \n",
      " 3     265.45      35.294     24.000     28.571                                 \n",
      " 4     246.57      28.571     24.000     26.087                                 \n",
      " 5     239.21      22.727     20.000     21.277                                 \n",
      " 6     215.80      42.857     24.000     30.769                                 \n",
      " 7     258.40      42.105     32.000     36.364                                 \n",
      " 8     237.19      50.000     32.000     39.024                                 \n",
      " 9     208.67      62.500     40.000     48.780                                 \n",
      "10     141.30      66.667     40.000     50.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667   40.000    50.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m50.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1421.81       0.000      0.000      0.000                                 \n",
      " 2    1245.16       0.000      0.000      0.000                                 \n",
      " 3    1262.77       0.000      0.000      0.000                                 \n",
      " 4    1249.04       0.000      0.000      0.000                                 \n",
      " 5    1262.46       0.000      0.000      0.000                                 \n",
      " 6    1205.26       0.000      0.000      0.000                                 \n",
      " 7    1137.92       0.000      0.000      0.000                                 \n",
      " 8    1131.84       0.000      0.000      0.000                                 \n",
      " 9    1058.85       0.000      0.000      0.000                                 \n",
      "10    1143.62       0.000      0.000      0.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "GPE               0.000    0.000     0.000\n",
      "RISK_FACTOR       0.000    0.000     0.000\n",
      "CARDINAL          0.000    0.000     0.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m0.000\u001b[0m\n",
      "Baseline       0.000             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⁉️ Why is `en_core_web_lg` producing no results at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     559.17       0.000      0.000      0.000                                 \n",
      " 2     550.33      33.333      8.000     12.903                                 \n",
      " 3     538.43      50.000     24.000     32.432                                 \n",
      " 4     457.89      52.632     40.000     45.455                                 \n",
      " 5     452.06      50.000     36.000     41.860                                 \n",
      " 6     415.01      60.000     48.000     53.333                                 \n",
      " 7     489.45      47.826     44.000     45.833                                 \n",
      " 8     461.13      45.000     36.000     40.000                                 \n",
      " 9     486.03      47.619     40.000     43.478                                 \n",
      "10     406.83      54.545     48.000     51.064                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   48.000    53.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m53.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_06_rf_sentences\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 --output models/2020_04_06_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "embed_rows: 2000 | require_vectors: True | cnn_maxout_pieces: 3 |\n",
      "token_vector_width: 96 | conv_depth: 4 | nr_feature_tokens: 3 |\n",
      "pretrained_vectors: en_vectors_web_lg.vectors\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     339.88       0.000      0.000      0.000                                 \n",
      " 2     199.85      50.000     16.000     24.242                                 \n",
      " 3     128.26      50.000     28.000     35.897                                 \n",
      " 4      76.43      42.857     24.000     30.769                                 \n",
      " 5      63.28      60.000     36.000     45.000                                 \n",
      " 6      29.70      53.333     32.000     40.000                                 \n",
      " 7      21.18      56.250     36.000     43.902                                 \n",
      " 8      36.86      50.000     36.000     41.860                                 \n",
      " 9      13.28      52.941     36.000     42.857                                 \n",
      "10       7.74      52.941     36.000     42.857                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   36.000    45.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m45.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2055.18       0.000      0.000      0.000                                 \n",
      " 2    1808.48       0.000      0.000      0.000                                 \n",
      " 3    1624.76       0.000      0.000      0.000                                 \n",
      " 4    1443.31       0.000      0.000      0.000                                 \n",
      " 5    1652.93       0.000      0.000      0.000                                 \n",
      " 6    1470.22       0.000      0.000      0.000                                 \n",
      " 7    1345.14       0.000      0.000      0.000                                 \n",
      " 8    1403.16      50.000      4.000      7.407                                 \n",
      " 9    1249.90      66.667      8.000     14.286                                 \n",
      "10    1357.22      66.667      8.000     14.286                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667    8.000    14.286\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m14.286\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     536.68       0.000      0.000      0.000                                 \n",
      " 2     631.61       0.000      0.000      0.000                                 \n",
      " 3     539.99      40.000     24.000     30.000                                 \n",
      " 4     505.27      47.619     40.000     43.478                                 \n",
      " 5     508.05      45.000     36.000     40.000                                 \n",
      " 6     461.69      52.941     36.000     42.857                                 \n",
      " 7     473.25      45.000     36.000     40.000                                 \n",
      " 8     571.35      61.111     44.000     51.163                                 \n",
      " 9     465.27      55.556     40.000     46.512                                 \n",
      "10     455.26      43.750     28.000     34.146                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      61.111   44.000    51.163\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m51.163\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label more data by correcting the model's predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model so far will be used: `Best F-Score   53.333`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_rf_sentences_correct to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 220 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences_correct\n",
      "Session ID: 2020-04-06_23-58-48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.correct cord_19_rf_sentences_correct models/2020_04_06_rf_sentences data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR --exclude cord_19_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For futher training, only `en_core_sci_lg` will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1554.25      61.538     37.500     46.602                                 \n",
      " 2    1346.09      64.407     59.375     61.789                                 \n",
      " 3    1407.15      66.667     50.000     57.143                                 \n",
      " 4    1411.73      72.727     50.000     59.259                                 \n",
      " 5    1412.81      73.913     53.125     61.818                                 \n",
      " 6    1319.96      73.913     53.125     61.818                                 \n",
      " 7    1378.05      72.917     54.688     62.500                                 \n",
      " 8    1208.99      72.727     62.500     67.227                                 \n",
      " 9    1177.16      73.077     59.375     65.517                                 \n",
      "10    1211.40      72.549     57.812     64.348                                 \n",
      "11    1142.34      74.510     59.375     66.087                                 \n",
      "12    1196.27      72.000     56.250     63.158                                 \n",
      "13    1153.93      72.000     56.250     63.158                                 \n",
      "14    1149.78      72.549     57.812     64.348                                 \n",
      "15    1154.34      69.231     56.250     62.069                                 \n",
      "16    1104.68      69.231     56.250     62.069                                 \n",
      "17    1062.17      68.627     54.688     60.870                                 \n",
      "18    1063.28      68.627     54.688     60.870                                 \n",
      "19    1048.51      68.627     54.688     60.870                                 \n",
      "20    1120.40      68.627     54.688     60.870                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.727   62.500    67.227\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.227\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1578.16      64.000     25.000     35.955                                 \n",
      " 2    1439.61      55.319     40.625     46.847                                 \n",
      " 3    1528.20      72.222     60.938     66.102                                 \n",
      " 4    1429.18      71.154     57.812     63.793                                 \n",
      " 5    1414.46      69.388     53.125     60.177                                 \n",
      " 6    1344.69      75.472     62.500     68.376                                 \n",
      " 7    1472.62      70.909     60.938     65.546                                 \n",
      " 8    1296.39      74.545     64.062     68.908                                 \n",
      " 9    1285.11      68.966     62.500     65.574                                 \n",
      "10    1236.84      70.175     62.500     66.116                                 \n",
      "11    1181.13      71.429     62.500     66.667                                 \n",
      "12    1235.60      70.909     60.938     65.546                                 \n",
      "13    1238.99      76.923     62.500     68.966                                 \n",
      "14    1151.94      75.926     64.062     69.492                                 \n",
      "15    1151.25      75.926     64.062     69.492                                 \n",
      "16    1218.30      78.000     60.938     68.421                                 \n",
      "17    1074.01      75.926     64.062     69.492                                 \n",
      "18    1121.71      76.364     65.625     70.588                                 \n",
      "19    1084.27      77.358     64.062     70.085                                 \n",
      "20    1106.32      76.471     60.938     67.826                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_07_rf_sentences_corrected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin --output models/2020_04_07_rf_sentences_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.28      62.500     23.438     34.091                                 \n",
      " 2    1397.40      59.091     40.625     48.148                                 \n",
      " 3    1485.47      70.833     53.125     60.714                                 \n",
      " 4    1445.56      68.293     43.750     53.333                                 \n",
      " 5    1431.31      64.000     50.000     56.140                                 \n",
      " 6    1339.87      70.833     53.125     60.714                                 \n",
      " 7    1387.07      72.340     53.125     61.261                                 \n",
      " 8    1232.74      76.596     56.250     64.865                                 \n",
      " 9    1207.39      72.340     53.125     61.261                                 \n",
      "10    1231.53      75.926     64.062     69.492                                 \n",
      "11    1154.22      74.545     64.062     68.908                                 \n",
      "12    1304.76      75.472     62.500     68.376                                 \n",
      "13    1155.21      69.811     57.812     63.248                                 \n",
      "14    1158.97      67.273     57.812     62.185                                 \n",
      "15    1092.88      69.811     57.812     63.248                                 \n",
      "16    1134.04      68.627     54.688     60.870                                 \n",
      "17    1055.42      66.667     56.250     61.017                                 \n",
      "18    1071.15      66.667     56.250     61.017                                 \n",
      "19    1060.90      69.231     56.250     62.069                                 \n",
      "20    1063.32      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model989.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.09 (Thu)\n",
    "## Experiments with new `tok2vec` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1577.68      57.895     34.375     43.137                                 \n",
      " 2    1386.95      67.308     54.688     60.345                                 \n",
      " 3    1455.49      76.596     56.250     64.865                                 \n",
      " 4    1457.04      79.592     60.938     69.027                                 \n",
      " 5    1413.30      78.431     62.500     69.565                                 \n",
      " 6    1351.85      76.923     62.500     68.966                                 \n",
      " 7    1304.38      78.000     60.938     68.421                                 \n",
      " 8    1255.67      76.471     60.938     67.826                                 \n",
      " 9    1219.66      78.431     62.500     69.565                                 \n",
      "10    1203.83      74.545     64.062     68.908                                 \n",
      "11    1125.02      74.545     64.062     68.908                                 \n",
      "12    1224.65      74.074     62.500     67.797                                 \n",
      "13    1173.56      75.000     60.938     67.241                                 \n",
      "14    1170.88      75.000     60.938     67.241                                 \n",
      "15    1074.42      71.154     57.812     63.793                                 \n",
      "16    1144.97      75.000     60.938     67.241                                 \n",
      "17    1041.02      73.077     59.375     65.517                                 \n",
      "18    1094.32      74.510     59.375     66.087                                 \n",
      "19    1051.65      74.510     59.375     66.087                                 \n",
      "20    1099.61      78.000     60.938     68.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.431   62.500    69.565\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.565\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model978_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1630.03      55.556     23.438     32.967                                 \n",
      " 2    1442.41      55.556     46.875     50.847                                 \n",
      " 3    1429.19      65.957     48.438     55.856                                 \n",
      " 4    1467.20      65.455     56.250     60.504                                 \n",
      " 5    1467.20      69.643     60.938     65.000                                 \n",
      " 6    1376.49      67.241     60.938     63.934                                 \n",
      " 7    1324.06      73.585     60.938     66.667                                 \n",
      " 8    1261.74      75.472     62.500     68.376                                 \n",
      " 9    1229.62      77.358     64.062     70.085                                 \n",
      "10    1162.35      74.545     64.062     68.908                                 \n",
      "11    1129.31      72.727     62.500     67.227                                 \n",
      "12    1226.05      73.684     65.625     69.421                                 \n",
      "13    1154.44      73.684     65.625     69.421                                 \n",
      "14    1146.38      69.492     64.062     66.667                                 \n",
      "15    1157.15      70.175     62.500     66.116                                 \n",
      "16    1122.06      72.549     57.812     64.348                                 \n",
      "17    1069.36      70.909     60.938     65.546                                 \n",
      "18    1112.07      71.930     64.062     67.769                                 \n",
      "19    1040.95      70.370     59.375     64.407                                 \n",
      "20    1074.33      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   64.062    70.085\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.085\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model997_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1587.95      62.963     26.562     37.363                                 \n",
      " 2    1500.37      60.784     48.438     53.913                                 \n",
      " 3    1510.36      63.492     62.500     62.992                                 \n",
      " 4    1519.20      60.000     56.250     58.065                                 \n",
      " 5    1521.26      65.574     62.500     64.000                                 \n",
      " 6    1495.73      64.912     57.812     61.157                                 \n",
      " 7    1386.50      65.517     59.375     62.295                                 \n",
      " 8    1225.63      65.574     62.500     64.000                                 \n",
      " 9    1277.40      65.079     64.062     64.567                                 \n",
      "10    1258.71      62.903     60.938     61.905                                 \n",
      "11    1151.32      61.905     60.938     61.417                                 \n",
      "12    1249.35      63.793     57.812     60.656                                 \n",
      "13    1169.56      67.241     60.938     63.934                                 \n",
      "14    1163.40      65.517     59.375     62.295                                 \n",
      "15    1137.84      65.517     59.375     62.295                                 \n",
      "16    1137.22      67.241     60.938     63.934                                 \n",
      "17    1094.24      67.857     59.375     63.333                                 \n",
      "18    1079.29      63.793     57.812     60.656                                 \n",
      "19    1028.63      63.158     56.250     59.504                                 \n",
      "20    1096.86      63.158     56.250     59.504                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.079   64.062    64.567\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.567\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_abs_fil_sci_model975_gpu.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.10 (Fri)\n",
    "## Experiments with new `tok2vec` models (cont.)\n",
    "\n",
    "The Kaggle notebook training models for the full set of abstracts (i.e. `cord_19_abstracts.jsonl`) crashed, so I have only partial results and no loss metrics for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model12.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1581.18      55.556     23.438     32.967                                 \n",
      " 2    1527.12      55.263     32.812     41.176                                 \n",
      " 3    1494.60      65.306     50.000     56.637                                 \n",
      " 4    1455.80      57.692     46.875     51.724                                 \n",
      " 5    1421.18      66.667     53.125     59.130                                 \n",
      " 6    1394.46      69.811     57.812     63.248                                 \n",
      " 7    1411.99      72.222     60.938     66.102                                 \n",
      " 8    1351.20      76.000     59.375     66.667                                 \n",
      " 9    1198.01      74.000     57.812     64.912                                 \n",
      "10    1182.78      70.370     59.375     64.407                                 \n",
      "11    1224.69      70.370     59.375     64.407                                 \n",
      "12    1278.27      71.154     57.812     63.793                                 \n",
      "13    1209.66      72.222     60.938     66.102                                 \n",
      "14    1189.60      69.231     56.250     62.069                                 \n",
      "15    1102.18      70.588     56.250     62.609                                 \n",
      "16    1113.05      69.811     57.812     63.248                                 \n",
      "17    1049.96      65.455     56.250     60.504                                 \n",
      "18    1084.73      66.667     56.250     61.017                                 \n",
      "19    1074.28      67.925     56.250     61.538                                 \n",
      "20    1076.52      67.925     56.250     61.538                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.000   59.375    66.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model16.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1567.69      48.780     31.250     38.095                                 \n",
      " 2    1443.54      60.000     46.875     52.632                                 \n",
      " 3    1424.25      58.491     48.438     52.991                                 \n",
      " 4    1434.44      64.000     50.000     56.140                                 \n",
      " 5    1519.93      67.797     62.500     65.041                                 \n",
      " 6    1484.36      74.545     64.062     68.908                                 \n",
      " 7    1375.14      76.923     62.500     68.966                                 \n",
      " 8    1287.66      74.074     62.500     67.797                                 \n",
      " 9    1236.24      70.588     56.250     62.609                                 \n",
      "10    1173.41      67.308     54.688     60.345                                 \n",
      "11    1176.78      65.455     56.250     60.504                                 \n",
      "12    1244.41      66.071     57.812     61.667                                 \n",
      "13    1164.18      70.370     59.375     64.407                                 \n",
      "14    1138.74      72.549     57.812     64.348                                 \n",
      "15    1123.50      68.966     62.500     65.574                                 \n",
      "16    1131.82      70.370     59.375     64.407                                 \n",
      "17    1055.50      70.909     60.938     65.546                                 \n",
      "18    1104.64      72.727     62.500     67.227                                 \n",
      "19    1042.63      73.585     60.938     66.667                                 \n",
      "20    1088.61      72.222     60.938     66.102                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.923   62.500    68.966\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.966\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model20.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1586.45      68.750     34.375     45.833                                 \n",
      " 2    1437.17      59.184     45.312     51.327                                 \n",
      " 3    1435.44      58.491     48.438     52.991                                 \n",
      " 4    1421.11      60.377     50.000     54.701                                 \n",
      " 5    1446.05      53.571     46.875     50.000                                 \n",
      " 6    1482.85      58.333     43.750     50.000                                 \n",
      " 7    1374.27      64.286     56.250     60.000                                 \n",
      " 8    1309.65      61.538     50.000     55.172                                 \n",
      " 9    1308.48      62.745     50.000     55.652                                 \n",
      "10    1221.00      60.784     48.438     53.913                                 \n",
      "11    1175.71      62.264     51.562     56.410                                 \n",
      "12    1278.85      60.714     53.125     56.667                                 \n",
      "13    1196.31      62.963     53.125     57.627                                 \n",
      "14    1185.35      62.264     51.562     56.410                                 \n",
      "15    1137.04      63.462     51.562     56.897                                 \n",
      "16    1128.04      62.963     53.125     57.627                                 \n",
      "17    1058.85      62.963     53.125     57.627                                 \n",
      "18    1175.82      62.963     53.125     57.627                                 \n",
      "19    1064.80      62.264     51.562     56.410                                 \n",
      "20    1102.07      63.462     51.562     56.897                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      64.286   56.250    60.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m60.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2Kading 'en_core_sci_lg'...\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model24.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1560.47      62.857     34.375     44.444                                 \n",
      " 2    1503.72      53.191     39.062     45.045                                 \n",
      " 3    1424.49      53.061     40.625     46.018                                 \n",
      " 4    1467.87      64.516     62.500     63.492                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5    1405.40      67.308     54.688     60.345                                 \n",
      " 6    1419.47      67.925     56.250     61.538                                 \n",
      " 7    1306.11      70.833     53.125     60.714                                 \n",
      " 8    1250.00      66.000     51.562     57.895                                 \n",
      " 9    1256.64      68.421     60.938     64.463                                 \n",
      "10    1155.48      73.684     65.625     69.421                                 \n",
      "11    1162.77      68.421     60.938     64.463                                 \n",
      "12    1254.68      68.421     60.938     64.463                                 \n",
      "13    1145.45      64.516     62.500     63.492                                 \n",
      "14    1166.52      70.690     64.062     67.213                                 \n",
      "15    1096.98      68.966     62.500     65.574                                 \n",
      "16    1111.96      67.857     59.375     63.333                                 \n",
      "17    1054.99      69.492     64.062     66.667                                 \n",
      "18    1057.61      68.333     64.062     66.129                                 \n",
      "19    1049.08      70.175     62.500     66.116                                 \n",
      "20    1072.20      68.966     62.500     65.574                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model28.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1587.09      51.351     29.688     37.624                                 \n",
      " 2    1650.39      55.769     45.312     50.000                                 \n",
      " 3    1451.46      59.649     53.125     56.198                                 \n",
      " 4    1526.65      67.857     59.375     63.333                                 \n",
      " 5    1515.19      70.000     54.688     61.404                                 \n",
      " 6    1408.17      70.690     64.062     67.213                                 \n",
      " 7    1426.65      70.588     56.250     62.609                                 \n",
      " 8    1310.03      72.340     53.125     61.261                                 \n",
      " 9    1190.85      70.000     54.688     61.404                                 \n",
      "10    1233.50      71.667     67.188     69.355                                 \n",
      "11    1184.19      70.968     68.750     69.841                                 \n",
      "12    1240.36      69.492     64.062     66.667                                 \n",
      "13    1187.25      71.429     62.500     66.667                                 \n",
      "14    1183.74      70.175     62.500     66.116                                 \n",
      "15    1114.92      68.966     62.500     65.574                                 \n",
      "16    1111.62      68.966     62.500     65.574                                 \n",
      "17    1056.72      70.175     62.500     66.116                                 \n",
      "18    1119.18      72.222     60.938     66.102                                 \n",
      "19    1048.80      73.214     64.062     68.333                                 \n",
      "20    1103.21      70.690     64.062     67.213                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.968   68.750    69.841\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.841\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model32.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1601.07      64.286     28.125     39.130                                 \n",
      " 2    1454.81      58.140     39.062     46.729                                 \n",
      " 3    1529.83      64.815     54.688     59.322                                 \n",
      " 4    1461.13      63.636     54.688     58.824                                 \n",
      " 5    1450.06      63.333     59.375     61.290                                 \n",
      " 6    1383.68      70.175     62.500     66.116                                 \n",
      " 7    1368.26      69.811     57.812     63.248                                 \n",
      " 8    1268.87      64.151     53.125     58.120                                 \n",
      " 9    1285.07      71.154     57.812     63.793                                 \n",
      "10    1219.67      74.545     64.062     68.908                                 \n",
      "11    1164.93      77.778     65.625     71.186                                 \n",
      "12    1247.79      77.778     65.625     71.186                                 \n",
      "13    1179.87      71.186     65.625     68.293                                 \n",
      "14    1154.97      67.213     64.062     65.600                                 \n",
      "15    1111.06      70.492     67.188     68.800                                 \n",
      "16    1119.19      70.492     67.188     68.800                                 \n",
      "17    1064.86      70.492     67.188     68.800                                 \n",
      "18    1089.32      73.684     65.625     69.421                                 \n",
      "19    1053.85      72.414     65.625     68.852                                 \n",
      "20    1091.09      72.414     65.625     68.852                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.778   65.625    71.186\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.186\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model36.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1566.85      57.143     31.250     40.404                                 \n",
      " 2    1401.14      58.696     42.188     49.091                                 \n",
      " 3    1481.59      64.151     53.125     58.120                                 \n",
      " 4    1406.87      67.857     59.375     63.333                                 \n",
      " 5    1355.47      74.545     64.062     68.908                                 \n",
      " 6    1415.40      73.585     60.938     66.667                                 \n",
      " 7    1378.60      72.222     60.938     66.102                                 \n",
      " 8    1229.25      75.000     60.938     67.241                                 \n",
      " 9    1204.60      75.472     62.500     68.376                                 \n",
      "10    1246.51      75.000     60.938     67.241                                 \n",
      "11    1147.90      74.545     64.062     68.908                                 \n",
      "12    1253.65      75.000     60.938     67.241                                 \n",
      "13    1136.62      75.000     60.938     67.241                                 \n",
      "14    1168.40      73.077     59.375     65.517                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    1124.20      73.585     60.938     66.667                                 \n",
      "16    1095.83      76.471     60.938     67.826                                 \n",
      "17    1079.37      76.000     59.375     66.667                                 \n",
      "18    1082.64      73.469     56.250     63.717                                 \n",
      "19    1053.44      75.000     60.938     67.241                                 \n",
      "20    1102.43      76.364     65.625     70.588                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model4.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1591.72      57.143     18.750     28.235                                 \n",
      " 2    1430.54      60.976     39.062     47.619                                 \n",
      " 3    1431.12      76.087     54.688     63.636                                 \n",
      " 4    1447.46      73.333     51.562     60.550                                 \n",
      " 5    1405.81      75.000     65.625     70.000                                 \n",
      " 6    1360.50      81.132     67.188     73.504                                 \n",
      " 7    1350.34      78.431     62.500     69.565                                 \n",
      " 8    1295.07      75.000     56.250     64.286                                 \n",
      " 9    1306.47      77.358     64.062     70.085                                 \n",
      "10    1206.40      73.684     65.625     69.421                                 \n",
      "11    1224.72      74.510     59.375     66.087                                 \n",
      "12    1314.89      73.077     59.375     65.517                                 \n",
      "13    1219.40      73.077     59.375     65.517                                 \n",
      "14    1193.32      71.698     59.375     64.957                                 \n",
      "15    1119.57      71.154     57.812     63.793                                 \n",
      "16    1117.24      70.588     56.250     62.609                                 \n",
      "17    1067.36      68.627     54.688     60.870                                 \n",
      "18    1087.17      68.627     54.688     60.870                                 \n",
      "19    1049.51      70.000     54.688     61.404                                 \n",
      "20    1108.60      67.925     56.250     61.538                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.132   67.188    73.504\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.504\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model40.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1600.65      57.143     18.750     28.235                                 \n",
      " 2    1437.82      54.286     29.688     38.384                                 \n",
      " 3    1498.85      71.930     64.062     67.769                                 \n",
      " 4    1407.49      70.690     64.062     67.213                                 \n",
      " 5    1357.41      71.429     62.500     66.667                                 \n",
      " 6    1388.41      74.545     64.062     68.908                                 \n",
      " 7    1363.74      74.545     64.062     68.908                                 \n",
      " 8    1242.85      72.222     60.938     66.102                                 \n",
      " 9    1233.88      68.421     60.938     64.463                                 \n",
      "10    1242.84      69.091     59.375     63.866                                 \n",
      "11    1151.93      71.429     62.500     66.667                                 \n",
      "12    1213.03      73.077     59.375     65.517                                 \n",
      "13    1213.62      70.909     60.938     65.546                                 \n",
      "14    1143.56      75.472     62.500     68.376                                 \n",
      "15    1118.12      75.000     60.938     67.241                                 \n",
      "16    1088.03      72.222     60.938     66.102                                 \n",
      "17    1038.61      72.727     62.500     67.227                                 \n",
      "18    1078.68      71.429     62.500     66.667                                 \n",
      "19    1052.48      70.175     62.500     66.116                                 \n",
      "20    1062.27      71.429     62.500     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   64.062    68.908\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.908\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model44.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1566.93      58.621     26.562     36.559                                 \n",
      " 2    1463.61      57.447     42.188     48.649                                 \n",
      " 3    1485.22      70.000     54.688     61.404                                 \n",
      " 4    1398.05      66.667     50.000     57.143                                 \n",
      " 5    1401.46      75.510     57.812     65.487                                 \n",
      " 6    1441.08      71.154     57.812     63.793                                 \n",
      " 7    1365.23      71.429     62.500     66.667                                 \n",
      " 8    1281.22      69.091     59.375     63.866                                 \n",
      " 9    1181.71      70.370     59.375     64.407                                 \n",
      "10    1196.62      70.175     62.500     66.116                                 \n",
      "11    1170.21      68.421     60.938     64.463                                 \n",
      "12    1243.63      68.966     62.500     65.574                                 \n",
      "13    1177.91      69.492     64.062     66.667                                 \n",
      "14    1135.75      70.312     70.312     70.312                                 \n",
      "15    1090.74      73.333     68.750     70.968                                 \n",
      "16    1096.61      71.186     65.625     68.293                                 \n",
      "17    1051.33      70.175     62.500     66.116                                 \n",
      "18    1076.22      68.966     62.500     65.574                                 \n",
      "19    1034.32      67.241     60.938     63.934                                 \n",
      "20    1051.87      68.421     60.938     64.463                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.333   68.750    70.968\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.968\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model48.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.05      55.000     34.375     42.308                                 \n",
      " 2    1392.97      53.488     35.938     42.991                                 \n",
      " 3    1453.49      69.091     59.375     63.866                                 \n",
      " 4    1423.99      65.455     56.250     60.504                                 \n",
      " 5    1476.47      62.264     51.562     56.410                                 \n",
      " 6    1355.60      72.000     56.250     63.158                                 \n",
      " 7    1354.21      69.811     57.812     63.248                                 \n",
      " 8    1242.94      69.231     56.250     62.069                                 \n",
      " 9    1186.63      70.000     54.688     61.404                                 \n",
      "10    1204.85      70.000     54.688     61.404                                 \n",
      "11    1155.13      69.388     53.125     60.177                                 \n",
      "12    1217.47      68.000     53.125     59.649                                 \n",
      "13    1180.31      70.833     53.125     60.714                                 \n",
      "14    1165.71      70.833     53.125     60.714                                 \n",
      "15    1100.92      71.739     51.562     60.000                                 \n",
      "16    1091.44      70.833     53.125     60.714                                 \n",
      "17    1022.36      66.667     53.125     59.130                                 \n",
      "18    1084.56      66.000     51.562     57.895                                 \n",
      "19    1090.36      64.706     51.562     57.391                                 \n",
      "20    1078.61      66.000     51.562     57.895                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      69.091   59.375    63.866\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m63.866\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model52.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1608.44      40.000     28.125     33.028                                 \n",
      " 2    1449.76      58.182     50.000     53.782                                 \n",
      " 3    1473.47      69.643     60.938     65.000                                 \n",
      " 4    1450.00      73.077     59.375     65.517                                 \n",
      " 5    1481.96      70.370     59.375     64.407                                 \n",
      " 6    1415.40      65.957     48.438     55.856                                 \n",
      " 7    1438.77      66.667     50.000     57.143                                 \n",
      " 8    1207.33      68.000     53.125     59.649                                 \n",
      " 9    1340.74      72.881     67.188     69.919                                 \n",
      "10    1258.67      72.414     65.625     68.852                                 \n",
      "11    1168.97      72.414     65.625     68.852                                 \n",
      "12    1239.83      70.000     65.625     67.742                                 \n",
      "13    1228.41      71.186     65.625     68.293                                 \n",
      "14    1160.43      70.000     65.625     67.742                                 \n",
      "15    1153.93      70.492     67.188     68.800                                 \n",
      "16    1134.44      75.000     70.312     72.581                                 \n",
      "17    1090.58      72.131     68.750     70.400                                 \n",
      "18    1069.41      70.968     68.750     69.841                                 \n",
      "19    1056.21      70.968     68.750     69.841                                 \n",
      "20    1092.92      71.429     70.312     70.866                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   70.312    72.581\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.581\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model56.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1591.64      61.111     34.375     44.000                                 \n",
      " 2    1406.56      58.974     35.938     44.660                                 \n",
      " 3    1485.15      60.000     46.875     52.632                                 \n",
      " 4    1447.88      65.000     60.938     62.903                                 \n",
      " 5    1390.46      75.000     56.250     64.286                                 \n",
      " 6    1414.66      71.429     54.688     61.947                                 \n",
      " 7    1378.33      72.917     54.688     62.500                                 \n",
      " 8    1250.30      71.739     51.562     60.000                                 \n",
      " 9    1257.52      73.913     53.125     61.818                                 \n",
      "10    1225.67      75.556     53.125     62.385                                 \n",
      "11    1148.38      74.074     62.500     67.797                                 \n",
      "12    1224.97      74.074     62.500     67.797                                 \n",
      "13    1156.48      74.545     64.062     68.908                                 \n",
      "14    1154.09      74.545     64.062     68.908                                 \n",
      "15    1089.64      75.472     62.500     68.376                                 \n",
      "16    1090.22      70.213     51.562     59.459                                 \n",
      "17    1041.93      70.455     48.438     57.407                                 \n",
      "18    1089.77      71.111     50.000     58.716                                 \n",
      "19    1050.11      73.333     51.562     60.550                                 \n",
      "20    1091.61      73.333     51.562     60.550                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   64.062    68.908\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.908\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model60.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1564.49      52.941     28.125     36.735                                 \n",
      " 2    1414.97      61.702     45.312     52.252                                 \n",
      " 3    1610.19      66.102     60.938     63.415                                 \n",
      " 4    1502.54      58.824     46.875     52.174                                 \n",
      " 5    1401.01      69.091     59.375     63.866                                 \n",
      " 6    1441.34      66.038     54.688     59.829                                 \n",
      " 7    1405.13      65.455     56.250     60.504                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8    1316.06      69.091     59.375     63.866                                 \n",
      " 9    1260.04      72.222     60.938     66.102                                 \n",
      "10    1273.23      70.909     60.938     65.546                                 \n",
      "11    1159.79      72.549     57.812     64.348                                 \n",
      "12    1226.75      72.549     57.812     64.348                                 \n",
      "13    1198.61      70.588     56.250     62.609                                 \n",
      "14    1210.97      70.000     54.688     61.404                                 \n",
      "15    1114.33      70.000     54.688     61.404                                 \n",
      "16    1153.35      68.627     54.688     60.870                                 \n",
      "17    1058.50      68.627     54.688     60.870                                 \n",
      "18    1094.25      70.000     54.688     61.404                                 \n",
      "19    1077.39      71.154     57.812     63.793                                 \n",
      "20    1087.05      69.811     57.812     63.248                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.222   60.938    66.102\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.102\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model64.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1541.59      58.065     28.125     37.895                                 \n",
      " 2    1429.62      63.415     40.625     49.524                                 \n",
      " 3    1413.39      75.472     62.500     68.376                                 \n",
      " 4    1412.86      71.698     59.375     64.957                                 \n",
      " 5    1405.91      63.333     59.375     61.290                                 \n",
      " 6    1353.85      67.925     56.250     61.538                                 \n",
      " 7    1357.46      65.455     56.250     60.504                                 \n",
      " 8    1272.83      65.385     53.125     58.621                                 \n",
      " 9    1249.00      65.385     53.125     58.621                                 \n",
      "10    1209.13      66.000     51.562     57.895                                 \n",
      "11    1120.88      69.231     56.250     62.069                                 \n",
      "12    1204.83      70.370     59.375     64.407                                 \n",
      "13    1177.72      67.857     59.375     63.333                                 \n",
      "14    1188.61      67.273     57.812     62.185                                 \n",
      "15    1110.20      66.667     59.375     62.810                                 \n",
      "16    1057.08      66.667     59.375     62.810                                 \n",
      "17    1046.98      64.912     57.812     61.157                                 \n",
      "18    1105.31      63.793     57.812     60.656                                 \n",
      "19    1040.24      63.333     59.375     61.290                                 \n",
      "20    1082.39      63.793     57.812     60.656                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.472   62.500    68.376\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.376\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model68.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1581.80      45.714     25.000     32.323                                 \n",
      " 2    1470.38      61.538     37.500     46.602                                 \n",
      " 3    1472.97      68.750     51.562     58.929                                 \n",
      " 4    1454.21      75.000     65.625     70.000                                 \n",
      " 5    1452.76      63.830     46.875     54.054                                 \n",
      " 6    1319.67      72.414     65.625     68.852                                 \n",
      " 7    1365.25      69.492     64.062     66.667                                 \n",
      " 8    1326.85      70.909     60.938     65.546                                 \n",
      " 9    1249.03      72.222     60.938     66.102                                 \n",
      "10    1235.53      75.000     65.625     70.000                                 \n",
      "11    1147.02      76.364     65.625     70.588                                 \n",
      "12    1231.51      76.364     65.625     70.588                                 \n",
      "13    1190.10      77.358     64.062     70.085                                 \n",
      "14    1113.84      78.431     62.500     69.565                                 \n",
      "15    1110.15      77.358     64.062     70.085                                 \n",
      "16    1113.47      75.472     62.500     68.376                                 \n",
      "17    1045.44      72.727     62.500     67.227                                 \n",
      "18    1121.51      72.881     67.188     69.919                                 \n",
      "19    1060.05      72.881     67.188     69.919                                 \n",
      "20    1090.93      73.214     64.062     68.333                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model72.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1555.27      57.576     29.688     39.175                                 \n",
      " 2    1447.05      59.184     45.312     51.327                                 \n",
      " 3    1426.93      59.649     53.125     56.198                                 \n",
      " 4    1570.45      62.745     50.000     55.652                                 \n",
      " 5    1434.99      71.429     54.688     61.947                                 \n",
      " 6    1363.70      73.469     56.250     63.717                                 \n",
      " 7    1317.33      73.469     56.250     63.717                                 \n",
      " 8    1281.66      73.214     64.062     68.333                                 \n",
      " 9    1295.42      75.926     64.062     69.492                                 \n",
      "10    1219.19      77.193     68.750     72.727                                 \n",
      "11    1132.41      77.193     68.750     72.727                                 \n",
      "12    1195.77      73.469     56.250     63.717                                 \n",
      "13    1176.86      72.917     54.688     62.500                                 \n",
      "14    1147.70      70.833     53.125     60.714                                 \n",
      "15    1142.38      69.388     53.125     60.177                                 \n",
      "16    1125.78      74.545     64.062     68.908                                 \n",
      "17    1062.35      69.643     60.938     65.000                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    1098.95      66.667     50.000     57.143                                 \n",
      "19    1116.63      65.306     50.000     56.637                                 \n",
      "20    1126.31      66.000     51.562     57.895                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.193   68.750    72.727\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.727\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model76.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1568.58      56.757     32.812     41.584                                 \n",
      " 2    1558.44      57.895     51.562     54.545                                 \n",
      " 3    1409.39      70.175     62.500     66.116                                 \n",
      " 4    1547.40      62.264     51.562     56.410                                 \n",
      " 5    1489.47      71.698     59.375     64.957                                 \n",
      " 6    1468.91      69.811     57.812     63.248                                 \n",
      " 7    1369.79      71.698     59.375     64.957                                 \n",
      " 8    1299.69      64.583     48.438     55.357                                 \n",
      " 9    1244.94      62.712     57.812     60.163                                 \n",
      "10    1231.10      64.286     56.250     60.000                                 \n",
      "11    1161.29      67.213     64.062     65.600                                 \n",
      "12    1224.88      67.213     64.062     65.600                                 \n",
      "13    1131.06      70.690     64.062     67.213                                 \n",
      "14    1161.37      70.492     67.188     68.800                                 \n",
      "15    1130.25      74.138     67.188     70.492                                 \n",
      "16    1095.18      70.492     67.188     68.800                                 \n",
      "17    1042.39      72.881     67.188     69.919                                 \n",
      "18    1086.17      71.186     65.625     68.293                                 \n",
      "19    1070.61      71.667     67.188     69.355                                 \n",
      "20    1076.24      70.492     67.188     68.800                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.138   67.188    70.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model8.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1575.80      56.250     28.125     37.500                                 \n",
      " 2    1453.59      59.459     34.375     43.564                                 \n",
      " 3    1473.61      59.184     45.312     51.327                                 \n",
      " 4    1445.04      59.574     43.750     50.450                                 \n",
      " 5    1398.35      73.810     48.438     58.491                                 \n",
      " 6    1358.28      74.468     54.688     63.063                                 \n",
      " 7    1358.68      72.000     56.250     63.158                                 \n",
      " 8    1276.02      80.851     59.375     68.468                                 \n",
      " 9    1257.82      79.167     59.375     67.857                                 \n",
      "10    1240.46      80.000     62.500     70.175                                 \n",
      "11    1149.84      76.471     60.938     67.826                                 \n",
      "12    1261.24      77.358     64.062     70.085                                 \n",
      "13    1163.79      75.926     64.062     69.492                                 \n",
      "14    1158.15      73.585     60.938     66.667                                 \n",
      "15    1129.25      72.222     60.938     66.102                                 \n",
      "16    1123.23      68.519     57.812     62.712                                 \n",
      "17    1061.33      71.698     59.375     64.957                                 \n",
      "18    1074.15      72.222     60.938     66.102                                 \n",
      "19    1062.43      72.222     60.938     66.102                                 \n",
      "20    1106.10      72.222     60.938     66.102                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      80.000   62.500    70.175\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.175\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model80.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1526.72      51.429     28.125     36.364                                 \n",
      " 2    1419.59      66.000     51.562     57.895                                 \n",
      " 3    1430.27      63.043     45.312     52.727                                 \n",
      " 4    1500.66      63.265     48.438     54.867                                 \n",
      " 5    1457.04      62.264     51.562     56.410                                 \n",
      " 6    1391.59      66.667     59.375     62.810                                 \n",
      " 7    1390.42      76.364     65.625     70.588                                 \n",
      " 8    1235.80      77.193     68.750     72.727                                 \n",
      " 9    1243.79      72.881     67.188     69.919                                 \n",
      "10    1298.22      71.667     67.188     69.355                                 \n",
      "11    1158.56      69.355     67.188     68.254                                 \n",
      "12    1245.47      68.254     67.188     67.717                                 \n",
      "13    1180.94      67.188     67.188     67.188                                 \n",
      "14    1151.15      70.968     68.750     69.841                                 \n",
      "15    1126.85      73.684     65.625     69.421                                 \n",
      "16    1124.71      70.175     62.500     66.116                                 \n",
      "17    1061.68      74.074     62.500     67.797                                 \n",
      "18    1054.66      74.074     62.500     67.797                                 \n",
      "19    1074.99      75.472     62.500     68.376                                 \n",
      "20    1092.19      72.727     62.500     67.227                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.193   68.750    72.727\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.727\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model84.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    1594.49      50.000     31.250     38.462                                 \n",
      " 2    1533.16      57.778     40.625     47.706                                 \n",
      " 3    1441.69      67.925     56.250     61.538                                 \n",
      " 4    1435.46      72.727     62.500     67.227                                 \n",
      " 5    1430.99      70.909     60.938     65.546                                 \n",
      " 6    1473.48      69.492     64.062     66.667                                 \n",
      " 7    1372.04      70.492     67.188     68.800                                 \n",
      " 8    1233.47      71.429     70.312     70.866                                 \n",
      " 9    1210.81      76.271     70.312     73.171                                 \n",
      "10    1187.56      72.414     65.625     68.852                                 \n",
      "11    1180.02      75.926     64.062     69.492                                 \n",
      "12    1275.10      75.000     60.938     67.241                                 \n",
      "13    1189.34      76.000     59.375     66.667                                 \n",
      "14    1154.50      75.000     60.938     67.241                                 \n",
      "15    1133.33      75.000     60.938     67.241                                 \n",
      "16    1129.77      74.000     57.812     64.912                                 \n",
      "17    1075.04      69.231     56.250     62.069                                 \n",
      "18    1083.14      73.077     59.375     65.517                                 \n",
      "19    1062.48      73.077     59.375     65.517                                 \n",
      "20    1062.85      74.074     62.500     67.797                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.271   70.312    73.171\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.171\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model88.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1607.17      51.429     28.125     36.364                                 \n",
      " 2    1477.03      55.000     51.562     53.226                                 \n",
      " 3    1488.43      65.517     59.375     62.295                                 \n",
      " 4    1531.81      62.712     57.812     60.163                                 \n",
      " 5    1466.97      63.636     54.688     58.824                                 \n",
      " 6    1420.66      64.912     57.812     61.157                                 \n",
      " 7    1362.49      66.071     57.812     61.667                                 \n",
      " 8    1221.75      60.714     53.125     56.667                                 \n",
      " 9    1302.77      67.241     60.938     63.934                                 \n",
      "10    1238.43      65.574     62.500     64.000                                 \n",
      "11    1148.25      65.574     62.500     64.000                                 \n",
      "12    1237.15      64.516     62.500     63.492                                 \n",
      "13    1168.22      65.574     62.500     64.000                                 \n",
      "14    1139.98      64.516     62.500     63.492                                 \n",
      "15    1110.94      65.574     62.500     64.000                                 \n",
      "16    1094.39      65.000     60.938     62.903                                 \n",
      "17    1045.28      66.102     60.938     63.415                                 \n",
      "18    1152.52      66.102     60.938     63.415                                 \n",
      "19    1116.45      67.213     64.062     65.600                                 \n",
      "20    1106.81      68.254     67.188     67.717                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      68.254   67.188    67.717\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.717\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model92.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1606.75      50.000     25.000     33.333                                 \n",
      " 2    1427.60      62.000     48.438     54.386                                 \n",
      " 3    1501.49      71.930     64.062     67.769                                 \n",
      " 4    1419.00      73.469     56.250     63.717                                 \n",
      " 5    1399.92      64.151     53.125     58.120                                 \n",
      " 6    1385.40      58.824     46.875     52.174                                 \n",
      " 7    1378.45      64.815     54.688     59.322                                 \n",
      " 8    1263.18      60.377     50.000     54.701                                 \n",
      " 9    1259.58      60.345     54.688     57.377                                 \n",
      "10    1238.35      60.000     56.250     58.065                                 \n",
      "11    1140.67      64.815     54.688     59.322                                 \n",
      "12    1248.47      65.455     56.250     60.504                                 \n",
      "13    1241.36      64.286     56.250     60.000                                 \n",
      "14    1168.94      66.667     56.250     61.017                                 \n",
      "15    1144.89      63.462     51.562     56.897                                 \n",
      "16    1159.38      66.667     53.125     59.130                                 \n",
      "17    1067.97      65.385     53.125     58.621                                 \n",
      "18    1091.08      61.538     50.000     55.172                                 \n",
      "19    1046.94      64.000     50.000     56.140                                 \n",
      "20    1101.95      64.000     50.000     56.140                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.930   64.062    67.769\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.769\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model96.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1602.98      55.882     29.688     38.776                                 \n",
      " 2    1439.73      63.043     45.312     52.727                                 \n",
      " 3    1519.90      64.407     59.375     61.789                                 \n",
      " 4    1479.68      64.815     54.688     59.322                                 \n",
      " 5    1456.75      61.818     53.125     57.143                                 \n",
      " 6    1392.80      66.667     62.500     64.516                                 \n",
      " 7    1349.02      71.930     64.062     67.769                                 \n",
      " 8    1329.47      68.750     51.562     58.929                                 \n",
      " 9    1230.68      70.588     56.250     62.609                                 \n",
      "10    1188.68      67.273     57.812     62.185                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    1161.85      68.519     57.812     62.712                                 \n",
      "12    1237.67      70.370     59.375     64.407                                 \n",
      "13    1165.27      70.909     60.938     65.546                                 \n",
      "14    1132.21      72.000     56.250     63.158                                 \n",
      "15    1106.33      72.000     56.250     63.158                                 \n",
      "16    1117.46      72.549     57.812     64.348                                 \n",
      "17    1062.85      73.077     59.375     65.517                                 \n",
      "18    1063.79      71.429     54.688     61.947                                 \n",
      "19    1058.69      72.000     56.250     63.158                                 \n",
      "20    1078.07      68.627     54.688     60.870                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.930   64.062    67.769\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.769\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# run training for a selected models, use every skip_models-th file\n",
    "skip_models = 4\n",
    "abs_models_dir = Path('models/tok2vec_abs_sci_ALL_gpu')\n",
    "\n",
    "for model_file in sorted(os.listdir(abs_models_dir)):\n",
    "    model_id = int(model_file.replace('model', '').replace('.bin', ''))\n",
    "    if model_id < 100 and model_id % skip_models == 0:\n",
    "        model_path = abs_models_dir / model_file\n",
    "        !prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg \\\n",
    "            --eval-split 0.2 --n-iter 20 --init-tok2vec $model_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
