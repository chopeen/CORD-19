{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.06 (Mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`RF sentences`)\n",
    "\n",
    "Following the official guide:\n",
    "- https://www.youtube.com/watch?v=59BKHO_xBPA\n",
    "- https://github.com/explosion/projects/tree/master/ner-food-ingredients#data-creation-and-training-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "\n",
      "‚ú®  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m‚úî Saved 102 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences\n",
      "Session ID: 2020-04-06_22-08-56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual cord_19_rf_sentences blank:en data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     389.18       0.000      0.000      0.000                                 \n",
      " 2     191.03      25.000      4.000      6.897                                 \n",
      " 3     265.45      35.294     24.000     28.571                                 \n",
      " 4     246.57      28.571     24.000     26.087                                 \n",
      " 5     239.21      22.727     20.000     21.277                                 \n",
      " 6     215.80      42.857     24.000     30.769                                 \n",
      " 7     258.40      42.105     32.000     36.364                                 \n",
      " 8     237.19      50.000     32.000     39.024                                 \n",
      " 9     208.67      62.500     40.000     48.780                                 \n",
      "10     141.30      66.667     40.000     50.000                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667   40.000    50.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m50.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1421.81       0.000      0.000      0.000                                 \n",
      " 2    1245.16       0.000      0.000      0.000                                 \n",
      " 3    1262.77       0.000      0.000      0.000                                 \n",
      " 4    1249.04       0.000      0.000      0.000                                 \n",
      " 5    1262.46       0.000      0.000      0.000                                 \n",
      " 6    1205.26       0.000      0.000      0.000                                 \n",
      " 7    1137.92       0.000      0.000      0.000                                 \n",
      " 8    1131.84       0.000      0.000      0.000                                 \n",
      " 9    1058.85       0.000      0.000      0.000                                 \n",
      "10    1143.62       0.000      0.000      0.000                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "GPE               0.000    0.000     0.000\n",
      "RISK_FACTOR       0.000    0.000     0.000\n",
      "CARDINAL          0.000    0.000     0.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m0.000\u001b[0m\n",
      "Baseline       0.000             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÅâÔ∏è Why is `en_core_web_lg` producing no results at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     559.17       0.000      0.000      0.000                                 \n",
      " 2     550.33      33.333      8.000     12.903                                 \n",
      " 3     538.43      50.000     24.000     32.432                                 \n",
      " 4     457.89      52.632     40.000     45.455                                 \n",
      " 5     452.06      50.000     36.000     41.860                                 \n",
      " 6     415.01      60.000     48.000     53.333                                 \n",
      " 7     489.45      47.826     44.000     45.833                                 \n",
      " 8     461.13      45.000     36.000     40.000                                 \n",
      " 9     486.03      47.619     40.000     43.478                                 \n",
      "10     406.83      54.545     48.000     51.064                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   48.000    53.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m53.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m‚úî Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_06_rf_sentences\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 --output models/2020_04_06_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "embed_rows: 2000 | require_vectors: True | cnn_maxout_pieces: 3 |\n",
      "token_vector_width: 96 | conv_depth: 4 | nr_feature_tokens: 3 |\n",
      "pretrained_vectors: en_vectors_web_lg.vectors\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     339.88       0.000      0.000      0.000                                 \n",
      " 2     199.85      50.000     16.000     24.242                                 \n",
      " 3     128.26      50.000     28.000     35.897                                 \n",
      " 4      76.43      42.857     24.000     30.769                                 \n",
      " 5      63.28      60.000     36.000     45.000                                 \n",
      " 6      29.70      53.333     32.000     40.000                                 \n",
      " 7      21.18      56.250     36.000     43.902                                 \n",
      " 8      36.86      50.000     36.000     41.860                                 \n",
      " 9      13.28      52.941     36.000     42.857                                 \n",
      "10       7.74      52.941     36.000     42.857                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   36.000    45.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m45.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2055.18       0.000      0.000      0.000                                 \n",
      " 2    1808.48       0.000      0.000      0.000                                 \n",
      " 3    1624.76       0.000      0.000      0.000                                 \n",
      " 4    1443.31       0.000      0.000      0.000                                 \n",
      " 5    1652.93       0.000      0.000      0.000                                 \n",
      " 6    1470.22       0.000      0.000      0.000                                 \n",
      " 7    1345.14       0.000      0.000      0.000                                 \n",
      " 8    1403.16      50.000      4.000      7.407                                 \n",
      " 9    1249.90      66.667      8.000     14.286                                 \n",
      "10    1357.22      66.667      8.000     14.286                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667    8.000    14.286\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m14.286\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     536.68       0.000      0.000      0.000                                 \n",
      " 2     631.61       0.000      0.000      0.000                                 \n",
      " 3     539.99      40.000     24.000     30.000                                 \n",
      " 4     505.27      47.619     40.000     43.478                                 \n",
      " 5     508.05      45.000     36.000     40.000                                 \n",
      " 6     461.69      52.941     36.000     42.857                                 \n",
      " 7     473.25      45.000     36.000     40.000                                 \n",
      " 8     571.35      61.111     44.000     51.163                                 \n",
      " 9     465.27      55.556     40.000     46.512                                 \n",
      "10     455.26      43.750     28.000     34.146                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      61.111   44.000    51.163\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m51.163\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• Top model so far: `53.333` üî•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label more data by correcting the model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_rf_sentences_correct to database SQLite.\n",
      "\n",
      "‚ú®  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m‚úî Saved 220 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences_correct\n",
      "Session ID: 2020-04-06_23-58-48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.correct cord_19_rf_sentences_correct models/2020_04_06_rf_sentences data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR --exclude cord_19_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For futher training, only `en_core_sci_lg` will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1554.25      61.538     37.500     46.602                                 \n",
      " 2    1346.09      64.407     59.375     61.789                                 \n",
      " 3    1407.15      66.667     50.000     57.143                                 \n",
      " 4    1411.73      72.727     50.000     59.259                                 \n",
      " 5    1412.81      73.913     53.125     61.818                                 \n",
      " 6    1319.96      73.913     53.125     61.818                                 \n",
      " 7    1378.05      72.917     54.688     62.500                                 \n",
      " 8    1208.99      72.727     62.500     67.227                                 \n",
      " 9    1177.16      73.077     59.375     65.517                                 \n",
      "10    1211.40      72.549     57.812     64.348                                 \n",
      "11    1142.34      74.510     59.375     66.087                                 \n",
      "12    1196.27      72.000     56.250     63.158                                 \n",
      "13    1153.93      72.000     56.250     63.158                                 \n",
      "14    1149.78      72.549     57.812     64.348                                 \n",
      "15    1154.34      69.231     56.250     62.069                                 \n",
      "16    1104.68      69.231     56.250     62.069                                 \n",
      "17    1062.17      68.627     54.688     60.870                                 \n",
      "18    1063.28      68.627     54.688     60.870                                 \n",
      "19    1048.51      68.627     54.688     60.870                                 \n",
      "20    1120.40      68.627     54.688     60.870                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.727   62.500    67.227\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.227\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1578.16      64.000     25.000     35.955                                 \n",
      " 2    1439.61      55.319     40.625     46.847                                 \n",
      " 3    1528.20      72.222     60.938     66.102                                 \n",
      " 4    1429.18      71.154     57.812     63.793                                 \n",
      " 5    1414.46      69.388     53.125     60.177                                 \n",
      " 6    1344.69      75.472     62.500     68.376                                 \n",
      " 7    1472.62      70.909     60.938     65.546                                 \n",
      " 8    1296.39      74.545     64.062     68.908                                 \n",
      " 9    1285.11      68.966     62.500     65.574                                 \n",
      "10    1236.84      70.175     62.500     66.116                                 \n",
      "11    1181.13      71.429     62.500     66.667                                 \n",
      "12    1235.60      70.909     60.938     65.546                                 \n",
      "13    1238.99      76.923     62.500     68.966                                 \n",
      "14    1151.94      75.926     64.062     69.492                                 \n",
      "15    1151.25      75.926     64.062     69.492                                 \n",
      "16    1218.30      78.000     60.938     68.421                                 \n",
      "17    1074.01      75.926     64.062     69.492                                 \n",
      "18    1121.71      76.364     65.625     70.588                                 \n",
      "19    1084.27      77.358     64.062     70.085                                 \n",
      "20    1106.32      76.471     60.938     67.826                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m‚úî Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_07_rf_sentences_corrected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin --output models/2020_04_07_rf_sentences_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.28      62.500     23.438     34.091                                 \n",
      " 2    1397.40      59.091     40.625     48.148                                 \n",
      " 3    1485.47      70.833     53.125     60.714                                 \n",
      " 4    1445.56      68.293     43.750     53.333                                 \n",
      " 5    1431.31      64.000     50.000     56.140                                 \n",
      " 6    1339.87      70.833     53.125     60.714                                 \n",
      " 7    1387.07      72.340     53.125     61.261                                 \n",
      " 8    1232.74      76.596     56.250     64.865                                 \n",
      " 9    1207.39      72.340     53.125     61.261                                 \n",
      "10    1231.53      75.926     64.062     69.492                                 \n",
      "11    1154.22      74.545     64.062     68.908                                 \n",
      "12    1304.76      75.472     62.500     68.376                                 \n",
      "13    1155.21      69.811     57.812     63.248                                 \n",
      "14    1158.97      67.273     57.812     62.185                                 \n",
      "15    1092.88      69.811     57.812     63.248                                 \n",
      "16    1134.04      68.627     54.688     60.870                                 \n",
      "17    1055.42      66.667     56.250     61.017                                 \n",
      "18    1071.15      66.667     56.250     61.017                                 \n",
      "19    1060.90      69.231     56.250     62.069                                 \n",
      "20    1063.32      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model989.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.09 (Thu)\n",
    "## Experiments with new `tok2vec` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1577.68      57.895     34.375     43.137                                 \n",
      " 2    1386.95      67.308     54.688     60.345                                 \n",
      " 3    1455.49      76.596     56.250     64.865                                 \n",
      " 4    1457.04      79.592     60.938     69.027                                 \n",
      " 5    1413.30      78.431     62.500     69.565                                 \n",
      " 6    1351.85      76.923     62.500     68.966                                 \n",
      " 7    1304.38      78.000     60.938     68.421                                 \n",
      " 8    1255.67      76.471     60.938     67.826                                 \n",
      " 9    1219.66      78.431     62.500     69.565                                 \n",
      "10    1203.83      74.545     64.062     68.908                                 \n",
      "11    1125.02      74.545     64.062     68.908                                 \n",
      "12    1224.65      74.074     62.500     67.797                                 \n",
      "13    1173.56      75.000     60.938     67.241                                 \n",
      "14    1170.88      75.000     60.938     67.241                                 \n",
      "15    1074.42      71.154     57.812     63.793                                 \n",
      "16    1144.97      75.000     60.938     67.241                                 \n",
      "17    1041.02      73.077     59.375     65.517                                 \n",
      "18    1094.32      74.510     59.375     66.087                                 \n",
      "19    1051.65      74.510     59.375     66.087                                 \n",
      "20    1099.61      78.000     60.938     68.421                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.431   62.500    69.565\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.565\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model978_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1630.03      55.556     23.438     32.967                                 \n",
      " 2    1442.41      55.556     46.875     50.847                                 \n",
      " 3    1429.19      65.957     48.438     55.856                                 \n",
      " 4    1467.20      65.455     56.250     60.504                                 \n",
      " 5    1467.20      69.643     60.938     65.000                                 \n",
      " 6    1376.49      67.241     60.938     63.934                                 \n",
      " 7    1324.06      73.585     60.938     66.667                                 \n",
      " 8    1261.74      75.472     62.500     68.376                                 \n",
      " 9    1229.62      77.358     64.062     70.085                                 \n",
      "10    1162.35      74.545     64.062     68.908                                 \n",
      "11    1129.31      72.727     62.500     67.227                                 \n",
      "12    1226.05      73.684     65.625     69.421                                 \n",
      "13    1154.44      73.684     65.625     69.421                                 \n",
      "14    1146.38      69.492     64.062     66.667                                 \n",
      "15    1157.15      70.175     62.500     66.116                                 \n",
      "16    1122.06      72.549     57.812     64.348                                 \n",
      "17    1069.36      70.909     60.938     65.546                                 \n",
      "18    1112.07      71.930     64.062     67.769                                 \n",
      "19    1040.95      70.370     59.375     64.407                                 \n",
      "20    1074.33      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   64.062    70.085\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.085\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model997_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1587.95      62.963     26.562     37.363                                 \n",
      " 2    1500.37      60.784     48.438     53.913                                 \n",
      " 3    1510.36      63.492     62.500     62.992                                 \n",
      " 4    1519.20      60.000     56.250     58.065                                 \n",
      " 5    1521.26      65.574     62.500     64.000                                 \n",
      " 6    1495.73      64.912     57.812     61.157                                 \n",
      " 7    1386.50      65.517     59.375     62.295                                 \n",
      " 8    1225.63      65.574     62.500     64.000                                 \n",
      " 9    1277.40      65.079     64.062     64.567                                 \n",
      "10    1258.71      62.903     60.938     61.905                                 \n",
      "11    1151.32      61.905     60.938     61.417                                 \n",
      "12    1249.35      63.793     57.812     60.656                                 \n",
      "13    1169.56      67.241     60.938     63.934                                 \n",
      "14    1163.40      65.517     59.375     62.295                                 \n",
      "15    1137.84      65.517     59.375     62.295                                 \n",
      "16    1137.22      67.241     60.938     63.934                                 \n",
      "17    1094.24      67.857     59.375     63.333                                 \n",
      "18    1079.29      63.793     57.812     60.656                                 \n",
      "19    1028.63      63.158     56.250     59.504                                 \n",
      "20    1096.86      63.158     56.250     59.504                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.079   64.062    64.567\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.567\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_abs_fil_sci_model975_gpu.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.10 (Fri)\n",
    "## Experiments with new `tok2vec` models (cont.)\n",
    "\n",
    "The Kaggle notebook training models for the full set of abstracts (i.e. `cord_19_abstracts.jsonl`) crashed, so I have only partial results and no loss metrics for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model100.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.29      43.478     31.250     36.364                                 \n",
      " 2    1421.36      59.574     43.750     50.450                                 \n",
      " 3    1486.19      68.519     57.812     62.712                                 \n",
      " 4    1477.14      70.000     54.688     61.404                                 \n",
      " 5    1389.42      73.469     56.250     63.717                                 \n",
      " 6    1377.87      70.000     54.688     61.404                                 \n",
      " 7    1379.27      65.385     53.125     58.621                                 \n",
      " 8    1256.60      64.151     53.125     58.120                                 \n",
      " 9    1242.36      66.038     54.688     59.829                                 \n",
      "10    1237.03      63.636     54.688     58.824                                 \n",
      "11    1130.25      65.385     53.125     58.621                                 \n",
      "12    1249.05      65.455     56.250     60.504                                 \n",
      "13    1186.25      68.519     57.812     62.712                                 \n",
      "14    1166.91      68.519     57.812     62.712                                 \n",
      "15    1119.23      66.071     57.812     61.667                                 \n",
      "16    1100.72      67.925     56.250     61.538                                 \n",
      "17    1057.66      74.576     68.750     71.545                                 \n",
      "18    1086.26      74.138     67.188     70.492                                 \n",
      "19    1057.49      69.841     68.750     69.291                                 \n",
      "20    1090.37      73.684     65.625     69.421                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model113.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1576.82      54.167     40.625     46.429                                 \n",
      " 2    1441.99      56.522     40.625     47.273                                 \n",
      " 3    1413.20      71.429     62.500     66.667                                 \n",
      " 4    1530.83      68.519     57.812     62.712                                 \n",
      " 5    1508.39      70.968     68.750     69.841                                 \n",
      " 6    1418.20      71.930     64.062     67.769                                 \n",
      " 7    1390.90      74.576     68.750     71.545                                 \n",
      " 8    1306.18      69.492     64.062     66.667                                 \n",
      " 9    1288.81      69.355     67.188     68.254                                 \n",
      "10    1235.70      67.692     68.750     68.217                                 \n",
      "11    1176.14      68.852     65.625     67.200                                 \n",
      "12    1225.75      71.186     65.625     68.293                                 \n",
      "13    1223.52      71.186     65.625     68.293                                 \n",
      "14    1144.79      70.370     59.375     64.407                                 \n",
      "15    1097.53      71.429     62.500     66.667                                 \n",
      "16    1107.15      71.429     62.500     66.667                                 \n",
      "17    1077.94      69.643     60.938     65.000                                 \n",
      "18    1110.78      72.222     60.938     66.102                                 \n",
      "19    1034.04      71.698     59.375     64.957                                 \n",
      "20    1096.63      71.429     62.500     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model126.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1606.39      43.636     37.500     40.336                                 \n",
      " 2    1452.80      60.000     51.562     55.462                                 \n",
      " 3    1437.93      59.677     57.812     58.730                                 \n",
      " 4    1419.75      63.043     45.312     52.727                                 \n",
      " 5    1400.15      67.925     56.250     61.538                                 \n",
      " 6    1396.64      68.750     51.562     58.929                                 \n",
      " 7    1385.28      66.667     59.375     62.810                                 \n",
      " 8    1260.33      66.667     59.375     62.810                                 \n",
      " 9    1228.95      69.231     56.250     62.069                                 \n",
      "10    1247.29      66.667     56.250     61.017                                 \n",
      "11    1176.21      66.102     60.938     63.415                                 \n",
      "12    1288.26      66.667     59.375     62.810                                 \n",
      "13    1179.91      69.091     59.375     63.866                                 \n",
      "14    1154.00      70.175     62.500     66.116                                 \n",
      "15    1152.69      68.966     62.500     65.574                                 \n",
      "16    1109.37      68.966     62.500     65.574                                 \n",
      "17    1050.43      67.857     59.375     63.333                                 \n",
      "18    1085.32      68.421     60.938     64.463                                 \n",
      "19    1029.84      64.706     51.562     57.391                                 \n",
      "20    1096.32      67.347     51.562     58.407                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.175   62.500    66.116\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.116\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model139.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1563.29      51.020     39.062     44.248                                 \n",
      " 2    1501.66      58.333     43.750     50.000                                 \n",
      " 3    1542.60      67.188     67.188     67.188                                 \n",
      " 4    1474.47      72.222     60.938     66.102                                 \n",
      " 5    1509.19      75.000     56.250     64.286                                 \n",
      " 6    1413.26      68.000     53.125     59.649                                 \n",
      " 7    1335.99      68.627     54.688     60.870                                 \n",
      " 8    1413.31      64.706     51.562     57.391                                 \n",
      " 9    1186.98      66.667     56.250     61.017                                 \n",
      "10    1248.32      69.231     56.250     62.069                                 \n",
      "11    1140.08      69.388     53.125     60.177                                 \n",
      "12    1236.78      68.750     51.562     58.929                                 \n",
      "13    1175.07      65.385     53.125     58.621                                 \n",
      "14    1142.11      65.385     53.125     58.621                                 \n",
      "15    1129.54      66.038     54.688     59.829                                 \n",
      "16    1106.93      68.750     51.562     58.929                                 \n",
      "17    1070.87      70.213     51.562     59.459                                 \n",
      "18    1088.39      70.213     51.562     59.459                                 \n",
      "19    1034.52      70.213     51.562     59.459                                 \n",
      "20    1128.90      68.750     51.562     58.929                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      67.188   67.188    67.188\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.188\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model152.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1571.39      58.140     39.062     46.729                                 \n",
      " 2    1510.07      60.000     46.875     52.632                                 \n",
      " 3    1489.39      72.917     54.688     62.500                                 \n",
      " 4    1469.38      69.643     60.938     65.000                                 \n",
      " 5    1444.18      70.833     53.125     60.714                                 \n",
      " 6    1500.48      68.085     50.000     57.658                                 \n",
      " 7    1316.60      68.085     50.000     57.658                                 \n",
      " 8    1286.18      68.750     51.562     58.929                                 \n",
      " 9    1264.42      71.429     54.688     61.947                                 \n",
      "10    1190.15      73.913     53.125     61.818                                 \n",
      "11    1131.21      75.510     57.812     65.487                                 \n",
      "12    1242.04      76.923     62.500     68.966                                 \n",
      "13    1185.61      72.340     53.125     61.261                                 \n",
      "14    1145.75      72.340     53.125     61.261                                 \n",
      "15    1116.77      75.472     62.500     68.376                                 \n",
      "16    1116.36      75.472     62.500     68.376                                 \n",
      "17    1059.02      73.585     60.938     66.667                                 \n",
      "18    1068.08      73.585     60.938     66.667                                 \n",
      "19    1059.03      75.472     62.500     68.376                                 \n",
      "20    1074.62      75.000     60.938     67.241                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.923   62.500    68.966\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.966\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model165.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1547.07      74.194     35.938     48.421                                 \n",
      " 2    1462.56      62.069     56.250     59.016                                 \n",
      " 3    1496.71      70.690     64.062     67.213                                 \n",
      " 4    1449.38      74.074     62.500     67.797                                 \n",
      " 5    1418.87      77.358     64.062     70.085                                 \n",
      " 6    1337.26      75.926     64.062     69.492                                 \n",
      " 7    1383.02      72.414     65.625     68.852                                 \n",
      " 8    1291.23      68.852     65.625     67.200                                 \n",
      " 9    1266.25      71.186     65.625     68.293                                 \n",
      "10    1185.12      69.355     67.188     68.254                                 \n",
      "11    1158.02      72.881     67.188     69.919                                 \n",
      "12    1188.67      73.333     68.750     70.968                                 \n",
      "13    1160.96      73.214     64.062     68.333                                 \n",
      "14    1138.56      71.930     64.062     67.769                                 \n",
      "15    1126.51      72.881     67.188     69.919                                 \n",
      "16    1089.93      71.186     65.625     68.293                                 \n",
      "17    1036.84      70.175     62.500     66.116                                 \n",
      "18    1102.04      69.643     60.938     65.000                                 \n",
      "19    1049.66      69.643     60.938     65.000                                 \n",
      "20    1071.79      68.421     60.938     64.463                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.333   68.750    70.968\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.968\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2Kading 'en_core_sci_lg'...\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model178.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1548.43      60.976     39.062     47.619                                 \n",
      " 2    1396.43      63.043     45.312     52.727                                 \n",
      " 3    1488.35      68.085     50.000     57.658                                 \n",
      " 4    1412.67      69.565     50.000     58.182                                 \n",
      " 5    1416.63      65.957     48.438     55.856                                 \n",
      " 6    1373.68      71.111     50.000     58.716                                 \n",
      " 7    1388.35      75.472     62.500     68.376                                 \n",
      " 8    1260.08      69.388     53.125     60.177                                 \n",
      " 9    1297.26      71.429     54.688     61.947                                 \n",
      "10    1221.41      71.429     54.688     61.947                                 \n",
      "11    1112.34      76.364     65.625     70.588                                 \n",
      "12    1259.60      67.857     59.375     63.333                                 \n",
      "13    1150.64      66.071     57.812     61.667                                 \n",
      "14    1120.27      67.308     54.688     60.345                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    1143.57      69.231     56.250     62.069                                 \n",
      "16    1108.60      69.091     59.375     63.866                                 \n",
      "17    1037.24      66.667     59.375     62.810                                 \n",
      "18    1059.90      67.857     59.375     63.333                                 \n",
      "19    1029.31      65.517     59.375     62.295                                 \n",
      "20    1091.05      67.797     62.500     65.041                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model191.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1531.35      54.839     26.562     35.789                                 \n",
      " 2    1411.43      65.909     45.312     53.704                                 \n",
      " 3    1398.77      67.391     48.438     56.364                                 \n",
      " 4    1362.76      66.667     56.250     61.017                                 \n",
      " 5    1381.48      70.909     60.938     65.546                                 \n",
      " 6    1355.07      76.364     65.625     70.588                                 \n",
      " 7    1335.37      73.585     60.938     66.667                                 \n",
      " 8    1285.76      68.750     51.562     58.929                                 \n",
      " 9    1227.28      77.778     65.625     71.186                                 \n",
      "10    1201.31      78.182     67.188     72.269                                 \n",
      "11    1149.59      73.469     56.250     63.717                                 \n",
      "12    1275.63      73.469     56.250     63.717                                 \n",
      "13    1207.65      76.364     65.625     70.588                                 \n",
      "14    1130.14      74.576     68.750     71.545                                 \n",
      "15    1099.09      71.186     65.625     68.293                                 \n",
      "16    1126.79      70.690     64.062     67.213                                 \n",
      "17    1046.66      71.930     64.062     67.769                                 \n",
      "18    1065.97      71.186     65.625     68.293                                 \n",
      "19    1034.82      72.414     65.625     68.852                                 \n",
      "20    1099.55      72.414     65.625     68.852                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model204.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1559.76      60.606     31.250     41.237                                 \n",
      " 2    1453.45      50.820     48.438     49.600                                 \n",
      " 3    1409.66      65.079     64.062     64.567                                 \n",
      " 4    1475.36      73.684     65.625     69.421                                 \n",
      " 5    1361.59      71.186     65.625     68.293                                 \n",
      " 6    1355.81      71.186     65.625     68.293                                 \n",
      " 7    1318.82      73.585     60.938     66.667                                 \n",
      " 8    1249.84      68.627     54.688     60.870                                 \n",
      " 9    1261.36      71.667     67.188     69.355                                 \n",
      "10    1192.93      70.690     64.062     67.213                                 \n",
      "11    1132.25      71.667     67.188     69.355                                 \n",
      "12    1208.10      68.333     64.062     66.129                                 \n",
      "13    1172.95      67.213     64.062     65.600                                 \n",
      "14    1127.60      71.930     64.062     67.769                                 \n",
      "15    1129.79      68.852     65.625     67.200                                 \n",
      "16    1101.97      71.186     65.625     68.293                                 \n",
      "17    1044.06      72.414     65.625     68.852                                 \n",
      "18    1063.17      73.684     65.625     69.421                                 \n",
      "19    1053.16      70.175     62.500     66.116                                 \n",
      "20    1088.13      69.643     60.938     65.000                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model217.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1588.40      50.000     34.375     40.741                                 \n",
      " 2    1381.86      64.444     45.312     53.211                                 \n",
      " 3    1377.05      72.549     57.812     64.348                                 \n",
      " 4    1447.86      79.592     60.938     69.027                                 \n",
      " 5    1434.80      77.193     68.750     72.727                                 \n",
      " 6    1396.29      76.667     71.875     74.194                                 \n",
      " 7    1305.60      76.667     71.875     74.194                                 \n",
      " 8    1262.80      71.429     70.312     70.866                                 \n",
      " 9    1177.84      69.231     70.312     69.767                                 \n",
      "10    1187.94      71.186     65.625     68.293                                 \n",
      "11    1123.51      71.930     64.062     67.769                                 \n",
      "12    1221.49      70.690     64.062     67.213                                 \n",
      "13    1162.42      73.214     64.062     68.333                                 \n",
      "14    1143.42      73.585     60.938     66.667                                 \n",
      "15    1102.69      69.643     60.938     65.000                                 \n",
      "16    1078.37      70.909     60.938     65.546                                 \n",
      "17    1052.39      72.222     60.938     66.102                                 \n",
      "18    1064.30      74.545     64.062     68.908                                 \n",
      "19    1045.06      74.545     64.062     68.908                                 \n",
      "20    1089.94      73.214     64.062     68.333                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.667   71.875    74.194\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.194\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model230.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1537.49      65.714     35.938     46.465                                 \n",
      " 2    1506.48      51.064     37.500     43.243                                 \n",
      " 3    1436.09      68.627     54.688     60.870                                 \n",
      " 4    1438.86      67.925     56.250     61.538                                 \n",
      " 5    1471.17      58.730     57.812     58.268                                 \n",
      " 6    1395.94      76.786     67.188     71.667                                 \n",
      " 7    1329.15      71.186     65.625     68.293                                 \n",
      " 8    1224.20      70.000     65.625     67.742                                 \n",
      " 9    1212.04      72.222     60.938     66.102                                 \n",
      "10    1220.04      74.074     62.500     67.797                                 \n",
      "11    1146.63      77.358     64.062     70.085                                 \n",
      "12    1201.44      78.846     64.062     70.690                                 \n",
      "13    1193.53      73.214     64.062     68.333                                 \n",
      "14    1151.32      73.214     64.062     68.333                                 \n",
      "15    1174.86      72.414     65.625     68.852                                 \n",
      "16    1132.91      75.000     65.625     70.000                                 \n",
      "17    1062.43      73.684     65.625     69.421                                 \n",
      "18    1104.23      74.545     64.062     68.908                                 \n",
      "19    1082.55      73.214     64.062     68.333                                 \n",
      "20    1089.93      71.930     64.062     67.769                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.786   67.188    71.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model243.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1511.24      72.000     28.125     40.449                                 \n",
      " 2    1438.49      60.784     48.438     53.913                                 \n",
      " 3    1436.51      69.643     60.938     65.000                                 \n",
      " 4    1509.60      66.102     60.938     63.415                                 \n",
      " 5    1540.57      66.129     64.062     65.079                                 \n",
      " 6    1377.66      66.667     53.125     59.130                                 \n",
      " 7    1324.55      73.684     65.625     69.421                                 \n",
      " 8    1321.93      69.355     67.188     68.254                                 \n",
      " 9    1203.07      69.841     68.750     69.291                                 \n",
      "10    1180.82      70.492     67.188     68.800                                 \n",
      "11    1123.77      69.355     67.188     68.254                                 \n",
      "12    1239.00      69.355     67.188     68.254                                 \n",
      "13    1148.78      68.750     68.750     68.750                                 \n",
      "14    1158.82      67.692     68.750     68.217                                 \n",
      "15    1085.99      68.254     67.188     67.717                                 \n",
      "16    1131.41      67.742     65.625     66.667                                 \n",
      "17    1055.09      70.690     64.062     67.213                                 \n",
      "18    1065.59      71.930     64.062     67.769                                 \n",
      "19    1040.85      71.930     64.062     67.769                                 \n",
      "20    1082.37      70.175     62.500     66.116                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model256.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1545.08      58.621     26.562     36.559                                 \n",
      " 2    1419.43      62.745     50.000     55.652                                 \n",
      " 3    1450.36      73.214     64.062     68.333                                 \n",
      " 4    1400.91      70.690     64.062     67.213                                 \n",
      " 5    1412.40      70.588     56.250     62.609                                 \n",
      " 6    1341.37      74.000     57.812     64.912                                 \n",
      " 7    1343.98      70.833     53.125     60.714                                 \n",
      " 8    1292.65      71.111     50.000     58.716                                 \n",
      " 9    1179.34      69.565     50.000     58.182                                 \n",
      "10    1247.50      70.213     51.562     59.459                                 \n",
      "11    1175.39      70.833     53.125     60.714                                 \n",
      "12    1229.61      75.472     62.500     68.376                                 \n",
      "13    1182.13      74.545     64.062     68.908                                 \n",
      "14    1167.71      72.222     60.938     66.102                                 \n",
      "15    1113.38      70.370     59.375     64.407                                 \n",
      "16    1094.86      74.074     62.500     67.797                                 \n",
      "17    1076.16      69.091     59.375     63.866                                 \n",
      "18    1109.22      62.500     46.875     53.571                                 \n",
      "19    1060.25      63.830     46.875     54.054                                 \n",
      "20    1087.38      63.830     46.875     54.054                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   64.062    68.908\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.908\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model269.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1520.36      78.947     23.438     36.145                                 \n",
      " 2    1397.99      65.574     62.500     64.000                                 \n",
      " 3    1442.61      75.000     65.625     70.000                                 \n",
      " 4    1391.94      71.698     59.375     64.957                                 \n",
      " 5    1394.91      71.930     64.062     67.769                                 \n",
      " 6    1356.89      68.421     60.938     64.463                                 \n",
      " 7    1364.08      69.231     56.250     62.069                                 \n",
      " 8    1270.54      71.698     59.375     64.957                                 \n",
      " 9    1203.23      70.909     60.938     65.546                                 \n",
      "10    1188.31      66.667     62.500     64.516                                 \n",
      "11    1153.89      69.492     64.062     66.667                                 \n",
      "12    1197.13      69.492     64.062     66.667                                 \n",
      "13    1194.79      71.698     59.375     64.957                                 \n",
      "14    1113.36      72.727     62.500     67.227                                 \n",
      "15    1105.46      73.585     60.938     66.667                                 \n",
      "16    1116.92      73.077     59.375     65.517                                 \n",
      "17    1031.77      74.510     59.375     66.087                                 \n",
      "18    1073.23      73.077     59.375     65.517                                 \n",
      "19    1062.78      71.698     59.375     64.957                                 \n",
      "20    1108.77      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   65.625    70.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model282.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1475.57      73.529     39.062     51.020                                 \n",
      " 2    1444.66      61.538     50.000     55.172                                 \n",
      " 3    1397.05      65.306     50.000     56.637                                 \n",
      " 4    1422.26      63.265     48.438     54.867                                 \n",
      " 5    1386.09      68.421     60.938     64.463                                 \n",
      " 6    1353.86      76.923     62.500     68.966                                 \n",
      " 7    1395.51      70.690     64.062     67.213                                 \n",
      " 8    1243.82      75.472     62.500     68.376                                 \n",
      " 9    1247.40      70.492     67.188     68.800                                 \n",
      "10    1174.12      72.414     65.625     68.852                                 \n",
      "11    1156.15      73.684     65.625     69.421                                 \n",
      "12    1239.20      73.214     64.062     68.333                                 \n",
      "13    1186.23      71.930     64.062     67.769                                 \n",
      "14    1136.16      71.930     64.062     67.769                                 \n",
      "15    1090.41      68.333     64.062     66.129                                 \n",
      "16    1081.16      67.797     62.500     65.041                                 \n",
      "17    1064.12      67.213     64.062     65.600                                 \n",
      "18    1071.57      66.667     65.625     66.142                                 \n",
      "19    1029.70      67.742     65.625     66.667                                 \n",
      "20    1097.97      66.667     62.500     64.516                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model295.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1523.41      65.517     29.688     40.860                                 \n",
      " 2    1468.56      58.824     46.875     52.174                                 \n",
      " 3    1469.97      65.306     50.000     56.637                                 \n",
      " 4    1435.29      66.667     53.125     59.130                                 \n",
      " 5    1517.71      66.667     53.125     59.130                                 \n",
      " 6    1426.38      78.182     67.188     72.269                                 \n",
      " 7    1363.57      74.545     64.062     68.908                                 \n",
      " 8    1204.75      72.131     68.750     70.400                                 \n",
      " 9    1215.02      70.000     65.625     67.742                                 \n",
      "10    1153.08      72.000     56.250     63.158                                 \n",
      "11    1153.13      75.000     65.625     70.000                                 \n",
      "12    1206.34      75.000     65.625     70.000                                 \n",
      "13    1186.23      74.074     62.500     67.797                                 \n",
      "14    1124.83      73.585     60.938     66.667                                 \n",
      "15    1125.46      72.727     62.500     67.227                                 \n",
      "16    1111.84      74.545     64.062     68.908                                 \n",
      "17    1060.41      75.000     65.625     70.000                                 \n",
      "18    1056.05      75.439     67.188     71.074                                 \n",
      "19    1054.58      75.439     67.188     71.074                                 \n",
      "20    1097.81      77.778     65.625     71.186                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model308.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.02      61.905     40.625     49.057                                 \n",
      " 2    1389.84      56.897     51.562     54.098                                 \n",
      " 3    1485.12      71.698     59.375     64.957                                 \n",
      " 4    1385.46      70.175     62.500     66.116                                 \n",
      " 5    1455.78      72.727     62.500     67.227                                 \n",
      " 6    1404.07      78.947     70.312     74.380                                 \n",
      " 7    1323.94      81.818     70.312     75.630                                 \n",
      " 8    1229.71      75.862     68.750     72.131                                 \n",
      " 9    1211.78      77.966     71.875     74.797                                 \n",
      "10    1249.24      76.786     67.188     71.667                                 \n",
      "11    1124.41      76.786     67.188     71.667                                 \n",
      "12    1227.59      75.926     64.062     69.492                                 \n",
      "13    1188.04      71.429     62.500     66.667                                 \n",
      "14    1126.55      77.358     64.062     70.085                                 \n",
      "15    1136.49      77.358     64.062     70.085                                 \n",
      "16    1146.76      78.431     62.500     69.565                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    1045.76      74.545     64.062     68.908                                 \n",
      "18    1047.72      74.545     64.062     68.908                                 \n",
      "19    1039.92      76.786     67.188     71.667                                 \n",
      "20    1076.51      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.818   70.312    75.630\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.630\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model321.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1510.93      68.421     40.625     50.980                                 \n",
      " 2    1444.88      54.545     46.875     50.420                                 \n",
      " 3    1377.60      68.519     57.812     62.712                                 \n",
      " 4    1388.17      70.690     64.062     67.213                                 \n",
      " 5    1384.22      70.968     68.750     69.841                                 \n",
      " 6    1382.66      70.968     68.750     69.841                                 \n",
      " 7    1300.98      69.355     67.188     68.254                                 \n",
      " 8    1268.51      65.000     60.938     62.903                                 \n",
      " 9    1194.28      68.333     64.062     66.129                                 \n",
      "10    1182.41      72.881     67.188     69.919                                 \n",
      "11    1179.37      75.926     64.062     69.492                                 \n",
      "12    1226.69      71.930     64.062     67.769                                 \n",
      "13    1214.25      70.690     64.062     67.213                                 \n",
      "14    1115.74      71.930     64.062     67.769                                 \n",
      "15    1076.93      70.000     65.625     67.742                                 \n",
      "16    1106.47      72.881     67.188     69.919                                 \n",
      "17    1046.70      72.881     67.188     69.919                                 \n",
      "18    1060.13      71.667     67.188     69.355                                 \n",
      "19    1050.26      71.667     67.188     69.355                                 \n",
      "20    1090.53      71.667     67.188     69.355                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.881   67.188    69.919\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.919\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model334.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1483.42      67.647     35.938     46.939                                 \n",
      " 2    1437.08      51.613     50.000     50.794                                 \n",
      " 3    1444.43      75.472     62.500     68.376                                 \n",
      " 4    1379.16      70.370     59.375     64.407                                 \n",
      " 5    1422.62      80.000     62.500     70.175                                 \n",
      " 6    1320.15      79.630     67.188     72.881                                 \n",
      " 7    1373.90      79.310     71.875     75.410                                 \n",
      " 8    1283.61      75.862     68.750     72.131                                 \n",
      " 9    1215.63      79.630     67.188     72.881                                 \n",
      "10    1176.07      76.364     65.625     70.588                                 \n",
      "11    1140.37      78.182     67.188     72.269                                 \n",
      "12    1217.24      78.571     68.750     73.333                                 \n",
      "13    1203.73      78.182     67.188     72.269                                 \n",
      "14    1205.44      79.630     67.188     72.881                                 \n",
      "15    1122.55      81.132     67.188     73.504                                 \n",
      "16    1127.57      81.132     67.188     73.504                                 \n",
      "17    1093.40      82.692     67.188     74.138                                 \n",
      "18    1059.69      81.481     68.750     74.576                                 \n",
      "19    1052.47      78.182     67.188     72.269                                 \n",
      "20    1074.00      75.000     70.312     72.581                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.310   71.875    75.410\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.410\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model347.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1491.38      73.077     29.688     42.222                                 \n",
      " 2    1383.10      54.098     51.562     52.800                                 \n",
      " 3    1424.20      67.857     59.375     63.333                                 \n",
      " 4    1404.94      71.154     57.812     63.793                                 \n",
      " 5    1405.28      68.254     67.188     67.717                                 \n",
      " 6    1394.99      77.778     65.625     71.186                                 \n",
      " 7    1317.99      74.138     67.188     70.492                                 \n",
      " 8    1188.57      65.517     59.375     62.295                                 \n",
      " 9    1200.68      68.333     64.062     66.129                                 \n",
      "10    1172.03      67.742     65.625     66.667                                 \n",
      "11    1117.81      67.742     65.625     66.667                                 \n",
      "12    1173.13      68.421     60.938     64.463                                 \n",
      "13    1186.30      68.421     60.938     64.463                                 \n",
      "14    1122.39      68.421     60.938     64.463                                 \n",
      "15    1108.01      68.966     62.500     65.574                                 \n",
      "16    1117.94      72.414     65.625     68.852                                 \n",
      "17    1022.12      70.690     64.062     67.213                                 \n",
      "18    1066.09      70.690     64.062     67.213                                 \n",
      "19    1051.72      71.930     64.062     67.769                                 \n",
      "20    1075.17      71.429     62.500     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.778   65.625    71.186\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.186\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model360.bin\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1483.42      63.415     40.625     49.524                                 \n",
      " 2    1529.89      60.000     60.938     60.465                                 \n",
      " 3    1444.98      66.154     67.188     66.667                                 \n",
      " 4    1448.20      68.421     60.938     64.463                                 \n",
      " 5    1388.45      67.692     68.750     68.217                                 \n",
      " 6    1309.81      65.574     62.500     64.000                                 \n",
      " 7    1318.09      68.852     65.625     67.200                                 \n",
      " 8    1223.92      66.667     65.625     66.142                                 \n",
      " 9    1219.50      68.254     67.188     67.717                                 \n",
      "10    1226.45      68.182     70.312     69.231                                 \n",
      "11    1153.58      72.581     70.312     71.429                                 \n",
      "12    1213.61      71.667     67.188     69.355                                 \n",
      "13    1173.91      69.492     64.062     66.667                                 \n",
      "14    1163.38      71.429     62.500     66.667                                 \n",
      "15    1121.68      69.492     64.062     66.667                                 \n",
      "16    1092.13      68.333     64.062     66.129                                 \n",
      "17    1037.37      69.492     64.062     66.667                                 \n",
      "18    1069.78      72.727     62.500     67.227                                 \n",
      "19    1053.63      74.074     62.500     67.797                                 \n",
      "20    1091.28      74.074     62.500     67.797                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.581   70.312    71.429\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.429\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model373.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1479.95      80.000     25.000     38.095                                 \n",
      " 2    1463.46      58.621     53.125     55.738                                 \n",
      " 3    1436.31      70.769     71.875     71.318                                 \n",
      " 4    1401.12      67.742     65.625     66.667                                 \n",
      " 5    1463.03      71.429     62.500     66.667                                 \n",
      " 6    1367.25      71.930     64.062     67.769                                 \n",
      " 7    1305.11      73.684     65.625     69.421                                 \n",
      " 8    1319.25      75.439     67.188     71.074                                 \n",
      " 9    1279.53      69.355     67.188     68.254                                 \n",
      "10    1179.43      68.254     67.188     67.717                                 \n",
      "11    1149.79      70.000     65.625     67.742                                 \n",
      "12    1195.89      71.930     64.062     67.769                                 \n",
      "13    1183.69      72.727     62.500     67.227                                 \n",
      "14    1125.26      72.727     62.500     67.227                                 \n",
      "15    1092.42      73.214     64.062     68.333                                 \n",
      "16    1110.40      75.000     65.625     70.000                                 \n",
      "17    1055.49      76.364     65.625     70.588                                 \n",
      "18    1082.35      74.545     64.062     68.908                                 \n",
      "19    1032.87      74.074     62.500     67.797                                 \n",
      "20    1095.61      74.545     64.062     68.908                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.769   71.875    71.318\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.318\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model386.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1481.04      77.273     26.562     39.535                                 \n",
      " 2    1443.40      56.604     46.875     51.282                                 \n",
      " 3    1417.97      73.214     64.062     68.333                                 \n",
      " 4    1352.21      69.355     67.188     68.254                                 \n",
      " 5    1402.85      66.667     62.500     64.516                                 \n",
      " 6    1313.22      78.571     68.750     73.333                                 \n",
      " 7    1345.62      77.193     68.750     72.727                                 \n",
      " 8    1217.45      76.364     65.625     70.588                                 \n",
      " 9    1176.15      76.786     67.188     71.667                                 \n",
      "10    1161.80      73.684     65.625     69.421                                 \n",
      "11    1109.51      70.492     67.188     68.800                                 \n",
      "12    1203.64      76.364     65.625     70.588                                 \n",
      "13    1168.50      72.881     67.188     69.919                                 \n",
      "14    1149.29      72.881     67.188     69.919                                 \n",
      "15    1099.32      71.186     65.625     68.293                                 \n",
      "16    1098.75      72.881     67.188     69.919                                 \n",
      "17    1038.38      72.881     67.188     69.919                                 \n",
      "18    1073.96      71.186     65.625     68.293                                 \n",
      "19    1058.22      71.186     65.625     68.293                                 \n",
      "20    1091.36      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.571   68.750    73.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model399.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1472.05      57.778     40.625     47.706                                 \n",
      " 2    1449.91      58.000     45.312     50.877                                 \n",
      " 3    1394.46      72.340     53.125     61.261                                 \n",
      " 4    1452.94      67.273     57.812     62.185                                 \n",
      " 5    1429.51      71.186     65.625     68.293                                 \n",
      " 6    1354.91      76.364     65.625     70.588                                 \n",
      " 7    1337.65      74.576     68.750     71.545                                 \n",
      " 8    1283.85      73.333     68.750     70.968                                 \n",
      " 9    1201.50      72.131     68.750     70.400                                 \n",
      "10    1195.83      70.690     64.062     67.213                                 \n",
      "11    1139.20      71.930     64.062     67.769                                 \n",
      "12    1221.27      70.175     62.500     66.116                                 \n",
      "13    1194.65      71.930     64.062     67.769                                 \n",
      "14    1123.81      71.930     64.062     67.769                                 \n",
      "15    1102.07      74.545     64.062     68.908                                 \n",
      "16    1086.01      75.439     67.188     71.074                                 \n",
      "17    1045.85      75.000     65.625     70.000                                 \n",
      "18    1073.74      75.000     65.625     70.000                                 \n",
      "19    1055.08      75.439     67.188     71.074                                 \n",
      "20    1070.98      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# run training for a selected models, use every skip_models-th file\n",
    "skip_models = 13\n",
    "abs_models_dir = Path('models/tok2vec_abs_sci_ALL_gpu')\n",
    "\n",
    "models = sorted(os.listdir(abs_models_dir))\n",
    "\n",
    "for idx, model_file in enumerate(models):\n",
    "    if idx % skip_models == 0:\n",
    "        model_path = abs_models_dir / model_file\n",
    "        !prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg \\\n",
    "            --eval-split 0.2 --n-iter 20 --init-tok2vec $model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training final models with selected `tok2vec` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def train_ner_with_every_tok2vec(datasets):\n",
    "    tok2vec_dir = Path('models')\n",
    "    tok2vecs = sorted(os.listdir(tok2vec_dir))\n",
    "    \n",
    "    for tok2vec_file in tok2vecs:\n",
    "        if \"_sci_\" not in tok2vec_file:\n",
    "            continue\n",
    "\n",
    "        tok2vec_path = tok2vec_dir / tok2vec_file\n",
    "        !prodigy train ner $datasets en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "            --init-tok2vec $tok2vec_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1587.95      62.963     26.562     37.363                                 \n",
      " 2    1500.37      60.784     48.438     53.913                                 \n",
      " 3    1510.36      63.492     62.500     62.992                                 \n",
      " 4    1519.20      60.000     56.250     58.065                                 \n",
      " 5    1521.26      65.574     62.500     64.000                                 \n",
      " 6    1495.73      64.912     57.812     61.157                                 \n",
      " 7    1386.50      65.517     59.375     62.295                                 \n",
      " 8    1225.63      65.574     62.500     64.000                                 \n",
      " 9    1277.40      65.079     64.062     64.567                                 \n",
      "10    1258.71      62.903     60.938     61.905                                 \n",
      "11    1151.32      61.905     60.938     61.417                                 \n",
      "12    1249.35      63.793     57.812     60.656                                 \n",
      "13    1169.56      67.241     60.938     63.934                                 \n",
      "14    1163.40      65.517     59.375     62.295                                 \n",
      "15    1137.84      65.517     59.375     62.295                                 \n",
      "16    1137.22      67.241     60.938     63.934                                 \n",
      "17    1094.24      67.857     59.375     63.333                                 \n",
      "18    1079.29      63.793     57.812     60.656                                 \n",
      "19    1028.63      63.158     56.250     59.504                                 \n",
      "20    1096.86      63.158     56.250     59.504                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.079   64.062    64.567\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.567\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model238_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1575.28      47.368     28.125     35.294                                 \n",
      " 2    1473.45      68.000     53.125     59.649                                 \n",
      " 3    1414.79      73.214     64.062     68.333                                 \n",
      " 4    1463.85      72.727     62.500     67.227                                 \n",
      " 5    1384.56      76.364     65.625     70.588                                 \n",
      " 6    1343.33      82.692     67.188     74.138                                 \n",
      " 7    1333.10      80.000     68.750     73.950                                 \n",
      " 8    1285.83      77.966     71.875     74.797                                 \n",
      " 9    1231.73      74.545     64.062     68.908                                 \n",
      "10    1147.56      68.333     64.062     66.129                                 \n",
      "11    1133.60      71.667     67.188     69.355                                 \n",
      "12    1186.93      71.186     65.625     68.293                                 \n",
      "13    1163.38      68.852     65.625     67.200                                 \n",
      "14    1152.35      72.414     65.625     68.852                                 \n",
      "15    1096.20      69.492     64.062     66.667                                 \n",
      "16    1076.68      69.492     64.062     66.667                                 \n",
      "17    1034.84      71.429     62.500     66.667                                 \n",
      "18    1071.06      73.214     64.062     68.333                                 \n",
      "19    1066.33      73.214     64.062     68.333                                 \n",
      "20    1082.98      72.727     62.500     67.227                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.966   71.875    74.797\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.797\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2400_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1496.09      71.429     31.250     43.478                                 \n",
      " 2    1428.07      60.976     39.062     47.619                                 \n",
      " 3    1414.88      70.690     64.062     67.213                                 \n",
      " 4    1394.45      68.333     64.062     66.129                                 \n",
      " 5    1386.77      80.000     62.500     70.175                                 \n",
      " 6    1337.78      78.846     64.062     70.690                                 \n",
      " 7    1308.50      79.245     65.625     71.795                                 \n",
      " 8    1229.83      74.074     62.500     67.797                                 \n",
      " 9    1189.92      75.000     65.625     70.000                                 \n",
      "10    1199.78      76.923     62.500     68.966                                 \n",
      "11    1130.30      76.923     62.500     68.966                                 \n",
      "12    1245.61      75.000     60.938     67.241                                 \n",
      "13    1170.87      72.222     60.938     66.102                                 \n",
      "14    1132.59      70.370     59.375     64.407                                 \n",
      "15    1118.17      69.643     60.938     65.000                                 \n",
      "16    1075.07      72.222     60.938     66.102                                 \n",
      "17    1055.17      70.909     60.938     65.546                                 \n",
      "18    1065.72      67.273     57.812     62.185                                 \n",
      "19    1108.23      69.091     59.375     63.866                                 \n",
      "20    1081.93      68.519     57.812     62.712                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.245   65.625    71.795\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.795\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2401_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1581.14      64.516     31.250     42.105                                 \n",
      " 2    1486.14      60.976     39.062     47.619                                 \n",
      " 3    1464.08      67.925     56.250     61.538                                 \n",
      " 4    1497.64      65.306     50.000     56.637                                 \n",
      " 5    1430.13      64.151     53.125     58.120                                 \n",
      " 6    1414.06      72.000     56.250     63.158                                 \n",
      " 7    1455.04      74.510     59.375     66.087                                 \n",
      " 8    1262.20      75.472     62.500     68.376                                 \n",
      " 9    1305.18      78.431     62.500     69.565                                 \n",
      "10    1269.22      79.630     67.188     72.881                                 \n",
      "11    1109.86      78.846     64.062     70.690                                 \n",
      "12    1294.03      80.000     62.500     70.175                                 \n",
      "13    1189.09      80.392     64.062     71.304                                 \n",
      "14    1183.32      78.431     62.500     69.565                                 \n",
      "15    1149.91      78.431     62.500     69.565                                 \n",
      "16    1237.89      78.431     62.500     69.565                                 \n",
      "17    1107.08      78.846     64.062     70.690                                 \n",
      "18    1170.77      78.846     64.062     70.690                                 \n",
      "19    1085.09      78.846     64.062     70.690                                 \n",
      "20    1126.38      77.778     65.625     71.186                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.630   67.188    72.881\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.881\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2402_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1522.07      50.000     15.625     23.810                                 \n",
      " 2    1434.56      58.974     35.938     44.660                                 \n",
      " 3    1439.36      75.676     43.750     55.446                                 \n",
      " 4    1392.42      65.909     45.312     53.704                                 \n",
      " 5    1351.52      82.222     57.812     67.890                                 \n",
      " 6    1424.66      70.175     62.500     66.116                                 \n",
      " 7    1342.50      74.545     64.062     68.908                                 \n",
      " 8    1259.57      71.154     57.812     63.793                                 \n",
      " 9    1268.84      70.370     59.375     64.407                                 \n",
      "10    1224.35      68.519     57.812     62.712                                 \n",
      "11    1221.88      68.519     57.812     62.712                                 \n",
      "12    1244.84      72.222     60.938     66.102                                 \n",
      "13    1158.82      73.077     59.375     65.517                                 \n",
      "14    1163.86      79.592     60.938     69.027                                 \n",
      "15    1179.30      80.000     62.500     70.175                                 \n",
      "16    1113.85      80.000     62.500     70.175                                 \n",
      "17    1081.04      78.000     60.938     68.421                                 \n",
      "18    1115.72      78.000     60.938     68.421                                 \n",
      "19    1060.52      75.000     60.938     67.241                                 \n",
      "20    1116.15      75.000     60.938     67.241                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      80.000   62.500    70.175\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.175\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model304_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1527.20      64.706     34.375     44.898                                 \n",
      " 2    1514.31      52.381     51.562     51.969                                 \n",
      " 3    1487.56      67.797     62.500     65.041                                 \n",
      " 4    1420.83      70.175     62.500     66.116                                 \n",
      " 5    1392.88      71.186     65.625     68.293                                 \n",
      " 6    1343.58      77.193     68.750     72.727                                 \n",
      " 7    1345.95      76.271     70.312     73.171                                 \n",
      " 8    1223.03      79.310     71.875     75.410                                 \n",
      " 9    1255.10      75.439     67.188     71.074                                 \n",
      "10    1219.86      76.786     67.188     71.667                                 \n",
      "11    1165.85      76.786     67.188     71.667                                 \n",
      "12    1215.02      77.778     65.625     71.186                                 \n",
      "13    1185.63      76.786     67.188     71.667                                 \n",
      "14    1128.99      75.000     65.625     70.000                                 \n",
      "15    1108.05      70.690     64.062     67.213                                 \n",
      "16    1113.84      74.138     67.188     70.492                                 \n",
      "17    1042.53      73.684     65.625     69.421                                 \n",
      "18    1074.24      73.684     65.625     69.421                                 \n",
      "19    1035.15      74.576     68.750     71.545                                 \n",
      "20    1101.89      71.186     65.625     68.293                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.310   71.875    75.410\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.410\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.02      61.905     40.625     49.057                                 \n",
      " 2    1389.84      56.897     51.562     54.098                                 \n",
      " 3    1485.12      71.698     59.375     64.957                                 \n",
      " 4    1385.46      70.175     62.500     66.116                                 \n",
      " 5    1455.78      72.727     62.500     67.227                                 \n",
      " 6    1404.07      78.947     70.312     74.380                                 \n",
      " 7    1323.94      81.818     70.312     75.630                                 \n",
      " 8    1229.71      75.862     68.750     72.131                                 \n",
      " 9    1211.78      77.966     71.875     74.797                                 \n",
      "10    1249.24      76.786     67.188     71.667                                 \n",
      "11    1124.41      76.786     67.188     71.667                                 \n",
      "12    1227.59      75.926     64.062     69.492                                 \n",
      "13    1188.04      71.429     62.500     66.667                                 \n",
      "14    1126.55      77.358     64.062     70.085                                 \n",
      "15    1136.49      77.358     64.062     70.085                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    1146.76      78.431     62.500     69.565                                 \n",
      "17    1045.76      74.545     64.062     68.908                                 \n",
      "18    1047.72      74.545     64.062     68.908                                 \n",
      "19    1039.92      76.786     67.188     71.667                                 \n",
      "20    1076.51      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.818   70.312    75.630\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.630\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model336_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1507.62      57.895     34.375     43.137                                 \n",
      " 2    1465.82      57.627     53.125     55.285                                 \n",
      " 3    1433.29      62.121     64.062     63.077                                 \n",
      " 4    1496.11      68.519     57.812     62.712                                 \n",
      " 5    1393.36      67.308     54.688     60.345                                 \n",
      " 6    1369.23      69.231     56.250     62.069                                 \n",
      " 7    1297.14      72.131     68.750     70.400                                 \n",
      " 8    1253.85      71.429     70.312     70.866                                 \n",
      " 9    1177.67      74.074     62.500     67.797                                 \n",
      "10    1182.16      68.750     51.562     58.929                                 \n",
      "11    1184.30      70.213     51.562     59.459                                 \n",
      "12    1228.26      68.627     54.688     60.870                                 \n",
      "13    1179.65      75.439     67.188     71.074                                 \n",
      "14    1169.15      75.439     67.188     71.074                                 \n",
      "15    1083.01      75.000     65.625     70.000                                 \n",
      "16    1106.40      74.545     64.062     68.908                                 \n",
      "17    1082.69      72.222     60.938     66.102                                 \n",
      "18    1068.73      72.222     60.938     66.102                                 \n",
      "19    1050.78      72.222     60.938     66.102                                 \n",
      "20    1081.67      72.222     60.938     66.102                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.439   67.188    71.074\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.074\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model4_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1591.72      57.143     18.750     28.235                                 \n",
      " 2    1430.54      60.976     39.062     47.619                                 \n",
      " 3    1431.12      76.087     54.688     63.636                                 \n",
      " 4    1447.46      73.333     51.562     60.550                                 \n",
      " 5    1405.81      75.000     65.625     70.000                                 \n",
      " 6    1360.50      81.132     67.188     73.504                                 \n",
      " 7    1350.34      78.431     62.500     69.565                                 \n",
      " 8    1295.07      75.000     56.250     64.286                                 \n",
      " 9    1306.47      77.358     64.062     70.085                                 \n",
      "10    1206.40      73.684     65.625     69.421                                 \n",
      "11    1224.72      74.510     59.375     66.087                                 \n",
      "12    1314.89      73.077     59.375     65.517                                 \n",
      "13    1219.40      73.077     59.375     65.517                                 \n",
      "14    1193.32      71.698     59.375     64.957                                 \n",
      "15    1119.57      71.154     57.812     63.793                                 \n",
      "16    1117.24      70.588     56.250     62.609                                 \n",
      "17    1067.36      68.627     54.688     60.870                                 \n",
      "18    1087.17      68.627     54.688     60.870                                 \n",
      "19    1049.51      70.000     54.688     61.404                                 \n",
      "20    1108.60      67.925     56.250     61.538                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.132   67.188    73.504\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.504\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1578.16      64.000     25.000     35.955                                 \n",
      " 2    1439.61      55.319     40.625     46.847                                 \n",
      " 3    1528.20      72.222     60.938     66.102                                 \n",
      " 4    1429.18      71.154     57.812     63.793                                 \n",
      " 5    1414.46      69.388     53.125     60.177                                 \n",
      " 6    1344.69      75.472     62.500     68.376                                 \n",
      " 7    1472.62      70.909     60.938     65.546                                 \n",
      " 8    1296.39      74.545     64.062     68.908                                 \n",
      " 9    1285.11      68.966     62.500     65.574                                 \n",
      "10    1236.84      70.175     62.500     66.116                                 \n",
      "11    1181.13      71.429     62.500     66.667                                 \n",
      "12    1235.60      70.909     60.938     65.546                                 \n",
      "13    1238.99      76.923     62.500     68.966                                 \n",
      "14    1151.94      75.926     64.062     69.492                                 \n",
      "15    1151.25      75.926     64.062     69.492                                 \n",
      "16    1218.30      78.000     60.938     68.421                                 \n",
      "17    1074.01      75.926     64.062     69.492                                 \n",
      "18    1121.71      76.364     65.625     70.588                                 \n",
      "19    1084.27      77.358     64.062     70.085                                 \n",
      "20    1106.32      76.471     60.938     67.826                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1577.68      57.895     34.375     43.137                                 \n",
      " 2    1386.95      67.308     54.688     60.345                                 \n",
      " 3    1455.49      76.596     56.250     64.865                                 \n",
      " 4    1457.04      79.592     60.938     69.027                                 \n",
      " 5    1413.30      78.431     62.500     69.565                                 \n",
      " 6    1351.85      76.923     62.500     68.966                                 \n",
      " 7    1304.38      78.000     60.938     68.421                                 \n",
      " 8    1255.67      76.471     60.938     67.826                                 \n",
      " 9    1219.66      78.431     62.500     69.565                                 \n",
      "10    1203.83      74.545     64.062     68.908                                 \n",
      "11    1125.02      74.545     64.062     68.908                                 \n",
      "12    1224.65      74.074     62.500     67.797                                 \n",
      "13    1173.56      75.000     60.938     67.241                                 \n",
      "14    1170.88      75.000     60.938     67.241                                 \n",
      "15    1074.42      71.154     57.812     63.793                                 \n",
      "16    1144.97      75.000     60.938     67.241                                 \n",
      "17    1041.02      73.077     59.375     65.517                                 \n",
      "18    1094.32      74.510     59.375     66.087                                 \n",
      "19    1051.65      74.510     59.375     66.087                                 \n",
      "20    1099.61      78.000     60.938     68.421                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.431   62.500    69.565\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.565\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.28      62.500     23.438     34.091                                 \n",
      " 2    1397.40      59.091     40.625     48.148                                 \n",
      " 3    1485.47      70.833     53.125     60.714                                 \n",
      " 4    1445.56      68.293     43.750     53.333                                 \n",
      " 5    1431.31      64.000     50.000     56.140                                 \n",
      " 6    1339.87      70.833     53.125     60.714                                 \n",
      " 7    1387.07      72.340     53.125     61.261                                 \n",
      " 8    1232.74      76.596     56.250     64.865                                 \n",
      " 9    1207.39      72.340     53.125     61.261                                 \n",
      "10    1231.53      75.926     64.062     69.492                                 \n",
      "11    1154.22      74.545     64.062     68.908                                 \n",
      "12    1304.76      75.472     62.500     68.376                                 \n",
      "13    1155.21      69.811     57.812     63.248                                 \n",
      "14    1158.97      67.273     57.812     62.185                                 \n",
      "15    1092.88      69.811     57.812     63.248                                 \n",
      "16    1134.04      68.627     54.688     60.870                                 \n",
      "17    1055.42      66.667     56.250     61.017                                 \n",
      "18    1071.15      66.667     56.250     61.017                                 \n",
      "19    1060.90      69.231     56.250     62.069                                 \n",
      "20    1063.32      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2Kading 'en_core_sci_lg'...\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1630.03      55.556     23.438     32.967                                 \n",
      " 2    1442.41      55.556     46.875     50.847                                 \n",
      " 3    1429.19      65.957     48.438     55.856                                 \n",
      " 4    1467.20      65.455     56.250     60.504                                 \n",
      " 5    1467.20      69.643     60.938     65.000                                 \n",
      " 6    1376.49      67.241     60.938     63.934                                 \n",
      " 7    1324.06      73.585     60.938     66.667                                 \n",
      " 8    1261.74      75.472     62.500     68.376                                 \n",
      " 9    1229.62      77.358     64.062     70.085                                 \n",
      "10    1162.35      74.545     64.062     68.908                                 \n",
      "11    1129.31      72.727     62.500     67.227                                 \n",
      "12    1226.05      73.684     65.625     69.421                                 \n",
      "13    1154.44      73.684     65.625     69.421                                 \n",
      "14    1146.38      69.492     64.062     66.667                                 \n",
      "15    1157.15      70.175     62.500     66.116                                 \n",
      "16    1122.06      72.549     57.812     64.348                                 \n",
      "17    1069.36      70.909     60.938     65.546                                 \n",
      "18    1112.07      71.930     64.062     67.769                                 \n",
      "19    1040.95      70.370     59.375     64.407                                 \n",
      "20    1074.33      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   64.062    70.085\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.085\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ner_with_every_tok2vec(\"cord_19_rf_sentences,cord_19_rf_sentences_correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• Top model so far: `75.630` üî•\n",
    "- trained with `tok2vec_abs_sci_model308_gpu.bin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.02      61.905     40.625     49.057                                 \n",
      " 2    1389.84      56.897     51.562     54.098                                 \n",
      " 3    1485.12      71.698     59.375     64.957                                 \n",
      " 4    1385.46      70.175     62.500     66.116                                 \n",
      " 5    1455.78      72.727     62.500     67.227                                 \n",
      " 6    1404.07      78.947     70.312     74.380                                 \n",
      " 7    1323.94      81.818     70.312     75.630                                 \n",
      " 8    1229.71      75.862     68.750     72.131                                 \n",
      " 9    1211.78      77.966     71.875     74.797                                 \n",
      "10    1249.24      76.786     67.188     71.667                                 \n",
      "11    1124.41      76.786     67.188     71.667                                 \n",
      "12    1227.59      75.926     64.062     69.492                                 \n",
      "13    1188.04      71.429     62.500     66.667                                 \n",
      "14    1126.55      77.358     64.062     70.085                                 \n",
      "15    1136.49      77.358     64.062     70.085                                 \n",
      "16    1146.76      78.431     62.500     69.565                                 \n",
      "17    1045.76      74.545     64.062     68.908                                 \n",
      "18    1047.72      74.545     64.062     68.908                                 \n",
      "19    1039.92      76.786     67.188     71.667                                 \n",
      "20    1076.51      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.818   70.312    75.630\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.630\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m‚úî Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_10_en_ner_rf_sm\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg \\\n",
    "#    --eval-split 0.2 --n-iter 20 --init-tok2vec models/tok2vec_abs_sci_model308_gpu.bin \\\n",
    "#    --output models/2020_04_10_en_ner_rf_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.13 (Mon)\n",
    "## Label more data by correcting the model's predictions (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_rf_sentences_correct_2 to database SQLite.\n",
      "\n",
      "‚ú®  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.correct cord_19_rf_sentences_correct_2 models/2020_04_10_en_ner_rf_sm data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR --exclude cord_19_rf_sentences,cord_19_rf_sentences_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train final models, with 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2885.30      59.302     42.149     49.275                                 \n",
      " 2    2552.55      62.353     43.802     51.456                                 \n",
      " 3    2728.96      65.385     56.198     60.444                                 \n",
      " 4    2487.82      72.917     57.851     64.516                                 \n",
      " 5    2373.22      72.642     63.636     67.841                                 \n",
      " 6    2348.38      74.074     66.116     69.869                                 \n",
      " 7    2218.46      73.832     65.289     69.298                                 \n",
      " 8    2170.65      73.148     65.289     68.996                                 \n",
      " 9    2100.42      72.816     61.983     66.964                                 \n",
      "10    2139.80      75.490     63.636     69.058                                 \n",
      "11    2019.70      78.000     64.463     70.588                                 \n",
      "12    2038.26      78.218     65.289     71.171                                 \n",
      "13    1985.03      77.000     63.636     69.683                                 \n",
      "14    1951.26      75.758     61.983     68.182                                 \n",
      "15    1914.76      75.758     61.983     68.182                                 \n",
      "16    1872.98      75.248     62.810     68.468                                 \n",
      "17    1767.53      73.333     63.636     68.142                                 \n",
      "18    1821.03      73.786     62.810     67.857                                 \n",
      "19    1756.45      73.077     62.810     67.556                                 \n",
      "20    1812.57      70.370     62.810     66.376                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.218   65.289    71.171\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.171\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model238_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2852.29      68.132     51.240     58.491                                 \n",
      " 2    2621.84      77.273     56.198     65.072                                 \n",
      " 3    2599.70      75.728     64.463     69.643                                 \n",
      " 4    2422.69      73.394     66.116     69.565                                 \n",
      " 5    2291.69      71.560     64.463     67.826                                 \n",
      " 6    2259.82      77.358     67.769     72.247                                 \n",
      " 7    2173.01      75.701     66.942     71.053                                 \n",
      " 8    2135.90      76.699     65.289     70.536                                 \n",
      " 9    2131.74      72.727     66.116     69.264                                 \n",
      "10    2091.84      75.962     65.289     70.222                                 \n",
      "11    1972.21      75.962     65.289     70.222                                 \n",
      "12    1959.91      72.566     67.769     70.085                                 \n",
      "13    1979.00      72.321     66.942     69.528                                 \n",
      "14    1891.45      71.930     67.769     69.787                                 \n",
      "15    1917.09      71.681     66.942     69.231                                 \n",
      "16    1820.28      70.940     68.595     69.748                                 \n",
      "17    1774.21      68.376     66.116     67.227                                 \n",
      "18    1812.61      70.175     66.116     68.085                                 \n",
      "19    1759.71      70.175     66.116     68.085                                 \n",
      "20    1816.47      71.304     67.769     69.492                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   67.769    72.247\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.247\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2400_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2774.03      70.526     55.372     62.037                                 \n",
      " 2    2567.17      71.875     57.025     63.594                                 \n",
      " 3    2650.63      74.747     61.157     67.273                                 \n",
      " 4    2435.64      77.083     61.157     68.203                                 \n",
      " 5    2322.78      73.786     62.810     67.857                                 \n",
      " 6    2208.39      74.757     63.636     68.750                                 \n",
      " 7    2189.09      76.190     66.116     70.796                                 \n",
      " 8    2061.45      76.415     66.942     71.366                                 \n",
      " 9    2090.43      77.143     66.942     71.681                                 \n",
      "10    2046.25      78.704     70.248     74.236                                 \n",
      "11    2019.68      78.182     71.074     74.459                                 \n",
      "12    2026.61      78.899     71.074     74.783                                 \n",
      "13    1994.80      77.982     70.248     73.913                                 \n",
      "14    1976.07      75.455     68.595     71.861                                 \n",
      "15    1896.82      75.701     66.942     71.053                                 \n",
      "16    1812.48      75.000     66.942     70.742                                 \n",
      "17    1792.77      74.545     67.769     70.996                                 \n",
      "18    1818.84      74.775     68.595     71.552                                 \n",
      "19    1803.06      74.775     68.595     71.552                                 \n",
      "20    1835.78      74.107     68.595     71.245                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.899   71.074    74.783\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.783\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2401_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2802.33      63.953     45.455     53.140                                 \n",
      " 2    2777.16      68.085     52.893     59.535                                 \n",
      " 3    2653.47      69.231     59.504     64.000                                 \n",
      " 4    2473.14      70.874     60.331     65.179                                 \n",
      " 5    2394.22      69.000     57.025     62.443                                 \n",
      " 6    2297.21      69.000     57.025     62.443                                 \n",
      " 7    2192.55      68.269     58.678     63.111                                 \n",
      " 8    2293.42      71.845     61.157     66.071                                 \n",
      " 9    2159.01      70.476     61.157     65.487                                 \n",
      "10    2081.32      69.159     61.157     64.912                                 \n",
      "11    1994.01      68.519     61.157     64.629                                 \n",
      "12    1970.23      69.444     61.983     65.502                                 \n",
      "13    1967.99      68.468     62.810     65.517                                 \n",
      "14    1945.46      68.468     62.810     65.517                                 \n",
      "15    1900.57      66.372     61.983     64.103                                 \n",
      "16    1847.67      67.257     62.810     64.957                                 \n",
      "17    1794.01      67.857     62.810     65.236                                 \n",
      "18    1803.22      67.544     63.636     65.532                                 \n",
      "19    1777.86      66.957     63.636     65.254                                 \n",
      "20    1799.34      67.241     64.463     65.823                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.845   61.157    66.071\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.071\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2402_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2921.45      61.333     38.017     46.939                                 \n",
      " 2    2647.32      71.739     54.545     61.972                                 \n",
      " 3    2676.39      71.429     57.851     63.927                                 \n",
      " 4    2600.52      72.115     61.983     66.667                                 \n",
      " 5    2471.81      71.287     59.504     64.865                                 \n",
      " 6    2273.85      72.000     59.504     65.158                                 \n",
      " 7    2217.76      75.258     60.331     66.972                                 \n",
      " 8    2197.69      75.248     62.810     68.468                                 \n",
      " 9    2168.50      73.786     62.810     67.857                                 \n",
      "10    2191.43      72.115     61.983     66.667                                 \n",
      "11    2033.08      73.077     62.810     67.556                                 \n",
      "12    2038.16      71.569     60.331     65.471                                 \n",
      "13    2071.37      71.154     61.157     65.778                                 \n",
      "14    1923.85      72.381     62.810     67.257                                 \n",
      "15    1926.64      72.381     62.810     67.257                                 \n",
      "16    1896.23      71.296     63.636     67.249                                 \n",
      "17    1822.68      71.560     64.463     67.826                                 \n",
      "18    1822.97      71.560     64.463     67.826                                 \n",
      "19    1785.60      70.642     63.636     66.957                                 \n",
      "20    1815.14      70.370     62.810     66.376                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.248   62.810    68.468\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.468\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model304_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2756.33      69.072     55.372     61.468                                 \n",
      " 2    2670.17      73.786     62.810     67.857                                 \n",
      " 3    2680.49      70.370     62.810     66.376                                 \n",
      " 4    2416.43      72.174     68.595     70.339                                 \n",
      " 5    2327.03      72.807     68.595     70.638                                 \n",
      " 6    2261.51      74.545     67.769     70.996                                 \n",
      " 7    2156.66      73.684     69.421     71.489                                 \n",
      " 8    2157.50      74.775     68.595     71.552                                 \n",
      " 9    2056.64      74.336     69.421     71.795                                 \n",
      "10    2024.02      68.908     67.769     68.333                                 \n",
      "11    2000.89      71.930     67.769     69.787                                 \n",
      "12    1957.37      74.336     69.421     71.795                                 \n",
      "13    1921.06      74.336     69.421     71.795                                 \n",
      "14    1908.85      74.561     70.248     72.340                                 \n",
      "15    1898.20      74.545     67.769     70.996                                 \n",
      "16    1844.39      75.000     69.421     72.103                                 \n",
      "17    1803.71      75.455     68.595     71.861                                 \n",
      "18    1841.31      73.636     66.942     70.130                                 \n",
      "19    1749.20      74.074     66.116     69.869                                 \n",
      "20    1808.81      74.074     66.116     69.869                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.561   70.248    72.340\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.340\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2811.45      69.231     52.066     59.434                                 \n",
      " 2    2606.03      67.961     57.851     62.500                                 \n",
      " 3    2571.19      73.529     61.983     67.265                                 \n",
      " 4    2442.88      75.238     65.289     69.912                                 \n",
      " 5    2329.50      70.690     67.769     69.198                                 \n",
      " 6    2213.83      77.273     70.248     73.593                                 \n",
      " 7    2127.51      75.926     67.769     71.616                                 \n",
      " 8    2099.61      76.190     66.116     70.796                                 \n",
      " 9    2050.85      73.394     66.116     69.565                                 \n",
      "10    2017.65      73.874     67.769     70.690                                 \n",
      "11    1979.75      75.000     69.421     72.103                                 \n",
      "12    1960.84      75.893     70.248     72.961                                 \n",
      "13    1909.56      74.783     71.074     72.881                                 \n",
      "14    1891.09      75.862     72.727     74.262                                 \n",
      "15    1921.11      77.193     72.727     74.894                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    1818.28      75.652     71.901     73.729                                 \n",
      "17    1795.52      75.000     71.901     73.418                                 \n",
      "18    1827.94      74.561     70.248     72.340                                 \n",
      "19    1761.02      74.783     71.074     72.881                                 \n",
      "20    1806.65      73.504     71.074     72.269                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.193   72.727    74.894\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.894\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model336_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2809.39      67.033     50.413     57.547                                 \n",
      " 2    2607.82      69.000     57.025     62.443                                 \n",
      " 3    2679.98      73.148     65.289     68.996                                 \n",
      " 4    2373.86      71.053     66.942     68.936                                 \n",
      " 5    2317.09      71.304     67.769     69.492                                 \n",
      " 6    2186.74      73.874     67.769     70.690                                 \n",
      " 7    2132.76      73.394     66.116     69.565                                 \n",
      " 8    2098.73      72.973     66.942     69.828                                 \n",
      " 9    2044.13      74.545     67.769     70.996                                 \n",
      "10    2076.54      73.394     66.116     69.565                                 \n",
      "11    1928.78      70.536     65.289     67.811                                 \n",
      "12    1991.64      71.171     65.289     68.103                                 \n",
      "13    2001.98      70.536     65.289     67.811                                 \n",
      "14    1924.28      71.053     66.942     68.936                                 \n",
      "15    1884.74      71.053     66.942     68.936                                 \n",
      "16    1849.36      70.175     66.116     68.085                                 \n",
      "17    1784.86      69.565     66.116     67.797                                 \n",
      "18    1820.70      70.175     66.116     68.085                                 \n",
      "19    1753.51      70.796     66.116     68.376                                 \n",
      "20    1781.21      71.429     66.116     68.670                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   67.769    70.996\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.996\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model4_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2905.73      60.274     36.364     45.361                                 \n",
      " 2    2643.78      65.909     47.934     55.502                                 \n",
      " 3    2720.29      71.277     55.372     62.326                                 \n",
      " 4    2493.67      71.845     61.157     66.071                                 \n",
      " 5    2410.86      69.027     64.463     66.667                                 \n",
      " 6    2276.30      74.074     66.116     69.869                                 \n",
      " 7    2279.60      70.642     63.636     66.957                                 \n",
      " 8    2212.41      69.444     61.983     65.502                                 \n",
      " 9    2144.86      70.000     63.636     66.667                                 \n",
      "10    2110.11      70.000     63.636     66.667                                 \n",
      "11    2078.27      71.560     64.463     67.826                                 \n",
      "12    2030.53      70.270     64.463     67.241                                 \n",
      "13    2010.53      69.912     65.289     67.521                                 \n",
      "14    1974.33      69.912     65.289     67.521                                 \n",
      "15    1948.63      72.072     66.116     68.966                                 \n",
      "16    1864.64      73.148     65.289     68.996                                 \n",
      "17    1796.42      70.909     64.463     67.532                                 \n",
      "18    1834.32      68.182     61.983     64.935                                 \n",
      "19    1836.69      68.224     60.331     64.035                                 \n",
      "20    1837.54      68.868     60.331     64.317                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.074   66.116    69.869\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.869\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2913.83      64.865     39.669     49.231                                 \n",
      " 2    2781.90      61.321     53.719     57.269                                 \n",
      " 3    2695.09      64.486     57.025     60.526                                 \n",
      " 4    2555.06      67.619     58.678     62.832                                 \n",
      " 5    2456.87      73.529     61.983     67.265                                 \n",
      " 6    2215.30      78.125     61.983     69.124                                 \n",
      " 7    2202.15      73.786     62.810     67.857                                 \n",
      " 8    2135.29      72.897     64.463     68.421                                 \n",
      " 9    2100.14      74.766     66.116     70.175                                 \n",
      "10    2150.92      72.222     64.463     68.122                                 \n",
      "11    2019.84      74.766     66.116     70.175                                 \n",
      "12    2048.45      74.074     66.116     69.869                                 \n",
      "13    1996.72      74.312     66.942     70.435                                 \n",
      "14    1982.48      74.545     67.769     70.996                                 \n",
      "15    1960.40      71.930     67.769     69.787                                 \n",
      "16    1852.92      73.636     66.942     70.130                                 \n",
      "17    1841.95      74.545     67.769     70.996                                 \n",
      "18    1843.39      72.973     66.942     69.828                                 \n",
      "19    1796.31      72.973     66.942     69.828                                 \n",
      "20    1799.40      72.321     66.942     69.528                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   67.769    70.996\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.996\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2835.29      68.116     38.843     49.474                                 \n",
      " 2    2732.17      72.500     47.934     57.711                                 \n",
      " 3    2570.86      78.000     64.463     70.588                                 \n",
      " 4    2535.81      72.381     62.810     67.257                                 \n",
      " 5    2355.29      78.641     66.942     72.321                                 \n",
      " 6    2273.33      73.333     63.636     68.142                                 \n",
      " 7    2248.22      75.472     66.116     70.485                                 \n",
      " 8    2121.12      72.477     65.289     68.696                                 \n",
      " 9    2055.64      72.642     63.636     67.841                                 \n",
      "10    2045.31      69.159     61.157     64.912                                 \n",
      "11    1988.56      67.290     59.504     63.158                                 \n",
      "12    1970.19      66.981     58.678     62.555                                 \n",
      "13    1984.19      67.593     60.331     63.755                                 \n",
      "14    1921.90      68.868     60.331     64.317                                 \n",
      "15    1942.97      68.932     58.678     63.393                                 \n",
      "16    1833.59      68.627     57.851     62.780                                 \n",
      "17    1801.38      66.981     58.678     62.555                                 \n",
      "18    1821.15      68.571     59.504     63.717                                 \n",
      "19    1774.22      68.269     58.678     63.111                                 \n",
      "20    1800.21      67.890     61.157     64.348                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.641   66.942    72.321\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.321\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2806.94      69.512     47.107     56.158                                 \n",
      " 2    2534.86      65.591     50.413     57.009                                 \n",
      " 3    2651.01      62.037     55.372     58.515                                 \n",
      " 4    2407.22      73.214     67.769     70.386                                 \n",
      " 5    2364.25      77.570     68.595     72.807                                 \n",
      " 6    2290.54      75.000     66.942     70.742                                 \n",
      " 7    2250.24      74.257     61.983     67.568                                 \n",
      " 8    2157.26      73.786     62.810     67.857                                 \n",
      " 9    2040.44      76.238     63.636     69.369                                 \n",
      "10    2114.07      74.510     62.810     68.161                                 \n",
      "11    2010.97      73.585     64.463     68.722                                 \n",
      "12    2027.09      73.832     65.289     69.298                                 \n",
      "13    2005.38      75.472     66.116     70.485                                 \n",
      "14    1950.82      74.312     66.942     70.435                                 \n",
      "15    1921.53      72.642     63.636     67.841                                 \n",
      "16    1862.77      74.286     64.463     69.027                                 \n",
      "17    1809.07      71.429     61.983     66.372                                 \n",
      "18    1815.98      70.755     61.983     66.079                                 \n",
      "19    1778.76      70.093     61.983     65.789                                 \n",
      "20    1821.81      70.755     61.983     66.079                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.570   68.595    72.807\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.807\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m‚úî Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2778.89      65.385     42.149     51.256                                 \n",
      " 2    2658.80      64.706     54.545     59.193                                 \n",
      " 3    2603.19      70.192     60.331     64.889                                 \n",
      " 4    2483.60      68.367     55.372     61.187                                 \n",
      " 5    2393.74      73.267     61.157     66.667                                 \n",
      " 6    2299.20      70.093     61.983     65.789                                 \n",
      " 7    2252.09      70.370     62.810     66.376                                 \n",
      " 8    2151.54      70.093     61.983     65.789                                 \n",
      " 9    2125.46      69.091     62.810     65.801                                 \n",
      "10    2117.79      71.296     63.636     67.249                                 \n",
      "11    2026.21      71.296     63.636     67.249                                 \n",
      "12    2005.44      71.296     63.636     67.249                                 \n",
      "13    1990.53      70.755     61.983     66.079                                 \n",
      "14    1939.05      70.755     61.983     66.079                                 \n",
      "15    1946.72      71.429     61.983     66.372                                 \n",
      "16    1863.74      69.524     60.331     64.602                                 \n",
      "17    1847.71      70.192     60.331     64.889                                 \n",
      "18    1847.33      70.192     60.331     64.889                                 \n",
      "19    1799.33      69.231     59.504     64.000                                 \n",
      "20    1842.89      68.571     59.504     63.717                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.296   63.636    67.249\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.249\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ner_with_every_tok2vec(\"cord_19_rf_sentences,cord_19_rf_sentences_correct,cord_19_rf_sentences_correct_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• More annotations lowered the performance; top model: `74.894` üî•\n",
    "- trained with `tok2vec_abs_sci_model308_gpu.bin`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if `sci` is still the best choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1517.43      63.793     30.579     41.341                                 \n",
      " 2    1373.26      68.750     45.455     54.726                                 \n",
      " 3     997.71      69.048     47.934     56.585                                 \n",
      " 4     903.18      71.910     52.893     60.952                                 \n",
      " 5     663.74      75.269     57.851     65.421                                 \n",
      " 6     690.64      74.118     52.066     61.165                                 \n",
      " 7     499.83      75.862     54.545     63.462                                 \n",
      " 8     439.64      73.118     56.198     63.551                                 \n",
      " 9     385.50      72.043     55.372     62.617                                 \n",
      "10     331.79      71.134     57.025     63.303                                 \n",
      "11     322.72      68.317     57.025     62.162                                 \n",
      "12     266.74      68.041     54.545     60.550                                 \n",
      "13     265.05      68.478     52.066     59.155                                 \n",
      "14     179.49      68.750     54.545     60.829                                 \n",
      "15     140.89      67.708     53.719     59.908                                 \n",
      "16      99.59      68.317     57.025     62.162                                 \n",
      "17      99.56      66.990     57.025     61.607                                 \n",
      "18      95.81      67.647     57.025     61.883                                 \n",
      "19      97.89      67.925     59.504     63.436                                 \n",
      "20      84.40      68.224     60.331     64.035                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.269   57.851    65.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m65.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    6547.33       0.000      0.000      0.000                                 \n",
      " 2    6085.27      68.421     10.744     18.571                                 \n",
      " 3    6064.60      58.333     23.140     33.136                                 \n",
      " 4    5980.70      60.714     28.099     38.418                                 \n",
      " 5    5669.33      68.421     32.231     43.820                                 \n",
      " 6    5882.47      61.250     40.496     48.756                                 \n",
      " 7    5727.24      61.176     42.975     50.485                                 \n",
      " 8    5862.17      63.415     42.975     51.232                                 \n",
      " 9    6044.19      63.736     47.934     54.717                                 \n",
      "10    6021.27      62.887     50.413     55.963                                 \n",
      "11    5369.35      62.626     51.240     56.364                                 \n",
      "12    5961.72      64.948     52.066     57.798                                 \n",
      "13    5571.60      67.742     52.066     58.879                                 \n",
      "14    5504.25      64.706     54.545     59.193                                 \n",
      "15    5967.89      66.019     56.198     60.714                                 \n",
      "16    5967.39      65.094     57.025     60.793                                 \n",
      "17    5906.09      66.990     57.025     61.607                                 \n",
      "18    5842.47      68.000     56.198     61.538                                 \n",
      "19    5376.07      67.647     57.025     61.883                                 \n",
      "20    5383.20      70.707     57.851     63.636                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.707   57.851    63.636\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m63.636\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m‚úî Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4m‚Ñπ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ‚ú®  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2766.89      61.538     39.669     48.241                                 \n",
      " 2    2602.01      68.000     56.198     61.538                                 \n",
      " 3    2585.69      70.755     61.983     66.079                                 \n",
      " 4    2528.46      71.277     55.372     62.326                                 \n",
      " 5    2351.15      72.632     57.025     63.889                                 \n",
      " 6    2298.79      74.194     57.025     64.486                                 \n",
      " 7    2166.41      72.449     58.678     64.840                                 \n",
      " 8    2066.61      70.297     58.678     63.964                                 \n",
      " 9    2086.47      66.990     57.025     61.607                                 \n",
      "10    2096.89      67.308     57.851     62.222                                 \n",
      "11    1970.11      70.588     59.504     64.574                                 \n",
      "12    2011.52      69.903     59.504     64.286                                 \n",
      "13    1996.80      73.077     62.810     67.556                                 \n",
      "14    1930.77      73.077     62.810     67.556                                 \n",
      "15    1887.29      73.529     61.983     67.265                                 \n",
      "16    1869.41      75.000     61.983     67.873                                 \n",
      "17    1801.91      75.248     62.810     68.468                                 \n",
      "18    1836.60      74.510     62.810     68.161                                 \n",
      "19    1778.07      73.529     61.983     67.265                                 \n",
      "20    1823.88      73.529     61.983     67.265                                 \n",
      "\u001b[1m\n",
      "============================= ‚ú®  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.248   62.810    68.468\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.468\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = \"cord_19_rf_sentences,cord_19_rf_sentences_correct,cord_19_rf_sentences_correct_2\"\n",
    "\n",
    "for base_model in ['en_vectors_web_lg', 'en_core_web_lg', 'en_core_sci_lg']:\n",
    "    !prodigy train ner $datasets $base_model --eval-split 0.2 --n-iter 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`en_core_sci_lg` is still the best base model, although the margins are getting smaller."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
