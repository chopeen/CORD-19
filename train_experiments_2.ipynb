{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.06 (Mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the annotations from scratch (`RF sentences`)\n",
    "\n",
    "Following the official guide:\n",
    "- https://www.youtube.com/watch?v=59BKHO_xBPA\n",
    "- https://github.com/explosion/projects/tree/master/ner-food-ingredients#data-creation-and-training-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 102 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences\n",
      "Session ID: 2020-04-06_22-08-56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual cord_19_rf_sentences blank:en data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     389.18       0.000      0.000      0.000                                 \n",
      " 2     191.03      25.000      4.000      6.897                                 \n",
      " 3     265.45      35.294     24.000     28.571                                 \n",
      " 4     246.57      28.571     24.000     26.087                                 \n",
      " 5     239.21      22.727     20.000     21.277                                 \n",
      " 6     215.80      42.857     24.000     30.769                                 \n",
      " 7     258.40      42.105     32.000     36.364                                 \n",
      " 8     237.19      50.000     32.000     39.024                                 \n",
      " 9     208.67      62.500     40.000     48.780                                 \n",
      "10     141.30      66.667     40.000     50.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667   40.000    50.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m50.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1421.81       0.000      0.000      0.000                                 \n",
      " 2    1245.16       0.000      0.000      0.000                                 \n",
      " 3    1262.77       0.000      0.000      0.000                                 \n",
      " 4    1249.04       0.000      0.000      0.000                                 \n",
      " 5    1262.46       0.000      0.000      0.000                                 \n",
      " 6    1205.26       0.000      0.000      0.000                                 \n",
      " 7    1137.92       0.000      0.000      0.000                                 \n",
      " 8    1131.84       0.000      0.000      0.000                                 \n",
      " 9    1058.85       0.000      0.000      0.000                                 \n",
      "10    1143.62       0.000      0.000      0.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "GPE               0.000    0.000     0.000\n",
      "RISK_FACTOR       0.000    0.000     0.000\n",
      "CARDINAL          0.000    0.000     0.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m0.000\u001b[0m\n",
      "Baseline       0.000             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⁉️ Why is `en_core_web_lg` producing no results at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     559.17       0.000      0.000      0.000                                 \n",
      " 2     550.33      33.333      8.000     12.903                                 \n",
      " 3     538.43      50.000     24.000     32.432                                 \n",
      " 4     457.89      52.632     40.000     45.455                                 \n",
      " 5     452.06      50.000     36.000     41.860                                 \n",
      " 6     415.01      60.000     48.000     53.333                                 \n",
      " 7     489.45      47.826     44.000     45.833                                 \n",
      " 8     461.13      45.000     36.000     40.000                                 \n",
      " 9     486.03      47.619     40.000     43.478                                 \n",
      "10     406.83      54.545     48.000     51.064                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   48.000    53.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m53.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_06_rf_sentences\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 --output models/2020_04_06_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_vectors_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "embed_rows: 2000 | require_vectors: True | cnn_maxout_pieces: 3 |\n",
      "token_vector_width: 96 | conv_depth: 4 | nr_feature_tokens: 3 |\n",
      "pretrained_vectors: en_vectors_web_lg.vectors\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     339.88       0.000      0.000      0.000                                 \n",
      " 2     199.85      50.000     16.000     24.242                                 \n",
      " 3     128.26      50.000     28.000     35.897                                 \n",
      " 4      76.43      42.857     24.000     30.769                                 \n",
      " 5      63.28      60.000     36.000     45.000                                 \n",
      " 6      29.70      53.333     32.000     40.000                                 \n",
      " 7      21.18      56.250     36.000     43.902                                 \n",
      " 8      36.86      50.000     36.000     41.860                                 \n",
      " 9      13.28      52.941     36.000     42.857                                 \n",
      "10       7.74      52.941     36.000     42.857                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   36.000    45.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m45.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_vectors_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_web_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_vectors_model436.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2055.18       0.000      0.000      0.000                                 \n",
      " 2    1808.48       0.000      0.000      0.000                                 \n",
      " 3    1624.76       0.000      0.000      0.000                                 \n",
      " 4    1443.31       0.000      0.000      0.000                                 \n",
      " 5    1652.93       0.000      0.000      0.000                                 \n",
      " 6    1470.22       0.000      0.000      0.000                                 \n",
      " 7    1345.14       0.000      0.000      0.000                                 \n",
      " 8    1403.16      50.000      4.000      7.407                                 \n",
      " 9    1249.90      66.667      8.000     14.286                                 \n",
      "10    1357.22      66.667      8.000     14.286                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667    8.000    14.286\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m14.286\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_web_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_vectors_model436.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `en_core_sci_lg` + tok2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 10\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     536.68       0.000      0.000      0.000                                 \n",
      " 2     631.61       0.000      0.000      0.000                                 \n",
      " 3     539.99      40.000     24.000     30.000                                 \n",
      " 4     505.27      47.619     40.000     43.478                                 \n",
      " 5     508.05      45.000     36.000     40.000                                 \n",
      " 6     461.69      52.941     36.000     42.857                                 \n",
      " 7     473.25      45.000     36.000     40.000                                 \n",
      " 8     571.35      61.111     44.000     51.163                                 \n",
      " 9     465.27      55.556     40.000     46.512                                 \n",
      "10     455.26      43.750     28.000     34.146                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      61.111   44.000    51.163\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m51.163\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences en_core_sci_lg --eval-split 0.2 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔥 Top model so far: `53.333` 🔥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label more data by correcting the model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_rf_sentences_correct to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 220 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences_correct\n",
      "Session ID: 2020-04-06_23-58-48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.correct cord_19_rf_sentences_correct models/2020_04_06_rf_sentences data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR --exclude cord_19_rf_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For futher training, only `en_core_sci_lg` will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1554.25      61.538     37.500     46.602                                 \n",
      " 2    1346.09      64.407     59.375     61.789                                 \n",
      " 3    1407.15      66.667     50.000     57.143                                 \n",
      " 4    1411.73      72.727     50.000     59.259                                 \n",
      " 5    1412.81      73.913     53.125     61.818                                 \n",
      " 6    1319.96      73.913     53.125     61.818                                 \n",
      " 7    1378.05      72.917     54.688     62.500                                 \n",
      " 8    1208.99      72.727     62.500     67.227                                 \n",
      " 9    1177.16      73.077     59.375     65.517                                 \n",
      "10    1211.40      72.549     57.812     64.348                                 \n",
      "11    1142.34      74.510     59.375     66.087                                 \n",
      "12    1196.27      72.000     56.250     63.158                                 \n",
      "13    1153.93      72.000     56.250     63.158                                 \n",
      "14    1149.78      72.549     57.812     64.348                                 \n",
      "15    1154.34      69.231     56.250     62.069                                 \n",
      "16    1104.68      69.231     56.250     62.069                                 \n",
      "17    1062.17      68.627     54.688     60.870                                 \n",
      "18    1063.28      68.627     54.688     60.870                                 \n",
      "19    1048.51      68.627     54.688     60.870                                 \n",
      "20    1120.40      68.627     54.688     60.870                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.727   62.500    67.227\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.227\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1578.16      64.000     25.000     35.955                                 \n",
      " 2    1439.61      55.319     40.625     46.847                                 \n",
      " 3    1528.20      72.222     60.938     66.102                                 \n",
      " 4    1429.18      71.154     57.812     63.793                                 \n",
      " 5    1414.46      69.388     53.125     60.177                                 \n",
      " 6    1344.69      75.472     62.500     68.376                                 \n",
      " 7    1472.62      70.909     60.938     65.546                                 \n",
      " 8    1296.39      74.545     64.062     68.908                                 \n",
      " 9    1285.11      68.966     62.500     65.574                                 \n",
      "10    1236.84      70.175     62.500     66.116                                 \n",
      "11    1181.13      71.429     62.500     66.667                                 \n",
      "12    1235.60      70.909     60.938     65.546                                 \n",
      "13    1238.99      76.923     62.500     68.966                                 \n",
      "14    1151.94      75.926     64.062     69.492                                 \n",
      "15    1151.25      75.926     64.062     69.492                                 \n",
      "16    1218.30      78.000     60.938     68.421                                 \n",
      "17    1074.01      75.926     64.062     69.492                                 \n",
      "18    1121.71      76.364     65.625     70.588                                 \n",
      "19    1084.27      77.358     64.062     70.085                                 \n",
      "20    1106.32      76.471     60.938     67.826                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_07_rf_sentences_corrected\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model328.bin --output models/2020_04_07_rf_sentences_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.28      62.500     23.438     34.091                                 \n",
      " 2    1397.40      59.091     40.625     48.148                                 \n",
      " 3    1485.47      70.833     53.125     60.714                                 \n",
      " 4    1445.56      68.293     43.750     53.333                                 \n",
      " 5    1431.31      64.000     50.000     56.140                                 \n",
      " 6    1339.87      70.833     53.125     60.714                                 \n",
      " 7    1387.07      72.340     53.125     61.261                                 \n",
      " 8    1232.74      76.596     56.250     64.865                                 \n",
      " 9    1207.39      72.340     53.125     61.261                                 \n",
      "10    1231.53      75.926     64.062     69.492                                 \n",
      "11    1154.22      74.545     64.062     68.908                                 \n",
      "12    1304.76      75.472     62.500     68.376                                 \n",
      "13    1155.21      69.811     57.812     63.248                                 \n",
      "14    1158.97      67.273     57.812     62.185                                 \n",
      "15    1092.88      69.811     57.812     63.248                                 \n",
      "16    1134.04      68.627     54.688     60.870                                 \n",
      "17    1055.42      66.667     56.250     61.017                                 \n",
      "18    1071.15      66.667     56.250     61.017                                 \n",
      "19    1060.90      69.231     56.250     62.069                                 \n",
      "20    1063.32      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model989.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.09 (Thu)\n",
    "## Experiments with new `tok2vec` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1577.68      57.895     34.375     43.137                                 \n",
      " 2    1386.95      67.308     54.688     60.345                                 \n",
      " 3    1455.49      76.596     56.250     64.865                                 \n",
      " 4    1457.04      79.592     60.938     69.027                                 \n",
      " 5    1413.30      78.431     62.500     69.565                                 \n",
      " 6    1351.85      76.923     62.500     68.966                                 \n",
      " 7    1304.38      78.000     60.938     68.421                                 \n",
      " 8    1255.67      76.471     60.938     67.826                                 \n",
      " 9    1219.66      78.431     62.500     69.565                                 \n",
      "10    1203.83      74.545     64.062     68.908                                 \n",
      "11    1125.02      74.545     64.062     68.908                                 \n",
      "12    1224.65      74.074     62.500     67.797                                 \n",
      "13    1173.56      75.000     60.938     67.241                                 \n",
      "14    1170.88      75.000     60.938     67.241                                 \n",
      "15    1074.42      71.154     57.812     63.793                                 \n",
      "16    1144.97      75.000     60.938     67.241                                 \n",
      "17    1041.02      73.077     59.375     65.517                                 \n",
      "18    1094.32      74.510     59.375     66.087                                 \n",
      "19    1051.65      74.510     59.375     66.087                                 \n",
      "20    1099.61      78.000     60.938     68.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.431   62.500    69.565\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.565\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model978_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1630.03      55.556     23.438     32.967                                 \n",
      " 2    1442.41      55.556     46.875     50.847                                 \n",
      " 3    1429.19      65.957     48.438     55.856                                 \n",
      " 4    1467.20      65.455     56.250     60.504                                 \n",
      " 5    1467.20      69.643     60.938     65.000                                 \n",
      " 6    1376.49      67.241     60.938     63.934                                 \n",
      " 7    1324.06      73.585     60.938     66.667                                 \n",
      " 8    1261.74      75.472     62.500     68.376                                 \n",
      " 9    1229.62      77.358     64.062     70.085                                 \n",
      "10    1162.35      74.545     64.062     68.908                                 \n",
      "11    1129.31      72.727     62.500     67.227                                 \n",
      "12    1226.05      73.684     65.625     69.421                                 \n",
      "13    1154.44      73.684     65.625     69.421                                 \n",
      "14    1146.38      69.492     64.062     66.667                                 \n",
      "15    1157.15      70.175     62.500     66.116                                 \n",
      "16    1122.06      72.549     57.812     64.348                                 \n",
      "17    1069.36      70.909     60.938     65.546                                 \n",
      "18    1112.07      71.930     64.062     67.769                                 \n",
      "19    1040.95      70.370     59.375     64.407                                 \n",
      "20    1074.33      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   64.062    70.085\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.085\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_rf_sci_model997_gpu.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1587.95      62.963     26.562     37.363                                 \n",
      " 2    1500.37      60.784     48.438     53.913                                 \n",
      " 3    1510.36      63.492     62.500     62.992                                 \n",
      " 4    1519.20      60.000     56.250     58.065                                 \n",
      " 5    1521.26      65.574     62.500     64.000                                 \n",
      " 6    1495.73      64.912     57.812     61.157                                 \n",
      " 7    1386.50      65.517     59.375     62.295                                 \n",
      " 8    1225.63      65.574     62.500     64.000                                 \n",
      " 9    1277.40      65.079     64.062     64.567                                 \n",
      "10    1258.71      62.903     60.938     61.905                                 \n",
      "11    1151.32      61.905     60.938     61.417                                 \n",
      "12    1249.35      63.793     57.812     60.656                                 \n",
      "13    1169.56      67.241     60.938     63.934                                 \n",
      "14    1163.40      65.517     59.375     62.295                                 \n",
      "15    1137.84      65.517     59.375     62.295                                 \n",
      "16    1137.22      67.241     60.938     63.934                                 \n",
      "17    1094.24      67.857     59.375     63.333                                 \n",
      "18    1079.29      63.793     57.812     60.656                                 \n",
      "19    1028.63      63.158     56.250     59.504                                 \n",
      "20    1096.86      63.158     56.250     59.504                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.079   64.062    64.567\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.567\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg --eval-split 0.2 --n-iter 20 \\\n",
    "    --init-tok2vec models/tok2vec_abs_fil_sci_model975_gpu.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.10 (Fri)\n",
    "## Experiments with new `tok2vec` models (cont.)\n",
    "\n",
    "The Kaggle notebook training models for the full set of abstracts (i.e. `cord_19_abstracts.jsonl`) crashed, so I have only partial results and no loss metrics for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model100.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.29      43.478     31.250     36.364                                 \n",
      " 2    1421.36      59.574     43.750     50.450                                 \n",
      " 3    1486.19      68.519     57.812     62.712                                 \n",
      " 4    1477.14      70.000     54.688     61.404                                 \n",
      " 5    1389.42      73.469     56.250     63.717                                 \n",
      " 6    1377.87      70.000     54.688     61.404                                 \n",
      " 7    1379.27      65.385     53.125     58.621                                 \n",
      " 8    1256.60      64.151     53.125     58.120                                 \n",
      " 9    1242.36      66.038     54.688     59.829                                 \n",
      "10    1237.03      63.636     54.688     58.824                                 \n",
      "11    1130.25      65.385     53.125     58.621                                 \n",
      "12    1249.05      65.455     56.250     60.504                                 \n",
      "13    1186.25      68.519     57.812     62.712                                 \n",
      "14    1166.91      68.519     57.812     62.712                                 \n",
      "15    1119.23      66.071     57.812     61.667                                 \n",
      "16    1100.72      67.925     56.250     61.538                                 \n",
      "17    1057.66      74.576     68.750     71.545                                 \n",
      "18    1086.26      74.138     67.188     70.492                                 \n",
      "19    1057.49      69.841     68.750     69.291                                 \n",
      "20    1090.37      73.684     65.625     69.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model113.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1576.82      54.167     40.625     46.429                                 \n",
      " 2    1441.99      56.522     40.625     47.273                                 \n",
      " 3    1413.20      71.429     62.500     66.667                                 \n",
      " 4    1530.83      68.519     57.812     62.712                                 \n",
      " 5    1508.39      70.968     68.750     69.841                                 \n",
      " 6    1418.20      71.930     64.062     67.769                                 \n",
      " 7    1390.90      74.576     68.750     71.545                                 \n",
      " 8    1306.18      69.492     64.062     66.667                                 \n",
      " 9    1288.81      69.355     67.188     68.254                                 \n",
      "10    1235.70      67.692     68.750     68.217                                 \n",
      "11    1176.14      68.852     65.625     67.200                                 \n",
      "12    1225.75      71.186     65.625     68.293                                 \n",
      "13    1223.52      71.186     65.625     68.293                                 \n",
      "14    1144.79      70.370     59.375     64.407                                 \n",
      "15    1097.53      71.429     62.500     66.667                                 \n",
      "16    1107.15      71.429     62.500     66.667                                 \n",
      "17    1077.94      69.643     60.938     65.000                                 \n",
      "18    1110.78      72.222     60.938     66.102                                 \n",
      "19    1034.04      71.698     59.375     64.957                                 \n",
      "20    1096.63      71.429     62.500     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model126.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1606.39      43.636     37.500     40.336                                 \n",
      " 2    1452.80      60.000     51.562     55.462                                 \n",
      " 3    1437.93      59.677     57.812     58.730                                 \n",
      " 4    1419.75      63.043     45.312     52.727                                 \n",
      " 5    1400.15      67.925     56.250     61.538                                 \n",
      " 6    1396.64      68.750     51.562     58.929                                 \n",
      " 7    1385.28      66.667     59.375     62.810                                 \n",
      " 8    1260.33      66.667     59.375     62.810                                 \n",
      " 9    1228.95      69.231     56.250     62.069                                 \n",
      "10    1247.29      66.667     56.250     61.017                                 \n",
      "11    1176.21      66.102     60.938     63.415                                 \n",
      "12    1288.26      66.667     59.375     62.810                                 \n",
      "13    1179.91      69.091     59.375     63.866                                 \n",
      "14    1154.00      70.175     62.500     66.116                                 \n",
      "15    1152.69      68.966     62.500     65.574                                 \n",
      "16    1109.37      68.966     62.500     65.574                                 \n",
      "17    1050.43      67.857     59.375     63.333                                 \n",
      "18    1085.32      68.421     60.938     64.463                                 \n",
      "19    1029.84      64.706     51.562     57.391                                 \n",
      "20    1096.32      67.347     51.562     58.407                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.175   62.500    66.116\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.116\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model139.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1563.29      51.020     39.062     44.248                                 \n",
      " 2    1501.66      58.333     43.750     50.000                                 \n",
      " 3    1542.60      67.188     67.188     67.188                                 \n",
      " 4    1474.47      72.222     60.938     66.102                                 \n",
      " 5    1509.19      75.000     56.250     64.286                                 \n",
      " 6    1413.26      68.000     53.125     59.649                                 \n",
      " 7    1335.99      68.627     54.688     60.870                                 \n",
      " 8    1413.31      64.706     51.562     57.391                                 \n",
      " 9    1186.98      66.667     56.250     61.017                                 \n",
      "10    1248.32      69.231     56.250     62.069                                 \n",
      "11    1140.08      69.388     53.125     60.177                                 \n",
      "12    1236.78      68.750     51.562     58.929                                 \n",
      "13    1175.07      65.385     53.125     58.621                                 \n",
      "14    1142.11      65.385     53.125     58.621                                 \n",
      "15    1129.54      66.038     54.688     59.829                                 \n",
      "16    1106.93      68.750     51.562     58.929                                 \n",
      "17    1070.87      70.213     51.562     59.459                                 \n",
      "18    1088.39      70.213     51.562     59.459                                 \n",
      "19    1034.52      70.213     51.562     59.459                                 \n",
      "20    1128.90      68.750     51.562     58.929                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      67.188   67.188    67.188\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.188\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model152.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1571.39      58.140     39.062     46.729                                 \n",
      " 2    1510.07      60.000     46.875     52.632                                 \n",
      " 3    1489.39      72.917     54.688     62.500                                 \n",
      " 4    1469.38      69.643     60.938     65.000                                 \n",
      " 5    1444.18      70.833     53.125     60.714                                 \n",
      " 6    1500.48      68.085     50.000     57.658                                 \n",
      " 7    1316.60      68.085     50.000     57.658                                 \n",
      " 8    1286.18      68.750     51.562     58.929                                 \n",
      " 9    1264.42      71.429     54.688     61.947                                 \n",
      "10    1190.15      73.913     53.125     61.818                                 \n",
      "11    1131.21      75.510     57.812     65.487                                 \n",
      "12    1242.04      76.923     62.500     68.966                                 \n",
      "13    1185.61      72.340     53.125     61.261                                 \n",
      "14    1145.75      72.340     53.125     61.261                                 \n",
      "15    1116.77      75.472     62.500     68.376                                 \n",
      "16    1116.36      75.472     62.500     68.376                                 \n",
      "17    1059.02      73.585     60.938     66.667                                 \n",
      "18    1068.08      73.585     60.938     66.667                                 \n",
      "19    1059.03      75.472     62.500     68.376                                 \n",
      "20    1074.62      75.000     60.938     67.241                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.923   62.500    68.966\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.966\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model165.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1547.07      74.194     35.938     48.421                                 \n",
      " 2    1462.56      62.069     56.250     59.016                                 \n",
      " 3    1496.71      70.690     64.062     67.213                                 \n",
      " 4    1449.38      74.074     62.500     67.797                                 \n",
      " 5    1418.87      77.358     64.062     70.085                                 \n",
      " 6    1337.26      75.926     64.062     69.492                                 \n",
      " 7    1383.02      72.414     65.625     68.852                                 \n",
      " 8    1291.23      68.852     65.625     67.200                                 \n",
      " 9    1266.25      71.186     65.625     68.293                                 \n",
      "10    1185.12      69.355     67.188     68.254                                 \n",
      "11    1158.02      72.881     67.188     69.919                                 \n",
      "12    1188.67      73.333     68.750     70.968                                 \n",
      "13    1160.96      73.214     64.062     68.333                                 \n",
      "14    1138.56      71.930     64.062     67.769                                 \n",
      "15    1126.51      72.881     67.188     69.919                                 \n",
      "16    1089.93      71.186     65.625     68.293                                 \n",
      "17    1036.84      70.175     62.500     66.116                                 \n",
      "18    1102.04      69.643     60.938     65.000                                 \n",
      "19    1049.66      69.643     60.938     65.000                                 \n",
      "20    1071.79      68.421     60.938     64.463                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.333   68.750    70.968\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.968\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2Kading 'en_core_sci_lg'...\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model178.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1548.43      60.976     39.062     47.619                                 \n",
      " 2    1396.43      63.043     45.312     52.727                                 \n",
      " 3    1488.35      68.085     50.000     57.658                                 \n",
      " 4    1412.67      69.565     50.000     58.182                                 \n",
      " 5    1416.63      65.957     48.438     55.856                                 \n",
      " 6    1373.68      71.111     50.000     58.716                                 \n",
      " 7    1388.35      75.472     62.500     68.376                                 \n",
      " 8    1260.08      69.388     53.125     60.177                                 \n",
      " 9    1297.26      71.429     54.688     61.947                                 \n",
      "10    1221.41      71.429     54.688     61.947                                 \n",
      "11    1112.34      76.364     65.625     70.588                                 \n",
      "12    1259.60      67.857     59.375     63.333                                 \n",
      "13    1150.64      66.071     57.812     61.667                                 \n",
      "14    1120.27      67.308     54.688     60.345                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    1143.57      69.231     56.250     62.069                                 \n",
      "16    1108.60      69.091     59.375     63.866                                 \n",
      "17    1037.24      66.667     59.375     62.810                                 \n",
      "18    1059.90      67.857     59.375     63.333                                 \n",
      "19    1029.31      65.517     59.375     62.295                                 \n",
      "20    1091.05      67.797     62.500     65.041                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model191.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1531.35      54.839     26.562     35.789                                 \n",
      " 2    1411.43      65.909     45.312     53.704                                 \n",
      " 3    1398.77      67.391     48.438     56.364                                 \n",
      " 4    1362.76      66.667     56.250     61.017                                 \n",
      " 5    1381.48      70.909     60.938     65.546                                 \n",
      " 6    1355.07      76.364     65.625     70.588                                 \n",
      " 7    1335.37      73.585     60.938     66.667                                 \n",
      " 8    1285.76      68.750     51.562     58.929                                 \n",
      " 9    1227.28      77.778     65.625     71.186                                 \n",
      "10    1201.31      78.182     67.188     72.269                                 \n",
      "11    1149.59      73.469     56.250     63.717                                 \n",
      "12    1275.63      73.469     56.250     63.717                                 \n",
      "13    1207.65      76.364     65.625     70.588                                 \n",
      "14    1130.14      74.576     68.750     71.545                                 \n",
      "15    1099.09      71.186     65.625     68.293                                 \n",
      "16    1126.79      70.690     64.062     67.213                                 \n",
      "17    1046.66      71.930     64.062     67.769                                 \n",
      "18    1065.97      71.186     65.625     68.293                                 \n",
      "19    1034.82      72.414     65.625     68.852                                 \n",
      "20    1099.55      72.414     65.625     68.852                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model204.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1559.76      60.606     31.250     41.237                                 \n",
      " 2    1453.45      50.820     48.438     49.600                                 \n",
      " 3    1409.66      65.079     64.062     64.567                                 \n",
      " 4    1475.36      73.684     65.625     69.421                                 \n",
      " 5    1361.59      71.186     65.625     68.293                                 \n",
      " 6    1355.81      71.186     65.625     68.293                                 \n",
      " 7    1318.82      73.585     60.938     66.667                                 \n",
      " 8    1249.84      68.627     54.688     60.870                                 \n",
      " 9    1261.36      71.667     67.188     69.355                                 \n",
      "10    1192.93      70.690     64.062     67.213                                 \n",
      "11    1132.25      71.667     67.188     69.355                                 \n",
      "12    1208.10      68.333     64.062     66.129                                 \n",
      "13    1172.95      67.213     64.062     65.600                                 \n",
      "14    1127.60      71.930     64.062     67.769                                 \n",
      "15    1129.79      68.852     65.625     67.200                                 \n",
      "16    1101.97      71.186     65.625     68.293                                 \n",
      "17    1044.06      72.414     65.625     68.852                                 \n",
      "18    1063.17      73.684     65.625     69.421                                 \n",
      "19    1053.16      70.175     62.500     66.116                                 \n",
      "20    1088.13      69.643     60.938     65.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model217.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1588.40      50.000     34.375     40.741                                 \n",
      " 2    1381.86      64.444     45.312     53.211                                 \n",
      " 3    1377.05      72.549     57.812     64.348                                 \n",
      " 4    1447.86      79.592     60.938     69.027                                 \n",
      " 5    1434.80      77.193     68.750     72.727                                 \n",
      " 6    1396.29      76.667     71.875     74.194                                 \n",
      " 7    1305.60      76.667     71.875     74.194                                 \n",
      " 8    1262.80      71.429     70.312     70.866                                 \n",
      " 9    1177.84      69.231     70.312     69.767                                 \n",
      "10    1187.94      71.186     65.625     68.293                                 \n",
      "11    1123.51      71.930     64.062     67.769                                 \n",
      "12    1221.49      70.690     64.062     67.213                                 \n",
      "13    1162.42      73.214     64.062     68.333                                 \n",
      "14    1143.42      73.585     60.938     66.667                                 \n",
      "15    1102.69      69.643     60.938     65.000                                 \n",
      "16    1078.37      70.909     60.938     65.546                                 \n",
      "17    1052.39      72.222     60.938     66.102                                 \n",
      "18    1064.30      74.545     64.062     68.908                                 \n",
      "19    1045.06      74.545     64.062     68.908                                 \n",
      "20    1089.94      73.214     64.062     68.333                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.667   71.875    74.194\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.194\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model230.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1537.49      65.714     35.938     46.465                                 \n",
      " 2    1506.48      51.064     37.500     43.243                                 \n",
      " 3    1436.09      68.627     54.688     60.870                                 \n",
      " 4    1438.86      67.925     56.250     61.538                                 \n",
      " 5    1471.17      58.730     57.812     58.268                                 \n",
      " 6    1395.94      76.786     67.188     71.667                                 \n",
      " 7    1329.15      71.186     65.625     68.293                                 \n",
      " 8    1224.20      70.000     65.625     67.742                                 \n",
      " 9    1212.04      72.222     60.938     66.102                                 \n",
      "10    1220.04      74.074     62.500     67.797                                 \n",
      "11    1146.63      77.358     64.062     70.085                                 \n",
      "12    1201.44      78.846     64.062     70.690                                 \n",
      "13    1193.53      73.214     64.062     68.333                                 \n",
      "14    1151.32      73.214     64.062     68.333                                 \n",
      "15    1174.86      72.414     65.625     68.852                                 \n",
      "16    1132.91      75.000     65.625     70.000                                 \n",
      "17    1062.43      73.684     65.625     69.421                                 \n",
      "18    1104.23      74.545     64.062     68.908                                 \n",
      "19    1082.55      73.214     64.062     68.333                                 \n",
      "20    1089.93      71.930     64.062     67.769                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.786   67.188    71.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model243.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1511.24      72.000     28.125     40.449                                 \n",
      " 2    1438.49      60.784     48.438     53.913                                 \n",
      " 3    1436.51      69.643     60.938     65.000                                 \n",
      " 4    1509.60      66.102     60.938     63.415                                 \n",
      " 5    1540.57      66.129     64.062     65.079                                 \n",
      " 6    1377.66      66.667     53.125     59.130                                 \n",
      " 7    1324.55      73.684     65.625     69.421                                 \n",
      " 8    1321.93      69.355     67.188     68.254                                 \n",
      " 9    1203.07      69.841     68.750     69.291                                 \n",
      "10    1180.82      70.492     67.188     68.800                                 \n",
      "11    1123.77      69.355     67.188     68.254                                 \n",
      "12    1239.00      69.355     67.188     68.254                                 \n",
      "13    1148.78      68.750     68.750     68.750                                 \n",
      "14    1158.82      67.692     68.750     68.217                                 \n",
      "15    1085.99      68.254     67.188     67.717                                 \n",
      "16    1131.41      67.742     65.625     66.667                                 \n",
      "17    1055.09      70.690     64.062     67.213                                 \n",
      "18    1065.59      71.930     64.062     67.769                                 \n",
      "19    1040.85      71.930     64.062     67.769                                 \n",
      "20    1082.37      70.175     62.500     66.116                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model256.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1545.08      58.621     26.562     36.559                                 \n",
      " 2    1419.43      62.745     50.000     55.652                                 \n",
      " 3    1450.36      73.214     64.062     68.333                                 \n",
      " 4    1400.91      70.690     64.062     67.213                                 \n",
      " 5    1412.40      70.588     56.250     62.609                                 \n",
      " 6    1341.37      74.000     57.812     64.912                                 \n",
      " 7    1343.98      70.833     53.125     60.714                                 \n",
      " 8    1292.65      71.111     50.000     58.716                                 \n",
      " 9    1179.34      69.565     50.000     58.182                                 \n",
      "10    1247.50      70.213     51.562     59.459                                 \n",
      "11    1175.39      70.833     53.125     60.714                                 \n",
      "12    1229.61      75.472     62.500     68.376                                 \n",
      "13    1182.13      74.545     64.062     68.908                                 \n",
      "14    1167.71      72.222     60.938     66.102                                 \n",
      "15    1113.38      70.370     59.375     64.407                                 \n",
      "16    1094.86      74.074     62.500     67.797                                 \n",
      "17    1076.16      69.091     59.375     63.866                                 \n",
      "18    1109.22      62.500     46.875     53.571                                 \n",
      "19    1060.25      63.830     46.875     54.054                                 \n",
      "20    1087.38      63.830     46.875     54.054                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   64.062    68.908\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.908\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model269.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1520.36      78.947     23.438     36.145                                 \n",
      " 2    1397.99      65.574     62.500     64.000                                 \n",
      " 3    1442.61      75.000     65.625     70.000                                 \n",
      " 4    1391.94      71.698     59.375     64.957                                 \n",
      " 5    1394.91      71.930     64.062     67.769                                 \n",
      " 6    1356.89      68.421     60.938     64.463                                 \n",
      " 7    1364.08      69.231     56.250     62.069                                 \n",
      " 8    1270.54      71.698     59.375     64.957                                 \n",
      " 9    1203.23      70.909     60.938     65.546                                 \n",
      "10    1188.31      66.667     62.500     64.516                                 \n",
      "11    1153.89      69.492     64.062     66.667                                 \n",
      "12    1197.13      69.492     64.062     66.667                                 \n",
      "13    1194.79      71.698     59.375     64.957                                 \n",
      "14    1113.36      72.727     62.500     67.227                                 \n",
      "15    1105.46      73.585     60.938     66.667                                 \n",
      "16    1116.92      73.077     59.375     65.517                                 \n",
      "17    1031.77      74.510     59.375     66.087                                 \n",
      "18    1073.23      73.077     59.375     65.517                                 \n",
      "19    1062.78      71.698     59.375     64.957                                 \n",
      "20    1108.77      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   65.625    70.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model282.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1475.57      73.529     39.062     51.020                                 \n",
      " 2    1444.66      61.538     50.000     55.172                                 \n",
      " 3    1397.05      65.306     50.000     56.637                                 \n",
      " 4    1422.26      63.265     48.438     54.867                                 \n",
      " 5    1386.09      68.421     60.938     64.463                                 \n",
      " 6    1353.86      76.923     62.500     68.966                                 \n",
      " 7    1395.51      70.690     64.062     67.213                                 \n",
      " 8    1243.82      75.472     62.500     68.376                                 \n",
      " 9    1247.40      70.492     67.188     68.800                                 \n",
      "10    1174.12      72.414     65.625     68.852                                 \n",
      "11    1156.15      73.684     65.625     69.421                                 \n",
      "12    1239.20      73.214     64.062     68.333                                 \n",
      "13    1186.23      71.930     64.062     67.769                                 \n",
      "14    1136.16      71.930     64.062     67.769                                 \n",
      "15    1090.41      68.333     64.062     66.129                                 \n",
      "16    1081.16      67.797     62.500     65.041                                 \n",
      "17    1064.12      67.213     64.062     65.600                                 \n",
      "18    1071.57      66.667     65.625     66.142                                 \n",
      "19    1029.70      67.742     65.625     66.667                                 \n",
      "20    1097.97      66.667     62.500     64.516                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.684   65.625    69.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model295.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1523.41      65.517     29.688     40.860                                 \n",
      " 2    1468.56      58.824     46.875     52.174                                 \n",
      " 3    1469.97      65.306     50.000     56.637                                 \n",
      " 4    1435.29      66.667     53.125     59.130                                 \n",
      " 5    1517.71      66.667     53.125     59.130                                 \n",
      " 6    1426.38      78.182     67.188     72.269                                 \n",
      " 7    1363.57      74.545     64.062     68.908                                 \n",
      " 8    1204.75      72.131     68.750     70.400                                 \n",
      " 9    1215.02      70.000     65.625     67.742                                 \n",
      "10    1153.08      72.000     56.250     63.158                                 \n",
      "11    1153.13      75.000     65.625     70.000                                 \n",
      "12    1206.34      75.000     65.625     70.000                                 \n",
      "13    1186.23      74.074     62.500     67.797                                 \n",
      "14    1124.83      73.585     60.938     66.667                                 \n",
      "15    1125.46      72.727     62.500     67.227                                 \n",
      "16    1111.84      74.545     64.062     68.908                                 \n",
      "17    1060.41      75.000     65.625     70.000                                 \n",
      "18    1056.05      75.439     67.188     71.074                                 \n",
      "19    1054.58      75.439     67.188     71.074                                 \n",
      "20    1097.81      77.778     65.625     71.186                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model308.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.02      61.905     40.625     49.057                                 \n",
      " 2    1389.84      56.897     51.562     54.098                                 \n",
      " 3    1485.12      71.698     59.375     64.957                                 \n",
      " 4    1385.46      70.175     62.500     66.116                                 \n",
      " 5    1455.78      72.727     62.500     67.227                                 \n",
      " 6    1404.07      78.947     70.312     74.380                                 \n",
      " 7    1323.94      81.818     70.312     75.630                                 \n",
      " 8    1229.71      75.862     68.750     72.131                                 \n",
      " 9    1211.78      77.966     71.875     74.797                                 \n",
      "10    1249.24      76.786     67.188     71.667                                 \n",
      "11    1124.41      76.786     67.188     71.667                                 \n",
      "12    1227.59      75.926     64.062     69.492                                 \n",
      "13    1188.04      71.429     62.500     66.667                                 \n",
      "14    1126.55      77.358     64.062     70.085                                 \n",
      "15    1136.49      77.358     64.062     70.085                                 \n",
      "16    1146.76      78.431     62.500     69.565                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    1045.76      74.545     64.062     68.908                                 \n",
      "18    1047.72      74.545     64.062     68.908                                 \n",
      "19    1039.92      76.786     67.188     71.667                                 \n",
      "20    1076.51      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.818   70.312    75.630\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.630\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model321.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1510.93      68.421     40.625     50.980                                 \n",
      " 2    1444.88      54.545     46.875     50.420                                 \n",
      " 3    1377.60      68.519     57.812     62.712                                 \n",
      " 4    1388.17      70.690     64.062     67.213                                 \n",
      " 5    1384.22      70.968     68.750     69.841                                 \n",
      " 6    1382.66      70.968     68.750     69.841                                 \n",
      " 7    1300.98      69.355     67.188     68.254                                 \n",
      " 8    1268.51      65.000     60.938     62.903                                 \n",
      " 9    1194.28      68.333     64.062     66.129                                 \n",
      "10    1182.41      72.881     67.188     69.919                                 \n",
      "11    1179.37      75.926     64.062     69.492                                 \n",
      "12    1226.69      71.930     64.062     67.769                                 \n",
      "13    1214.25      70.690     64.062     67.213                                 \n",
      "14    1115.74      71.930     64.062     67.769                                 \n",
      "15    1076.93      70.000     65.625     67.742                                 \n",
      "16    1106.47      72.881     67.188     69.919                                 \n",
      "17    1046.70      72.881     67.188     69.919                                 \n",
      "18    1060.13      71.667     67.188     69.355                                 \n",
      "19    1050.26      71.667     67.188     69.355                                 \n",
      "20    1090.53      71.667     67.188     69.355                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.881   67.188    69.919\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.919\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model334.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1483.42      67.647     35.938     46.939                                 \n",
      " 2    1437.08      51.613     50.000     50.794                                 \n",
      " 3    1444.43      75.472     62.500     68.376                                 \n",
      " 4    1379.16      70.370     59.375     64.407                                 \n",
      " 5    1422.62      80.000     62.500     70.175                                 \n",
      " 6    1320.15      79.630     67.188     72.881                                 \n",
      " 7    1373.90      79.310     71.875     75.410                                 \n",
      " 8    1283.61      75.862     68.750     72.131                                 \n",
      " 9    1215.63      79.630     67.188     72.881                                 \n",
      "10    1176.07      76.364     65.625     70.588                                 \n",
      "11    1140.37      78.182     67.188     72.269                                 \n",
      "12    1217.24      78.571     68.750     73.333                                 \n",
      "13    1203.73      78.182     67.188     72.269                                 \n",
      "14    1205.44      79.630     67.188     72.881                                 \n",
      "15    1122.55      81.132     67.188     73.504                                 \n",
      "16    1127.57      81.132     67.188     73.504                                 \n",
      "17    1093.40      82.692     67.188     74.138                                 \n",
      "18    1059.69      81.481     68.750     74.576                                 \n",
      "19    1052.47      78.182     67.188     72.269                                 \n",
      "20    1074.00      75.000     70.312     72.581                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.310   71.875    75.410\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.410\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model347.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1491.38      73.077     29.688     42.222                                 \n",
      " 2    1383.10      54.098     51.562     52.800                                 \n",
      " 3    1424.20      67.857     59.375     63.333                                 \n",
      " 4    1404.94      71.154     57.812     63.793                                 \n",
      " 5    1405.28      68.254     67.188     67.717                                 \n",
      " 6    1394.99      77.778     65.625     71.186                                 \n",
      " 7    1317.99      74.138     67.188     70.492                                 \n",
      " 8    1188.57      65.517     59.375     62.295                                 \n",
      " 9    1200.68      68.333     64.062     66.129                                 \n",
      "10    1172.03      67.742     65.625     66.667                                 \n",
      "11    1117.81      67.742     65.625     66.667                                 \n",
      "12    1173.13      68.421     60.938     64.463                                 \n",
      "13    1186.30      68.421     60.938     64.463                                 \n",
      "14    1122.39      68.421     60.938     64.463                                 \n",
      "15    1108.01      68.966     62.500     65.574                                 \n",
      "16    1117.94      72.414     65.625     68.852                                 \n",
      "17    1022.12      70.690     64.062     67.213                                 \n",
      "18    1066.09      70.690     64.062     67.213                                 \n",
      "19    1051.72      71.930     64.062     67.769                                 \n",
      "20    1075.17      71.429     62.500     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.778   65.625    71.186\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.186\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model360.bin\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1483.42      63.415     40.625     49.524                                 \n",
      " 2    1529.89      60.000     60.938     60.465                                 \n",
      " 3    1444.98      66.154     67.188     66.667                                 \n",
      " 4    1448.20      68.421     60.938     64.463                                 \n",
      " 5    1388.45      67.692     68.750     68.217                                 \n",
      " 6    1309.81      65.574     62.500     64.000                                 \n",
      " 7    1318.09      68.852     65.625     67.200                                 \n",
      " 8    1223.92      66.667     65.625     66.142                                 \n",
      " 9    1219.50      68.254     67.188     67.717                                 \n",
      "10    1226.45      68.182     70.312     69.231                                 \n",
      "11    1153.58      72.581     70.312     71.429                                 \n",
      "12    1213.61      71.667     67.188     69.355                                 \n",
      "13    1173.91      69.492     64.062     66.667                                 \n",
      "14    1163.38      71.429     62.500     66.667                                 \n",
      "15    1121.68      69.492     64.062     66.667                                 \n",
      "16    1092.13      68.333     64.062     66.129                                 \n",
      "17    1037.37      69.492     64.062     66.667                                 \n",
      "18    1069.78      72.727     62.500     67.227                                 \n",
      "19    1053.63      74.074     62.500     67.797                                 \n",
      "20    1091.28      74.074     62.500     67.797                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.581   70.312    71.429\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.429\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model373.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1479.95      80.000     25.000     38.095                                 \n",
      " 2    1463.46      58.621     53.125     55.738                                 \n",
      " 3    1436.31      70.769     71.875     71.318                                 \n",
      " 4    1401.12      67.742     65.625     66.667                                 \n",
      " 5    1463.03      71.429     62.500     66.667                                 \n",
      " 6    1367.25      71.930     64.062     67.769                                 \n",
      " 7    1305.11      73.684     65.625     69.421                                 \n",
      " 8    1319.25      75.439     67.188     71.074                                 \n",
      " 9    1279.53      69.355     67.188     68.254                                 \n",
      "10    1179.43      68.254     67.188     67.717                                 \n",
      "11    1149.79      70.000     65.625     67.742                                 \n",
      "12    1195.89      71.930     64.062     67.769                                 \n",
      "13    1183.69      72.727     62.500     67.227                                 \n",
      "14    1125.26      72.727     62.500     67.227                                 \n",
      "15    1092.42      73.214     64.062     68.333                                 \n",
      "16    1110.40      75.000     65.625     70.000                                 \n",
      "17    1055.49      76.364     65.625     70.588                                 \n",
      "18    1082.35      74.545     64.062     68.908                                 \n",
      "19    1032.87      74.074     62.500     67.797                                 \n",
      "20    1095.61      74.545     64.062     68.908                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.769   71.875    71.318\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.318\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model386.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1481.04      77.273     26.562     39.535                                 \n",
      " 2    1443.40      56.604     46.875     51.282                                 \n",
      " 3    1417.97      73.214     64.062     68.333                                 \n",
      " 4    1352.21      69.355     67.188     68.254                                 \n",
      " 5    1402.85      66.667     62.500     64.516                                 \n",
      " 6    1313.22      78.571     68.750     73.333                                 \n",
      " 7    1345.62      77.193     68.750     72.727                                 \n",
      " 8    1217.45      76.364     65.625     70.588                                 \n",
      " 9    1176.15      76.786     67.188     71.667                                 \n",
      "10    1161.80      73.684     65.625     69.421                                 \n",
      "11    1109.51      70.492     67.188     68.800                                 \n",
      "12    1203.64      76.364     65.625     70.588                                 \n",
      "13    1168.50      72.881     67.188     69.919                                 \n",
      "14    1149.29      72.881     67.188     69.919                                 \n",
      "15    1099.32      71.186     65.625     68.293                                 \n",
      "16    1098.75      72.881     67.188     69.919                                 \n",
      "17    1038.38      72.881     67.188     69.919                                 \n",
      "18    1073.96      71.186     65.625     68.293                                 \n",
      "19    1058.22      71.186     65.625     68.293                                 \n",
      "20    1091.36      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.571   68.750    73.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_ALL_gpu/model399.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1472.05      57.778     40.625     47.706                                 \n",
      " 2    1449.91      58.000     45.312     50.877                                 \n",
      " 3    1394.46      72.340     53.125     61.261                                 \n",
      " 4    1452.94      67.273     57.812     62.185                                 \n",
      " 5    1429.51      71.186     65.625     68.293                                 \n",
      " 6    1354.91      76.364     65.625     70.588                                 \n",
      " 7    1337.65      74.576     68.750     71.545                                 \n",
      " 8    1283.85      73.333     68.750     70.968                                 \n",
      " 9    1201.50      72.131     68.750     70.400                                 \n",
      "10    1195.83      70.690     64.062     67.213                                 \n",
      "11    1139.20      71.930     64.062     67.769                                 \n",
      "12    1221.27      70.175     62.500     66.116                                 \n",
      "13    1194.65      71.930     64.062     67.769                                 \n",
      "14    1123.81      71.930     64.062     67.769                                 \n",
      "15    1102.07      74.545     64.062     68.908                                 \n",
      "16    1086.01      75.439     67.188     71.074                                 \n",
      "17    1045.85      75.000     65.625     70.000                                 \n",
      "18    1073.74      75.000     65.625     70.000                                 \n",
      "19    1055.08      75.439     67.188     71.074                                 \n",
      "20    1070.98      75.439     67.188     71.074                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.576   68.750    71.545\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.545\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# run training for a selected models, use every skip_models-th file\n",
    "skip_models = 13\n",
    "abs_models_dir = Path('models/tok2vec_abs_sci_ALL_gpu')\n",
    "\n",
    "models = sorted(os.listdir(abs_models_dir))\n",
    "\n",
    "for idx, model_file in enumerate(models):\n",
    "    if idx % skip_models == 0:\n",
    "        model_path = abs_models_dir / model_file\n",
    "        !prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg \\\n",
    "            --eval-split 0.2 --n-iter 20 --init-tok2vec $model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training final models with selected `tok2vec` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def train_ner_with_every_tok2vec(datasets, base_model=\"en_core_sci_lg\"):\n",
    "    tok2vec_dir = Path(\"models\")\n",
    "    tok2vecs = sorted(os.listdir(tok2vec_dir))\n",
    "    \n",
    "    for tok2vec_file in tok2vecs:\n",
    "        if \"_sci_\" not in tok2vec_file:\n",
    "            continue\n",
    "\n",
    "        tok2vec_path = tok2vec_dir / tok2vec_file\n",
    "        !prodigy train ner $datasets $base_model --eval-split 0.2 --n-iter 20 \\\n",
    "            --init-tok2vec $tok2vec_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1587.95      62.963     26.562     37.363                                 \n",
      " 2    1500.37      60.784     48.438     53.913                                 \n",
      " 3    1510.36      63.492     62.500     62.992                                 \n",
      " 4    1519.20      60.000     56.250     58.065                                 \n",
      " 5    1521.26      65.574     62.500     64.000                                 \n",
      " 6    1495.73      64.912     57.812     61.157                                 \n",
      " 7    1386.50      65.517     59.375     62.295                                 \n",
      " 8    1225.63      65.574     62.500     64.000                                 \n",
      " 9    1277.40      65.079     64.062     64.567                                 \n",
      "10    1258.71      62.903     60.938     61.905                                 \n",
      "11    1151.32      61.905     60.938     61.417                                 \n",
      "12    1249.35      63.793     57.812     60.656                                 \n",
      "13    1169.56      67.241     60.938     63.934                                 \n",
      "14    1163.40      65.517     59.375     62.295                                 \n",
      "15    1137.84      65.517     59.375     62.295                                 \n",
      "16    1137.22      67.241     60.938     63.934                                 \n",
      "17    1094.24      67.857     59.375     63.333                                 \n",
      "18    1079.29      63.793     57.812     60.656                                 \n",
      "19    1028.63      63.158     56.250     59.504                                 \n",
      "20    1096.86      63.158     56.250     59.504                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.079   64.062    64.567\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.567\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model238_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1575.28      47.368     28.125     35.294                                 \n",
      " 2    1473.45      68.000     53.125     59.649                                 \n",
      " 3    1414.79      73.214     64.062     68.333                                 \n",
      " 4    1463.85      72.727     62.500     67.227                                 \n",
      " 5    1384.56      76.364     65.625     70.588                                 \n",
      " 6    1343.33      82.692     67.188     74.138                                 \n",
      " 7    1333.10      80.000     68.750     73.950                                 \n",
      " 8    1285.83      77.966     71.875     74.797                                 \n",
      " 9    1231.73      74.545     64.062     68.908                                 \n",
      "10    1147.56      68.333     64.062     66.129                                 \n",
      "11    1133.60      71.667     67.188     69.355                                 \n",
      "12    1186.93      71.186     65.625     68.293                                 \n",
      "13    1163.38      68.852     65.625     67.200                                 \n",
      "14    1152.35      72.414     65.625     68.852                                 \n",
      "15    1096.20      69.492     64.062     66.667                                 \n",
      "16    1076.68      69.492     64.062     66.667                                 \n",
      "17    1034.84      71.429     62.500     66.667                                 \n",
      "18    1071.06      73.214     64.062     68.333                                 \n",
      "19    1066.33      73.214     64.062     68.333                                 \n",
      "20    1082.98      72.727     62.500     67.227                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.966   71.875    74.797\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.797\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2400_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1496.09      71.429     31.250     43.478                                 \n",
      " 2    1428.07      60.976     39.062     47.619                                 \n",
      " 3    1414.88      70.690     64.062     67.213                                 \n",
      " 4    1394.45      68.333     64.062     66.129                                 \n",
      " 5    1386.77      80.000     62.500     70.175                                 \n",
      " 6    1337.78      78.846     64.062     70.690                                 \n",
      " 7    1308.50      79.245     65.625     71.795                                 \n",
      " 8    1229.83      74.074     62.500     67.797                                 \n",
      " 9    1189.92      75.000     65.625     70.000                                 \n",
      "10    1199.78      76.923     62.500     68.966                                 \n",
      "11    1130.30      76.923     62.500     68.966                                 \n",
      "12    1245.61      75.000     60.938     67.241                                 \n",
      "13    1170.87      72.222     60.938     66.102                                 \n",
      "14    1132.59      70.370     59.375     64.407                                 \n",
      "15    1118.17      69.643     60.938     65.000                                 \n",
      "16    1075.07      72.222     60.938     66.102                                 \n",
      "17    1055.17      70.909     60.938     65.546                                 \n",
      "18    1065.72      67.273     57.812     62.185                                 \n",
      "19    1108.23      69.091     59.375     63.866                                 \n",
      "20    1081.93      68.519     57.812     62.712                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.245   65.625    71.795\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.795\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2401_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1581.14      64.516     31.250     42.105                                 \n",
      " 2    1486.14      60.976     39.062     47.619                                 \n",
      " 3    1464.08      67.925     56.250     61.538                                 \n",
      " 4    1497.64      65.306     50.000     56.637                                 \n",
      " 5    1430.13      64.151     53.125     58.120                                 \n",
      " 6    1414.06      72.000     56.250     63.158                                 \n",
      " 7    1455.04      74.510     59.375     66.087                                 \n",
      " 8    1262.20      75.472     62.500     68.376                                 \n",
      " 9    1305.18      78.431     62.500     69.565                                 \n",
      "10    1269.22      79.630     67.188     72.881                                 \n",
      "11    1109.86      78.846     64.062     70.690                                 \n",
      "12    1294.03      80.000     62.500     70.175                                 \n",
      "13    1189.09      80.392     64.062     71.304                                 \n",
      "14    1183.32      78.431     62.500     69.565                                 \n",
      "15    1149.91      78.431     62.500     69.565                                 \n",
      "16    1237.89      78.431     62.500     69.565                                 \n",
      "17    1107.08      78.846     64.062     70.690                                 \n",
      "18    1170.77      78.846     64.062     70.690                                 \n",
      "19    1085.09      78.846     64.062     70.690                                 \n",
      "20    1126.38      77.778     65.625     71.186                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.630   67.188    72.881\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.881\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2402_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1522.07      50.000     15.625     23.810                                 \n",
      " 2    1434.56      58.974     35.938     44.660                                 \n",
      " 3    1439.36      75.676     43.750     55.446                                 \n",
      " 4    1392.42      65.909     45.312     53.704                                 \n",
      " 5    1351.52      82.222     57.812     67.890                                 \n",
      " 6    1424.66      70.175     62.500     66.116                                 \n",
      " 7    1342.50      74.545     64.062     68.908                                 \n",
      " 8    1259.57      71.154     57.812     63.793                                 \n",
      " 9    1268.84      70.370     59.375     64.407                                 \n",
      "10    1224.35      68.519     57.812     62.712                                 \n",
      "11    1221.88      68.519     57.812     62.712                                 \n",
      "12    1244.84      72.222     60.938     66.102                                 \n",
      "13    1158.82      73.077     59.375     65.517                                 \n",
      "14    1163.86      79.592     60.938     69.027                                 \n",
      "15    1179.30      80.000     62.500     70.175                                 \n",
      "16    1113.85      80.000     62.500     70.175                                 \n",
      "17    1081.04      78.000     60.938     68.421                                 \n",
      "18    1115.72      78.000     60.938     68.421                                 \n",
      "19    1060.52      75.000     60.938     67.241                                 \n",
      "20    1116.15      75.000     60.938     67.241                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      80.000   62.500    70.175\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.175\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model304_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1527.20      64.706     34.375     44.898                                 \n",
      " 2    1514.31      52.381     51.562     51.969                                 \n",
      " 3    1487.56      67.797     62.500     65.041                                 \n",
      " 4    1420.83      70.175     62.500     66.116                                 \n",
      " 5    1392.88      71.186     65.625     68.293                                 \n",
      " 6    1343.58      77.193     68.750     72.727                                 \n",
      " 7    1345.95      76.271     70.312     73.171                                 \n",
      " 8    1223.03      79.310     71.875     75.410                                 \n",
      " 9    1255.10      75.439     67.188     71.074                                 \n",
      "10    1219.86      76.786     67.188     71.667                                 \n",
      "11    1165.85      76.786     67.188     71.667                                 \n",
      "12    1215.02      77.778     65.625     71.186                                 \n",
      "13    1185.63      76.786     67.188     71.667                                 \n",
      "14    1128.99      75.000     65.625     70.000                                 \n",
      "15    1108.05      70.690     64.062     67.213                                 \n",
      "16    1113.84      74.138     67.188     70.492                                 \n",
      "17    1042.53      73.684     65.625     69.421                                 \n",
      "18    1074.24      73.684     65.625     69.421                                 \n",
      "19    1035.15      74.576     68.750     71.545                                 \n",
      "20    1101.89      71.186     65.625     68.293                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.310   71.875    75.410\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.410\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.02      61.905     40.625     49.057                                 \n",
      " 2    1389.84      56.897     51.562     54.098                                 \n",
      " 3    1485.12      71.698     59.375     64.957                                 \n",
      " 4    1385.46      70.175     62.500     66.116                                 \n",
      " 5    1455.78      72.727     62.500     67.227                                 \n",
      " 6    1404.07      78.947     70.312     74.380                                 \n",
      " 7    1323.94      81.818     70.312     75.630                                 \n",
      " 8    1229.71      75.862     68.750     72.131                                 \n",
      " 9    1211.78      77.966     71.875     74.797                                 \n",
      "10    1249.24      76.786     67.188     71.667                                 \n",
      "11    1124.41      76.786     67.188     71.667                                 \n",
      "12    1227.59      75.926     64.062     69.492                                 \n",
      "13    1188.04      71.429     62.500     66.667                                 \n",
      "14    1126.55      77.358     64.062     70.085                                 \n",
      "15    1136.49      77.358     64.062     70.085                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    1146.76      78.431     62.500     69.565                                 \n",
      "17    1045.76      74.545     64.062     68.908                                 \n",
      "18    1047.72      74.545     64.062     68.908                                 \n",
      "19    1039.92      76.786     67.188     71.667                                 \n",
      "20    1076.51      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.818   70.312    75.630\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.630\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model336_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1507.62      57.895     34.375     43.137                                 \n",
      " 2    1465.82      57.627     53.125     55.285                                 \n",
      " 3    1433.29      62.121     64.062     63.077                                 \n",
      " 4    1496.11      68.519     57.812     62.712                                 \n",
      " 5    1393.36      67.308     54.688     60.345                                 \n",
      " 6    1369.23      69.231     56.250     62.069                                 \n",
      " 7    1297.14      72.131     68.750     70.400                                 \n",
      " 8    1253.85      71.429     70.312     70.866                                 \n",
      " 9    1177.67      74.074     62.500     67.797                                 \n",
      "10    1182.16      68.750     51.562     58.929                                 \n",
      "11    1184.30      70.213     51.562     59.459                                 \n",
      "12    1228.26      68.627     54.688     60.870                                 \n",
      "13    1179.65      75.439     67.188     71.074                                 \n",
      "14    1169.15      75.439     67.188     71.074                                 \n",
      "15    1083.01      75.000     65.625     70.000                                 \n",
      "16    1106.40      74.545     64.062     68.908                                 \n",
      "17    1082.69      72.222     60.938     66.102                                 \n",
      "18    1068.73      72.222     60.938     66.102                                 \n",
      "19    1050.78      72.222     60.938     66.102                                 \n",
      "20    1081.67      72.222     60.938     66.102                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.439   67.188    71.074\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.074\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model4_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1591.72      57.143     18.750     28.235                                 \n",
      " 2    1430.54      60.976     39.062     47.619                                 \n",
      " 3    1431.12      76.087     54.688     63.636                                 \n",
      " 4    1447.46      73.333     51.562     60.550                                 \n",
      " 5    1405.81      75.000     65.625     70.000                                 \n",
      " 6    1360.50      81.132     67.188     73.504                                 \n",
      " 7    1350.34      78.431     62.500     69.565                                 \n",
      " 8    1295.07      75.000     56.250     64.286                                 \n",
      " 9    1306.47      77.358     64.062     70.085                                 \n",
      "10    1206.40      73.684     65.625     69.421                                 \n",
      "11    1224.72      74.510     59.375     66.087                                 \n",
      "12    1314.89      73.077     59.375     65.517                                 \n",
      "13    1219.40      73.077     59.375     65.517                                 \n",
      "14    1193.32      71.698     59.375     64.957                                 \n",
      "15    1119.57      71.154     57.812     63.793                                 \n",
      "16    1117.24      70.588     56.250     62.609                                 \n",
      "17    1067.36      68.627     54.688     60.870                                 \n",
      "18    1087.17      68.627     54.688     60.870                                 \n",
      "19    1049.51      70.000     54.688     61.404                                 \n",
      "20    1108.60      67.925     56.250     61.538                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.132   67.188    73.504\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.504\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1578.16      64.000     25.000     35.955                                 \n",
      " 2    1439.61      55.319     40.625     46.847                                 \n",
      " 3    1528.20      72.222     60.938     66.102                                 \n",
      " 4    1429.18      71.154     57.812     63.793                                 \n",
      " 5    1414.46      69.388     53.125     60.177                                 \n",
      " 6    1344.69      75.472     62.500     68.376                                 \n",
      " 7    1472.62      70.909     60.938     65.546                                 \n",
      " 8    1296.39      74.545     64.062     68.908                                 \n",
      " 9    1285.11      68.966     62.500     65.574                                 \n",
      "10    1236.84      70.175     62.500     66.116                                 \n",
      "11    1181.13      71.429     62.500     66.667                                 \n",
      "12    1235.60      70.909     60.938     65.546                                 \n",
      "13    1238.99      76.923     62.500     68.966                                 \n",
      "14    1151.94      75.926     64.062     69.492                                 \n",
      "15    1151.25      75.926     64.062     69.492                                 \n",
      "16    1218.30      78.000     60.938     68.421                                 \n",
      "17    1074.01      75.926     64.062     69.492                                 \n",
      "18    1121.71      76.364     65.625     70.588                                 \n",
      "19    1084.27      77.358     64.062     70.085                                 \n",
      "20    1106.32      76.471     60.938     67.826                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1577.68      57.895     34.375     43.137                                 \n",
      " 2    1386.95      67.308     54.688     60.345                                 \n",
      " 3    1455.49      76.596     56.250     64.865                                 \n",
      " 4    1457.04      79.592     60.938     69.027                                 \n",
      " 5    1413.30      78.431     62.500     69.565                                 \n",
      " 6    1351.85      76.923     62.500     68.966                                 \n",
      " 7    1304.38      78.000     60.938     68.421                                 \n",
      " 8    1255.67      76.471     60.938     67.826                                 \n",
      " 9    1219.66      78.431     62.500     69.565                                 \n",
      "10    1203.83      74.545     64.062     68.908                                 \n",
      "11    1125.02      74.545     64.062     68.908                                 \n",
      "12    1224.65      74.074     62.500     67.797                                 \n",
      "13    1173.56      75.000     60.938     67.241                                 \n",
      "14    1170.88      75.000     60.938     67.241                                 \n",
      "15    1074.42      71.154     57.812     63.793                                 \n",
      "16    1144.97      75.000     60.938     67.241                                 \n",
      "17    1041.02      73.077     59.375     65.517                                 \n",
      "18    1094.32      74.510     59.375     66.087                                 \n",
      "19    1051.65      74.510     59.375     66.087                                 \n",
      "20    1099.61      78.000     60.938     68.421                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.431   62.500    69.565\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.565\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1570.28      62.500     23.438     34.091                                 \n",
      " 2    1397.40      59.091     40.625     48.148                                 \n",
      " 3    1485.47      70.833     53.125     60.714                                 \n",
      " 4    1445.56      68.293     43.750     53.333                                 \n",
      " 5    1431.31      64.000     50.000     56.140                                 \n",
      " 6    1339.87      70.833     53.125     60.714                                 \n",
      " 7    1387.07      72.340     53.125     61.261                                 \n",
      " 8    1232.74      76.596     56.250     64.865                                 \n",
      " 9    1207.39      72.340     53.125     61.261                                 \n",
      "10    1231.53      75.926     64.062     69.492                                 \n",
      "11    1154.22      74.545     64.062     68.908                                 \n",
      "12    1304.76      75.472     62.500     68.376                                 \n",
      "13    1155.21      69.811     57.812     63.248                                 \n",
      "14    1158.97      67.273     57.812     62.185                                 \n",
      "15    1092.88      69.811     57.812     63.248                                 \n",
      "16    1134.04      68.627     54.688     60.870                                 \n",
      "17    1055.42      66.667     56.250     61.017                                 \n",
      "18    1071.15      66.667     56.250     61.017                                 \n",
      "19    1060.90      69.231     56.250     62.069                                 \n",
      "20    1063.32      67.308     54.688     60.345                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.926   64.062    69.492\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.492\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2Kading 'en_core_sci_lg'...\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1630.03      55.556     23.438     32.967                                 \n",
      " 2    1442.41      55.556     46.875     50.847                                 \n",
      " 3    1429.19      65.957     48.438     55.856                                 \n",
      " 4    1467.20      65.455     56.250     60.504                                 \n",
      " 5    1467.20      69.643     60.938     65.000                                 \n",
      " 6    1376.49      67.241     60.938     63.934                                 \n",
      " 7    1324.06      73.585     60.938     66.667                                 \n",
      " 8    1261.74      75.472     62.500     68.376                                 \n",
      " 9    1229.62      77.358     64.062     70.085                                 \n",
      "10    1162.35      74.545     64.062     68.908                                 \n",
      "11    1129.31      72.727     62.500     67.227                                 \n",
      "12    1226.05      73.684     65.625     69.421                                 \n",
      "13    1154.44      73.684     65.625     69.421                                 \n",
      "14    1146.38      69.492     64.062     66.667                                 \n",
      "15    1157.15      70.175     62.500     66.116                                 \n",
      "16    1122.06      72.549     57.812     64.348                                 \n",
      "17    1069.36      70.909     60.938     65.546                                 \n",
      "18    1112.07      71.930     64.062     67.769                                 \n",
      "19    1040.95      70.370     59.375     64.407                                 \n",
      "20    1074.33      70.370     59.375     64.407                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   64.062    70.085\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.085\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ner_with_every_tok2vec(\"cord_19_rf_sentences,cord_19_rf_sentences_correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔥 Top model so far: `75.630` 🔥\n",
    "- trained with `tok2vec_abs_sci_model308_gpu.bin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1518.02      61.905     40.625     49.057                                 \n",
      " 2    1389.84      56.897     51.562     54.098                                 \n",
      " 3    1485.12      71.698     59.375     64.957                                 \n",
      " 4    1385.46      70.175     62.500     66.116                                 \n",
      " 5    1455.78      72.727     62.500     67.227                                 \n",
      " 6    1404.07      78.947     70.312     74.380                                 \n",
      " 7    1323.94      81.818     70.312     75.630                                 \n",
      " 8    1229.71      75.862     68.750     72.131                                 \n",
      " 9    1211.78      77.966     71.875     74.797                                 \n",
      "10    1249.24      76.786     67.188     71.667                                 \n",
      "11    1124.41      76.786     67.188     71.667                                 \n",
      "12    1227.59      75.926     64.062     69.492                                 \n",
      "13    1188.04      71.429     62.500     66.667                                 \n",
      "14    1126.55      77.358     64.062     70.085                                 \n",
      "15    1136.49      77.358     64.062     70.085                                 \n",
      "16    1146.76      78.431     62.500     69.565                                 \n",
      "17    1045.76      74.545     64.062     68.908                                 \n",
      "18    1047.72      74.545     64.062     68.908                                 \n",
      "19    1039.92      76.786     67.188     71.667                                 \n",
      "20    1076.51      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      81.818   70.312    75.630\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m75.630\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_10_en_ner_rf_sm\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!prodigy train ner cord_19_rf_sentences,cord_19_rf_sentences_correct en_core_sci_lg \\\n",
    "#    --eval-split 0.2 --n-iter 20 --init-tok2vec models/tok2vec_abs_sci_model308_gpu.bin \\\n",
    "#    --output models/2020_04_10_en_ner_rf_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.13 (Mon)\n",
    "## Label more data by correcting the model's predictions (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_rf_sentences_correct_2 to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.correct cord_19_rf_sentences_correct_2 models/2020_04_10_en_ner_rf_sm data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR --exclude cord_19_rf_sentences,cord_19_rf_sentences_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train final models, with 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2885.30      59.302     42.149     49.275                                 \n",
      " 2    2552.55      62.353     43.802     51.456                                 \n",
      " 3    2728.96      65.385     56.198     60.444                                 \n",
      " 4    2487.82      72.917     57.851     64.516                                 \n",
      " 5    2373.22      72.642     63.636     67.841                                 \n",
      " 6    2348.38      74.074     66.116     69.869                                 \n",
      " 7    2218.46      73.832     65.289     69.298                                 \n",
      " 8    2170.65      73.148     65.289     68.996                                 \n",
      " 9    2100.42      72.816     61.983     66.964                                 \n",
      "10    2139.80      75.490     63.636     69.058                                 \n",
      "11    2019.70      78.000     64.463     70.588                                 \n",
      "12    2038.26      78.218     65.289     71.171                                 \n",
      "13    1985.03      77.000     63.636     69.683                                 \n",
      "14    1951.26      75.758     61.983     68.182                                 \n",
      "15    1914.76      75.758     61.983     68.182                                 \n",
      "16    1872.98      75.248     62.810     68.468                                 \n",
      "17    1767.53      73.333     63.636     68.142                                 \n",
      "18    1821.03      73.786     62.810     67.857                                 \n",
      "19    1756.45      73.077     62.810     67.556                                 \n",
      "20    1812.57      70.370     62.810     66.376                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.218   65.289    71.171\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.171\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model238_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2852.29      68.132     51.240     58.491                                 \n",
      " 2    2621.84      77.273     56.198     65.072                                 \n",
      " 3    2599.70      75.728     64.463     69.643                                 \n",
      " 4    2422.69      73.394     66.116     69.565                                 \n",
      " 5    2291.69      71.560     64.463     67.826                                 \n",
      " 6    2259.82      77.358     67.769     72.247                                 \n",
      " 7    2173.01      75.701     66.942     71.053                                 \n",
      " 8    2135.90      76.699     65.289     70.536                                 \n",
      " 9    2131.74      72.727     66.116     69.264                                 \n",
      "10    2091.84      75.962     65.289     70.222                                 \n",
      "11    1972.21      75.962     65.289     70.222                                 \n",
      "12    1959.91      72.566     67.769     70.085                                 \n",
      "13    1979.00      72.321     66.942     69.528                                 \n",
      "14    1891.45      71.930     67.769     69.787                                 \n",
      "15    1917.09      71.681     66.942     69.231                                 \n",
      "16    1820.28      70.940     68.595     69.748                                 \n",
      "17    1774.21      68.376     66.116     67.227                                 \n",
      "18    1812.61      70.175     66.116     68.085                                 \n",
      "19    1759.71      70.175     66.116     68.085                                 \n",
      "20    1816.47      71.304     67.769     69.492                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.358   67.769    72.247\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.247\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2400_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2774.03      70.526     55.372     62.037                                 \n",
      " 2    2567.17      71.875     57.025     63.594                                 \n",
      " 3    2650.63      74.747     61.157     67.273                                 \n",
      " 4    2435.64      77.083     61.157     68.203                                 \n",
      " 5    2322.78      73.786     62.810     67.857                                 \n",
      " 6    2208.39      74.757     63.636     68.750                                 \n",
      " 7    2189.09      76.190     66.116     70.796                                 \n",
      " 8    2061.45      76.415     66.942     71.366                                 \n",
      " 9    2090.43      77.143     66.942     71.681                                 \n",
      "10    2046.25      78.704     70.248     74.236                                 \n",
      "11    2019.68      78.182     71.074     74.459                                 \n",
      "12    2026.61      78.899     71.074     74.783                                 \n",
      "13    1994.80      77.982     70.248     73.913                                 \n",
      "14    1976.07      75.455     68.595     71.861                                 \n",
      "15    1896.82      75.701     66.942     71.053                                 \n",
      "16    1812.48      75.000     66.942     70.742                                 \n",
      "17    1792.77      74.545     67.769     70.996                                 \n",
      "18    1818.84      74.775     68.595     71.552                                 \n",
      "19    1803.06      74.775     68.595     71.552                                 \n",
      "20    1835.78      74.107     68.595     71.245                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.899   71.074    74.783\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.783\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2401_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2802.33      63.953     45.455     53.140                                 \n",
      " 2    2777.16      68.085     52.893     59.535                                 \n",
      " 3    2653.47      69.231     59.504     64.000                                 \n",
      " 4    2473.14      70.874     60.331     65.179                                 \n",
      " 5    2394.22      69.000     57.025     62.443                                 \n",
      " 6    2297.21      69.000     57.025     62.443                                 \n",
      " 7    2192.55      68.269     58.678     63.111                                 \n",
      " 8    2293.42      71.845     61.157     66.071                                 \n",
      " 9    2159.01      70.476     61.157     65.487                                 \n",
      "10    2081.32      69.159     61.157     64.912                                 \n",
      "11    1994.01      68.519     61.157     64.629                                 \n",
      "12    1970.23      69.444     61.983     65.502                                 \n",
      "13    1967.99      68.468     62.810     65.517                                 \n",
      "14    1945.46      68.468     62.810     65.517                                 \n",
      "15    1900.57      66.372     61.983     64.103                                 \n",
      "16    1847.67      67.257     62.810     64.957                                 \n",
      "17    1794.01      67.857     62.810     65.236                                 \n",
      "18    1803.22      67.544     63.636     65.532                                 \n",
      "19    1777.86      66.957     63.636     65.254                                 \n",
      "20    1799.34      67.241     64.463     65.823                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.845   61.157    66.071\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.071\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2402_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2921.45      61.333     38.017     46.939                                 \n",
      " 2    2647.32      71.739     54.545     61.972                                 \n",
      " 3    2676.39      71.429     57.851     63.927                                 \n",
      " 4    2600.52      72.115     61.983     66.667                                 \n",
      " 5    2471.81      71.287     59.504     64.865                                 \n",
      " 6    2273.85      72.000     59.504     65.158                                 \n",
      " 7    2217.76      75.258     60.331     66.972                                 \n",
      " 8    2197.69      75.248     62.810     68.468                                 \n",
      " 9    2168.50      73.786     62.810     67.857                                 \n",
      "10    2191.43      72.115     61.983     66.667                                 \n",
      "11    2033.08      73.077     62.810     67.556                                 \n",
      "12    2038.16      71.569     60.331     65.471                                 \n",
      "13    2071.37      71.154     61.157     65.778                                 \n",
      "14    1923.85      72.381     62.810     67.257                                 \n",
      "15    1926.64      72.381     62.810     67.257                                 \n",
      "16    1896.23      71.296     63.636     67.249                                 \n",
      "17    1822.68      71.560     64.463     67.826                                 \n",
      "18    1822.97      71.560     64.463     67.826                                 \n",
      "19    1785.60      70.642     63.636     66.957                                 \n",
      "20    1815.14      70.370     62.810     66.376                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.248   62.810    68.468\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.468\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model304_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2756.33      69.072     55.372     61.468                                 \n",
      " 2    2670.17      73.786     62.810     67.857                                 \n",
      " 3    2680.49      70.370     62.810     66.376                                 \n",
      " 4    2416.43      72.174     68.595     70.339                                 \n",
      " 5    2327.03      72.807     68.595     70.638                                 \n",
      " 6    2261.51      74.545     67.769     70.996                                 \n",
      " 7    2156.66      73.684     69.421     71.489                                 \n",
      " 8    2157.50      74.775     68.595     71.552                                 \n",
      " 9    2056.64      74.336     69.421     71.795                                 \n",
      "10    2024.02      68.908     67.769     68.333                                 \n",
      "11    2000.89      71.930     67.769     69.787                                 \n",
      "12    1957.37      74.336     69.421     71.795                                 \n",
      "13    1921.06      74.336     69.421     71.795                                 \n",
      "14    1908.85      74.561     70.248     72.340                                 \n",
      "15    1898.20      74.545     67.769     70.996                                 \n",
      "16    1844.39      75.000     69.421     72.103                                 \n",
      "17    1803.71      75.455     68.595     71.861                                 \n",
      "18    1841.31      73.636     66.942     70.130                                 \n",
      "19    1749.20      74.074     66.116     69.869                                 \n",
      "20    1808.81      74.074     66.116     69.869                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.561   70.248    72.340\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.340\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2811.45      69.231     52.066     59.434                                 \n",
      " 2    2606.03      67.961     57.851     62.500                                 \n",
      " 3    2571.19      73.529     61.983     67.265                                 \n",
      " 4    2442.88      75.238     65.289     69.912                                 \n",
      " 5    2329.50      70.690     67.769     69.198                                 \n",
      " 6    2213.83      77.273     70.248     73.593                                 \n",
      " 7    2127.51      75.926     67.769     71.616                                 \n",
      " 8    2099.61      76.190     66.116     70.796                                 \n",
      " 9    2050.85      73.394     66.116     69.565                                 \n",
      "10    2017.65      73.874     67.769     70.690                                 \n",
      "11    1979.75      75.000     69.421     72.103                                 \n",
      "12    1960.84      75.893     70.248     72.961                                 \n",
      "13    1909.56      74.783     71.074     72.881                                 \n",
      "14    1891.09      75.862     72.727     74.262                                 \n",
      "15    1921.11      77.193     72.727     74.894                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    1818.28      75.652     71.901     73.729                                 \n",
      "17    1795.52      75.000     71.901     73.418                                 \n",
      "18    1827.94      74.561     70.248     72.340                                 \n",
      "19    1761.02      74.783     71.074     72.881                                 \n",
      "20    1806.65      73.504     71.074     72.269                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.193   72.727    74.894\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.894\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model336_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2809.39      67.033     50.413     57.547                                 \n",
      " 2    2607.82      69.000     57.025     62.443                                 \n",
      " 3    2679.98      73.148     65.289     68.996                                 \n",
      " 4    2373.86      71.053     66.942     68.936                                 \n",
      " 5    2317.09      71.304     67.769     69.492                                 \n",
      " 6    2186.74      73.874     67.769     70.690                                 \n",
      " 7    2132.76      73.394     66.116     69.565                                 \n",
      " 8    2098.73      72.973     66.942     69.828                                 \n",
      " 9    2044.13      74.545     67.769     70.996                                 \n",
      "10    2076.54      73.394     66.116     69.565                                 \n",
      "11    1928.78      70.536     65.289     67.811                                 \n",
      "12    1991.64      71.171     65.289     68.103                                 \n",
      "13    2001.98      70.536     65.289     67.811                                 \n",
      "14    1924.28      71.053     66.942     68.936                                 \n",
      "15    1884.74      71.053     66.942     68.936                                 \n",
      "16    1849.36      70.175     66.116     68.085                                 \n",
      "17    1784.86      69.565     66.116     67.797                                 \n",
      "18    1820.70      70.175     66.116     68.085                                 \n",
      "19    1753.51      70.796     66.116     68.376                                 \n",
      "20    1781.21      71.429     66.116     68.670                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   67.769    70.996\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.996\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model4_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2905.73      60.274     36.364     45.361                                 \n",
      " 2    2643.78      65.909     47.934     55.502                                 \n",
      " 3    2720.29      71.277     55.372     62.326                                 \n",
      " 4    2493.67      71.845     61.157     66.071                                 \n",
      " 5    2410.86      69.027     64.463     66.667                                 \n",
      " 6    2276.30      74.074     66.116     69.869                                 \n",
      " 7    2279.60      70.642     63.636     66.957                                 \n",
      " 8    2212.41      69.444     61.983     65.502                                 \n",
      " 9    2144.86      70.000     63.636     66.667                                 \n",
      "10    2110.11      70.000     63.636     66.667                                 \n",
      "11    2078.27      71.560     64.463     67.826                                 \n",
      "12    2030.53      70.270     64.463     67.241                                 \n",
      "13    2010.53      69.912     65.289     67.521                                 \n",
      "14    1974.33      69.912     65.289     67.521                                 \n",
      "15    1948.63      72.072     66.116     68.966                                 \n",
      "16    1864.64      73.148     65.289     68.996                                 \n",
      "17    1796.42      70.909     64.463     67.532                                 \n",
      "18    1834.32      68.182     61.983     64.935                                 \n",
      "19    1836.69      68.224     60.331     64.035                                 \n",
      "20    1837.54      68.868     60.331     64.317                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.074   66.116    69.869\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.869\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2913.83      64.865     39.669     49.231                                 \n",
      " 2    2781.90      61.321     53.719     57.269                                 \n",
      " 3    2695.09      64.486     57.025     60.526                                 \n",
      " 4    2555.06      67.619     58.678     62.832                                 \n",
      " 5    2456.87      73.529     61.983     67.265                                 \n",
      " 6    2215.30      78.125     61.983     69.124                                 \n",
      " 7    2202.15      73.786     62.810     67.857                                 \n",
      " 8    2135.29      72.897     64.463     68.421                                 \n",
      " 9    2100.14      74.766     66.116     70.175                                 \n",
      "10    2150.92      72.222     64.463     68.122                                 \n",
      "11    2019.84      74.766     66.116     70.175                                 \n",
      "12    2048.45      74.074     66.116     69.869                                 \n",
      "13    1996.72      74.312     66.942     70.435                                 \n",
      "14    1982.48      74.545     67.769     70.996                                 \n",
      "15    1960.40      71.930     67.769     69.787                                 \n",
      "16    1852.92      73.636     66.942     70.130                                 \n",
      "17    1841.95      74.545     67.769     70.996                                 \n",
      "18    1843.39      72.973     66.942     69.828                                 \n",
      "19    1796.31      72.973     66.942     69.828                                 \n",
      "20    1799.40      72.321     66.942     69.528                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.545   67.769    70.996\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.996\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2835.29      68.116     38.843     49.474                                 \n",
      " 2    2732.17      72.500     47.934     57.711                                 \n",
      " 3    2570.86      78.000     64.463     70.588                                 \n",
      " 4    2535.81      72.381     62.810     67.257                                 \n",
      " 5    2355.29      78.641     66.942     72.321                                 \n",
      " 6    2273.33      73.333     63.636     68.142                                 \n",
      " 7    2248.22      75.472     66.116     70.485                                 \n",
      " 8    2121.12      72.477     65.289     68.696                                 \n",
      " 9    2055.64      72.642     63.636     67.841                                 \n",
      "10    2045.31      69.159     61.157     64.912                                 \n",
      "11    1988.56      67.290     59.504     63.158                                 \n",
      "12    1970.19      66.981     58.678     62.555                                 \n",
      "13    1984.19      67.593     60.331     63.755                                 \n",
      "14    1921.90      68.868     60.331     64.317                                 \n",
      "15    1942.97      68.932     58.678     63.393                                 \n",
      "16    1833.59      68.627     57.851     62.780                                 \n",
      "17    1801.38      66.981     58.678     62.555                                 \n",
      "18    1821.15      68.571     59.504     63.717                                 \n",
      "19    1774.22      68.269     58.678     63.111                                 \n",
      "20    1800.21      67.890     61.157     64.348                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.641   66.942    72.321\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.321\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2806.94      69.512     47.107     56.158                                 \n",
      " 2    2534.86      65.591     50.413     57.009                                 \n",
      " 3    2651.01      62.037     55.372     58.515                                 \n",
      " 4    2407.22      73.214     67.769     70.386                                 \n",
      " 5    2364.25      77.570     68.595     72.807                                 \n",
      " 6    2290.54      75.000     66.942     70.742                                 \n",
      " 7    2250.24      74.257     61.983     67.568                                 \n",
      " 8    2157.26      73.786     62.810     67.857                                 \n",
      " 9    2040.44      76.238     63.636     69.369                                 \n",
      "10    2114.07      74.510     62.810     68.161                                 \n",
      "11    2010.97      73.585     64.463     68.722                                 \n",
      "12    2027.09      73.832     65.289     69.298                                 \n",
      "13    2005.38      75.472     66.116     70.485                                 \n",
      "14    1950.82      74.312     66.942     70.435                                 \n",
      "15    1921.53      72.642     63.636     67.841                                 \n",
      "16    1862.77      74.286     64.463     69.027                                 \n",
      "17    1809.07      71.429     61.983     66.372                                 \n",
      "18    1815.98      70.755     61.983     66.079                                 \n",
      "19    1778.76      70.093     61.983     65.789                                 \n",
      "20    1821.81      70.755     61.983     66.079                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.570   68.595    72.807\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.807\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2778.89      65.385     42.149     51.256                                 \n",
      " 2    2658.80      64.706     54.545     59.193                                 \n",
      " 3    2603.19      70.192     60.331     64.889                                 \n",
      " 4    2483.60      68.367     55.372     61.187                                 \n",
      " 5    2393.74      73.267     61.157     66.667                                 \n",
      " 6    2299.20      70.093     61.983     65.789                                 \n",
      " 7    2252.09      70.370     62.810     66.376                                 \n",
      " 8    2151.54      70.093     61.983     65.789                                 \n",
      " 9    2125.46      69.091     62.810     65.801                                 \n",
      "10    2117.79      71.296     63.636     67.249                                 \n",
      "11    2026.21      71.296     63.636     67.249                                 \n",
      "12    2005.44      71.296     63.636     67.249                                 \n",
      "13    1990.53      70.755     61.983     66.079                                 \n",
      "14    1939.05      70.755     61.983     66.079                                 \n",
      "15    1946.72      71.429     61.983     66.372                                 \n",
      "16    1863.74      69.524     60.331     64.602                                 \n",
      "17    1847.71      70.192     60.331     64.889                                 \n",
      "18    1847.33      70.192     60.331     64.889                                 \n",
      "19    1799.33      69.231     59.504     64.000                                 \n",
      "20    1842.89      68.571     59.504     63.717                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.296   63.636    67.249\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.249\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ner_with_every_tok2vec(\"cord_19_rf_sentences,cord_19_rf_sentences_correct,cord_19_rf_sentences_correct_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔥 More annotations lowered the performance; top model: `74.894` 🔥\n",
    "- trained with `tok2vec_abs_sci_model308_gpu.bin`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if `sci` is still the best choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_0_1_2 = \"cord_19_rf_sentences,cord_19_rf_sentences_correct,cord_19_rf_sentences_correct_2\"\n",
    "model_0_1_2 = \"models/2020_04_13_en_ner_rf_sm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_vectors_web_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1517.43      63.793     30.579     41.341                                 \n",
      " 2    1373.26      68.750     45.455     54.726                                 \n",
      " 3     997.71      69.048     47.934     56.585                                 \n",
      " 4     903.18      71.910     52.893     60.952                                 \n",
      " 5     663.74      75.269     57.851     65.421                                 \n",
      " 6     690.64      74.118     52.066     61.165                                 \n",
      " 7     499.83      75.862     54.545     63.462                                 \n",
      " 8     439.64      73.118     56.198     63.551                                 \n",
      " 9     385.50      72.043     55.372     62.617                                 \n",
      "10     331.79      71.134     57.025     63.303                                 \n",
      "11     322.72      68.317     57.025     62.162                                 \n",
      "12     266.74      68.041     54.545     60.550                                 \n",
      "13     265.05      68.478     52.066     59.155                                 \n",
      "14     179.49      68.750     54.545     60.829                                 \n",
      "15     140.89      67.708     53.719     59.908                                 \n",
      "16      99.59      68.317     57.025     62.162                                 \n",
      "17      99.56      66.990     57.025     61.607                                 \n",
      "18      95.81      67.647     57.025     61.883                                 \n",
      "19      97.89      67.925     59.504     63.436                                 \n",
      "20      84.40      68.224     60.331     64.035                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.269   57.851    65.421\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m65.421\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_web_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    6547.33       0.000      0.000      0.000                                 \n",
      " 2    6085.27      68.421     10.744     18.571                                 \n",
      " 3    6064.60      58.333     23.140     33.136                                 \n",
      " 4    5980.70      60.714     28.099     38.418                                 \n",
      " 5    5669.33      68.421     32.231     43.820                                 \n",
      " 6    5882.47      61.250     40.496     48.756                                 \n",
      " 7    5727.24      61.176     42.975     50.485                                 \n",
      " 8    5862.17      63.415     42.975     51.232                                 \n",
      " 9    6044.19      63.736     47.934     54.717                                 \n",
      "10    6021.27      62.887     50.413     55.963                                 \n",
      "11    5369.35      62.626     51.240     56.364                                 \n",
      "12    5961.72      64.948     52.066     57.798                                 \n",
      "13    5571.60      67.742     52.066     58.879                                 \n",
      "14    5504.25      64.706     54.545     59.193                                 \n",
      "15    5967.89      66.019     56.198     60.714                                 \n",
      "16    5967.39      65.094     57.025     60.793                                 \n",
      "17    5906.09      66.990     57.025     61.607                                 \n",
      "18    5842.47      68.000     56.198     61.538                                 \n",
      "19    5376.07      67.647     57.025     61.883                                 \n",
      "20    5383.20      70.707     57.851     63.636                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.707   57.851    63.636\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m63.636\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2766.89      61.538     39.669     48.241                                 \n",
      " 2    2602.01      68.000     56.198     61.538                                 \n",
      " 3    2585.69      70.755     61.983     66.079                                 \n",
      " 4    2528.46      71.277     55.372     62.326                                 \n",
      " 5    2351.15      72.632     57.025     63.889                                 \n",
      " 6    2298.79      74.194     57.025     64.486                                 \n",
      " 7    2166.41      72.449     58.678     64.840                                 \n",
      " 8    2066.61      70.297     58.678     63.964                                 \n",
      " 9    2086.47      66.990     57.025     61.607                                 \n",
      "10    2096.89      67.308     57.851     62.222                                 \n",
      "11    1970.11      70.588     59.504     64.574                                 \n",
      "12    2011.52      69.903     59.504     64.286                                 \n",
      "13    1996.80      73.077     62.810     67.556                                 \n",
      "14    1930.77      73.077     62.810     67.556                                 \n",
      "15    1887.29      73.529     61.983     67.265                                 \n",
      "16    1869.41      75.000     61.983     67.873                                 \n",
      "17    1801.91      75.248     62.810     68.468                                 \n",
      "18    1836.60      74.510     62.810     68.161                                 \n",
      "19    1778.07      73.529     61.983     67.265                                 \n",
      "20    1823.88      73.529     61.983     67.265                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.248   62.810    68.468\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.468\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for base_model in ['en_vectors_web_lg', 'en_core_web_lg', 'en_core_sci_lg']:\n",
    "    !prodigy train ner $datasets_0_1_2 $base_model --eval-split 0.2 --n-iter 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`en_core_sci_lg` is still the best base model, although the margins are getting smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2811.45      69.231     52.066     59.434                                 \n",
      " 2    2606.03      67.961     57.851     62.500                                 \n",
      " 3    2571.19      73.529     61.983     67.265                                 \n",
      " 4    2442.88      75.238     65.289     69.912                                 \n",
      " 5    2329.50      70.690     67.769     69.198                                 \n",
      " 6    2213.83      77.273     70.248     73.593                                 \n",
      " 7    2127.51      75.926     67.769     71.616                                 \n",
      " 8    2099.61      76.190     66.116     70.796                                 \n",
      " 9    2050.85      73.394     66.116     69.565                                 \n",
      "10    2017.65      73.874     67.769     70.690                                 \n",
      "11    1979.75      75.000     69.421     72.103                                 \n",
      "12    1960.84      75.893     70.248     72.961                                 \n",
      "13    1909.56      74.783     71.074     72.881                                 \n",
      "14    1891.09      75.862     72.727     74.262                                 \n",
      "15    1921.11      77.193     72.727     74.894                                 \n",
      "16    1818.28      75.652     71.901     73.729                                 \n",
      "17    1795.52      75.000     71.901     73.418                                 \n",
      "18    1827.94      74.561     70.248     72.340                                 \n",
      "19    1761.02      74.783     71.074     72.881                                 \n",
      "20    1806.65      73.504     71.074     72.269                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.193   72.727    74.894\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.894\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[38;5;2m✔ Saved model:\n",
      "/home/users/grzenkom/git/GitHub-chopeen/CORD-19/models/2020_04_13_en_ner_rf_sm\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy train ner $datasets_0_1_2 en_core_sci_lg \\\n",
    "    --output $model_0_1_2 \\\n",
    "    --init-tok2vec models/tok2vec_abs_sci_model308_gpu.bin \\\n",
    "    --eval-split 0.2 --n-iter 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label more data by correcting the model's predictions (part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 label(s): RISK_FACTOR\n",
      "Added dataset cord_19_rf_sentences_correct_3 to database SQLite.\n",
      "\n",
      "✨  Starting the web server at http://localhost:8080 ...\n",
      "Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 79 annotations to database SQLite\u001b[0m\n",
      "Dataset: cord_19_rf_sentences_correct_3\n",
      "Session ID: 2020-04-13_23-22-28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.correct cord_19_rf_sentences_correct_3 $model_0_1_2 data/raw/cord_19_rf_sentences.jsonl \\\n",
    "    --label RISK_FACTOR --exclude $datasets_0_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train final models, with 4 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_0_1_2_3 = \"cord_19_rf_sentences,cord_19_rf_sentences_correct,cord_19_rf_sentences_correct_2,\" \\\n",
    "    \"cord_19_rf_sentences_correct_3\"\n",
    "model_0_1_2_3 = \"models/2020_04_14_en_ner_rf_sm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3381.36      59.854     51.899     55.593                                 \n",
      " 2    3083.86      62.420     62.025     62.222                                 \n",
      " 3    2890.69      61.585     63.924     62.733                                 \n",
      " 4    2752.00      60.209     72.785     65.903                                 \n",
      " 5    2699.75      61.850     67.722     64.653                                 \n",
      " 6    2627.96      62.428     68.354     65.257                                 \n",
      " 7    2529.31      62.805     65.190     63.975                                 \n",
      " 8    2484.78      65.244     67.722     66.460                                 \n",
      " 9    2417.60      64.535     70.253     67.273                                 \n",
      "10    2326.47      62.644     68.987     65.663                                 \n",
      "11    2382.41      63.529     68.354     65.854                                 \n",
      "12    2328.39      64.706     69.620     67.073                                 \n",
      "13    2250.18      62.712     70.253     66.269                                 \n",
      "14    2166.57      61.878     70.886     66.077                                 \n",
      "15    2216.66      62.431     71.519     66.667                                 \n",
      "16    2215.12      61.081     71.519     65.889                                 \n",
      "17    2195.58      60.326     70.253     64.912                                 \n",
      "18    2204.19      62.570     70.886     66.469                                 \n",
      "19    2062.14      62.570     70.886     66.469                                 \n",
      "20    2136.29      62.712     70.253     66.269                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      64.535   70.253    67.273\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.273\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model238_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3167.64      60.000     55.063     57.426                                 \n",
      " 2    3114.11      66.897     61.392     64.026                                 \n",
      " 3    2847.31      66.250     67.089     66.667                                 \n",
      " 4    2780.27      63.030     65.823     64.396                                 \n",
      " 5    2640.91      64.881     68.987     66.871                                 \n",
      " 6    2633.10      62.130     66.456     64.220                                 \n",
      " 7    2427.68      62.651     65.823     64.198                                 \n",
      " 8    2366.50      62.874     66.456     64.615                                 \n",
      " 9    2221.28      62.286     68.987     65.465                                 \n",
      "10    2343.81      62.069     68.354     65.060                                 \n",
      "11    2272.93      63.372     68.987     66.061                                 \n",
      "12    2302.86      61.988     67.089     64.438                                 \n",
      "13    2184.16      61.765     66.456     64.024                                 \n",
      "14    2182.51      64.198     65.823     65.000                                 \n",
      "15    2237.49      64.848     67.722     66.254                                 \n",
      "16    2202.57      63.690     67.722     65.644                                 \n",
      "17    2171.06      64.881     68.987     66.871                                 \n",
      "18    2179.72      64.671     68.354     66.462                                 \n",
      "19    2056.87      65.854     68.354     67.081                                 \n",
      "20    2103.63      64.242     67.089     65.635                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.854   68.354    67.081\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.081\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2400_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3147.17      70.588     53.165     60.650                                 \n",
      " 2    3141.90      65.772     62.025     63.844                                 \n",
      " 3    2752.55      64.242     67.089     65.635                                 \n",
      " 4    2657.05      65.244     67.722     66.460                                 \n",
      " 5    2656.56      63.483     71.519     67.262                                 \n",
      " 6    2644.58      65.089     69.620     67.278                                 \n",
      " 7    2505.39      63.095     67.089     65.031                                 \n",
      " 8    2385.09      62.644     68.987     65.663                                 \n",
      " 9    2319.00      63.529     68.354     65.854                                 \n",
      "10    2406.17      62.941     67.722     65.244                                 \n",
      "11    2230.22      63.006     68.987     65.861                                 \n",
      "12    2269.27      62.209     67.722     64.848                                 \n",
      "13    2213.18      61.047     66.456     63.636                                 \n",
      "14    2156.81      61.404     66.456     63.830                                 \n",
      "15    2224.78      61.272     67.089     64.048                                 \n",
      "16    2174.67      61.143     67.722     64.264                                 \n",
      "17    2145.39      62.069     68.354     65.060                                 \n",
      "18    2156.68      61.932     68.987     65.269                                 \n",
      "19    2066.53      61.582     68.987     65.075                                 \n",
      "20    2116.27      62.644     68.987     65.663                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.089   69.620    67.278\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.278\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2401_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3272.69      65.347     41.772     50.965                                 \n",
      " 2    3212.73      55.556     53.797     54.662                                 \n",
      " 3    2913.31      60.625     61.392     61.006                                 \n",
      " 4    2705.93      56.497     63.291     59.701                                 \n",
      " 5    2729.06      59.649     64.557     62.006                                 \n",
      " 6    2752.73      60.366     62.658     61.491                                 \n",
      " 7    2524.16      62.048     65.190     63.580                                 \n",
      " 8    2514.53      60.494     62.025     61.250                                 \n",
      " 9    2379.19      61.212     63.924     62.539                                 \n",
      "10    2417.57      60.479     63.924     62.154                                 \n",
      "11    2328.35      61.111     62.658     61.875                                 \n",
      "12    2329.63      62.733     63.924     63.323                                 \n",
      "13    2270.79      63.975     65.190     64.577                                 \n",
      "14    2176.77      62.346     63.924     63.125                                 \n",
      "15    2214.43      64.557     64.557     64.557                                 \n",
      "16    2283.58      63.694     63.291     63.492                                 \n",
      "17    2206.73      62.264     62.658     62.461                                 \n",
      "18    2169.01      63.462     62.658     63.057                                 \n",
      "19    2109.11      62.048     65.190     63.580                                 \n",
      "20    2180.90      62.805     65.190     63.975                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      63.975   65.190    64.577\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.577\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2402_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3274.19      60.000     53.165     56.376                                 \n",
      " 2    3157.45      60.494     62.025     61.250                                 \n",
      " 3    2833.29      58.242     67.089     62.353                                 \n",
      " 4    2751.77      56.452     66.456     61.047                                 \n",
      " 5    2711.08      58.046     63.924     60.843                                 \n",
      " 6    2706.27      60.606     63.291     61.920                                 \n",
      " 7    2554.47      58.929     62.658     60.736                                 \n",
      " 8    2497.23      61.963     63.924     62.928                                 \n",
      " 9    2343.18      61.491     62.658     62.069                                 \n",
      "10    2374.94      63.314     67.722     65.443                                 \n",
      "11    2294.36      64.024     66.456     65.217                                 \n",
      "12    2382.03      63.314     67.722     65.443                                 \n",
      "13    2310.09      62.651     65.823     64.198                                 \n",
      "14    2205.89      62.275     65.823     64.000                                 \n",
      "15    2253.76      62.275     65.823     64.000                                 \n",
      "16    2275.61      61.538     65.823     63.609                                 \n",
      "17    2184.04      61.677     65.190     63.385                                 \n",
      "18    2192.44      61.212     63.924     62.539                                 \n",
      "19    2102.20      61.078     64.557     62.769                                 \n",
      "20    2126.10      61.818     64.557     63.158                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      63.314   67.722    65.443\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m65.443\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model304_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3120.09      57.447     51.266     54.181                                 \n",
      " 2    3184.89      63.580     65.190     64.375                                 \n",
      " 3    2775.95      67.925     68.354     68.139                                 \n",
      " 4    2656.59      68.553     68.987     68.770                                 \n",
      " 5    2625.31      68.354     68.354     68.354                                 \n",
      " 6    2690.79      64.497     68.987     66.667                                 \n",
      " 7    2522.20      67.284     68.987     68.125                                 \n",
      " 8    2487.48      68.590     67.722     68.153                                 \n",
      " 9    2313.55      67.949     67.089     67.516                                 \n",
      "10    2304.56      67.516     67.089     67.302                                 \n",
      "11    2223.53      66.258     68.354     67.290                                 \n",
      "12    2294.07      66.667     68.354     67.500                                 \n",
      "13    2258.33      66.061     68.987     67.492                                 \n",
      "14    2164.83      66.463     68.987     67.702                                 \n",
      "15    2233.36      66.061     68.987     67.492                                 \n",
      "16    2210.84      66.061     68.987     67.492                                 \n",
      "17    2260.86      67.485     69.620     68.536                                 \n",
      "18    2159.81      66.460     67.722     67.085                                 \n",
      "19    2102.16      66.049     67.722     66.875                                 \n",
      "20    2150.42      66.463     68.987     67.702                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      68.553   68.987    68.770\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.770\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3156.23      56.579     54.430     55.484                                 \n",
      " 2    3097.37      65.244     67.722     66.460                                 \n",
      " 3    2830.50      59.322     66.456     62.687                                 \n",
      " 4    2744.99      59.043     70.253     64.162                                 \n",
      " 5    2608.06      62.295     72.152     66.862                                 \n",
      " 6    2678.91      64.740     70.886     67.674                                 \n",
      " 7    2540.71      64.368     70.886     67.470                                 \n",
      " 8    2493.58      64.327     69.620     66.869                                 \n",
      " 9    2362.01      65.060     68.354     66.667                                 \n",
      "10    2355.99      64.327     69.620     66.869                                 \n",
      "11    2278.90      63.429     70.253     66.667                                 \n",
      "12    2328.09      61.364     68.354     64.671                                 \n",
      "13    2318.73      61.850     67.722     64.653                                 \n",
      "14    2225.63      60.694     66.456     63.444                                 \n",
      "15    2263.54      61.272     67.089     64.048                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    2240.57      61.272     67.089     64.048                                 \n",
      "17    2205.91      60.819     65.823     63.222                                 \n",
      "18    2198.57      62.573     67.722     65.046                                 \n",
      "19    2103.46      64.497     68.987     66.667                                 \n",
      "20    2157.28      64.497     68.987     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      64.740   70.886    67.674\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.674\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model336_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3120.52      63.910     53.797     58.419                                 \n",
      " 2    3115.88      61.250     62.025     61.635                                 \n",
      " 3    2814.94      65.625     66.456     66.038                                 \n",
      " 4    2700.35      64.671     68.354     66.462                                 \n",
      " 5    2596.03      63.804     65.823     64.798                                 \n",
      " 6    2731.47      63.372     68.987     66.061                                 \n",
      " 7    2499.12      63.314     67.722     65.443                                 \n",
      " 8    2492.55      64.634     67.089     65.839                                 \n",
      " 9    2318.44      64.634     67.089     65.839                                 \n",
      "10    2359.43      64.881     68.987     66.871                                 \n",
      "11    2250.47      66.250     67.089     66.667                                 \n",
      "12    2362.62      63.690     67.722     65.644                                 \n",
      "13    2254.41      64.535     70.253     67.273                                 \n",
      "14    2163.40      64.327     69.620     66.869                                 \n",
      "15    2198.60      63.529     68.354     65.854                                 \n",
      "16    2218.61      63.855     67.089     65.432                                 \n",
      "17    2170.02      65.060     68.354     66.667                                 \n",
      "18    2169.46      64.671     68.354     66.462                                 \n",
      "19    2092.24      64.286     68.354     66.258                                 \n",
      "20    2111.17      63.690     67.722     65.644                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      64.535   70.253    67.273\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.273\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model4_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3277.98      64.762     43.038     51.711                                 \n",
      " 2    3153.05      57.534     53.165     55.263                                 \n",
      " 3    2947.26      57.386     63.924     60.479                                 \n",
      " 4    2792.19      63.690     67.722     65.644                                 \n",
      " 5    2731.15      65.269     68.987     67.077                                 \n",
      " 6    2750.25      67.500     68.354     67.925                                 \n",
      " 7    2601.51      64.671     68.354     66.462                                 \n",
      " 8    2504.88      63.253     66.456     64.815                                 \n",
      " 9    2391.62      62.791     68.354     65.455                                 \n",
      "10    2393.75      63.529     68.354     65.854                                 \n",
      "11    2263.69      63.690     67.722     65.644                                 \n",
      "12    2357.00      63.372     68.987     66.061                                 \n",
      "13    2420.00      65.432     67.089     66.250                                 \n",
      "14    2226.84      66.038     66.456     66.246                                 \n",
      "15    2239.51      66.879     66.456     66.667                                 \n",
      "16    2310.56      65.217     66.456     65.831                                 \n",
      "17    2231.66      65.217     66.456     65.831                                 \n",
      "18    2181.23      65.000     65.823     65.409                                 \n",
      "19    2152.75      65.839     67.089     66.458                                 \n",
      "20    2149.13      66.667     67.089     66.877                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      67.500   68.354    67.925\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.925\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3425.92      54.902     53.165     54.019                                 \n",
      " 2    3147.72      56.548     60.127     58.282                                 \n",
      " 3    2927.23      58.333     66.456     62.130                                 \n",
      " 4    2783.33      57.778     65.823     61.538                                 \n",
      " 5    2615.98      60.335     68.354     64.095                                 \n",
      " 6    2676.69      60.355     64.557     62.385                                 \n",
      " 7    2598.98      61.310     65.190     63.190                                 \n",
      " 8    2502.96      64.327     69.620     66.869                                 \n",
      " 9    2320.91      64.571     71.519     67.868                                 \n",
      "10    2355.41      62.500     69.620     65.868                                 \n",
      "11    2306.98      60.221     68.987     64.307                                 \n",
      "12    2308.90      60.221     68.987     64.307                                 \n",
      "13    2317.24      57.979     68.987     63.006                                 \n",
      "14    2174.50      59.890     68.987     64.118                                 \n",
      "15    2193.33      60.109     69.620     64.516                                 \n",
      "16    2242.15      61.017     68.354     64.478                                 \n",
      "17    2257.02      61.364     68.354     64.671                                 \n",
      "18    2181.62      62.500     69.620     65.868                                 \n",
      "19    2129.18      60.440     69.620     64.706                                 \n",
      "20    2128.65      58.602     68.987     63.372                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      64.571   71.519    67.868\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.868\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3342.47      50.595     53.797     52.147                                 \n",
      " 2    3156.18      61.006     61.392     61.199                                 \n",
      " 3    2907.23      61.111     62.658     61.875                                 \n",
      " 4    2676.68      63.580     65.190     64.375                                 \n",
      " 5    2700.87      62.428     68.354     65.257                                 \n",
      " 6    2693.58      66.272     70.886     68.502                                 \n",
      " 7    2495.51      65.854     68.354     67.081                                 \n",
      " 8    2502.03      64.671     68.354     66.462                                 \n",
      " 9    2305.59      63.793     70.253     66.867                                 \n",
      "10    2327.51      61.932     68.987     65.269                                 \n",
      "11    2277.38      63.429     70.253     66.667                                 \n",
      "12    2284.40      63.743     68.987     66.261                                 \n",
      "13    2239.10      64.286     68.354     66.258                                 \n",
      "14    2118.41      65.217     66.456     65.831                                 \n",
      "15    2205.37      64.968     64.557     64.762                                 \n",
      "16    2231.33      65.190     65.190     65.190                                 \n",
      "17    2186.18      65.823     65.823     65.823                                 \n",
      "18    2147.88      65.190     65.190     65.190                                 \n",
      "19    2056.28      65.823     65.823     65.823                                 \n",
      "20    2091.91      65.839     67.089     66.458                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.272   70.886    68.502\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.502\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3299.06      62.308     51.266     56.250                                 \n",
      " 2    3045.93      54.645     63.291     58.651                                 \n",
      " 3    2853.10      54.396     62.658     58.235                                 \n",
      " 4    2768.87      56.571     62.658     59.459                                 \n",
      " 5    2649.12      56.989     67.089     61.628                                 \n",
      " 6    2611.10      57.609     67.089     61.988                                 \n",
      " 7    2495.59      59.563     68.987     63.930                                 \n",
      " 8    2453.73      58.989     66.456     62.500                                 \n",
      " 9    2288.15      57.865     65.190     61.310                                 \n",
      "10    2336.47      58.286     64.557     61.261                                 \n",
      "11    2243.92      57.303     64.557     60.714                                 \n",
      "12    2320.35      55.738     64.557     59.824                                 \n",
      "13    2268.44      56.250     62.658     59.281                                 \n",
      "14    2147.65      56.180     63.291     59.524                                 \n",
      "15    2184.79      57.803     63.291     60.423                                 \n",
      "16    2205.61      59.172     63.291     61.162                                 \n",
      "17    2199.21      59.302     64.557     61.818                                 \n",
      "18    2199.69      60.465     65.823     63.030                                 \n",
      "19    2093.77      59.195     65.190     62.048                                 \n",
      "20    2138.54      58.659     66.456     62.315                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      59.563   68.987    63.930\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m63.930\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_lg'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3257.61      55.405     51.899     53.595                                 \n",
      " 2    3121.04      62.581     61.392     61.981                                 \n",
      " 3    2864.59      62.500     66.456     64.417                                 \n",
      " 4    2718.22      56.216     65.823     60.641                                 \n",
      " 5    2736.15      66.867     70.253     68.519                                 \n",
      " 6    2710.74      65.031     67.089     66.044                                 \n",
      " 7    2604.90      64.286     68.354     66.258                                 \n",
      " 8    2469.19      63.372     68.987     66.061                                 \n",
      " 9    2367.77      63.905     68.354     66.055                                 \n",
      "10    2345.97      63.584     69.620     66.465                                 \n",
      "11    2336.75      63.743     68.987     66.261                                 \n",
      "12    2358.93      63.743     68.987     66.261                                 \n",
      "13    2179.64      65.269     68.987     67.077                                 \n",
      "14    2178.20      65.476     69.620     67.485                                 \n",
      "15    2227.55      64.706     69.620     67.073                                 \n",
      "16    2228.16      62.500     69.620     65.868                                 \n",
      "17    2186.96      63.372     68.987     66.061                                 \n",
      "18    2182.85      63.905     68.354     66.055                                 \n",
      "19    2055.30      63.314     67.722     65.443                                 \n",
      "20    2129.45      63.372     68.987     66.061                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.867   70.253    68.519\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.519\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ner_with_every_tok2vec(datasets_0_1_2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔥 Top model for a full set of annotations: `68.770` 🔥\n",
    "- trained with `tok2vec_abs_sci_model304_gpu.bin`\n",
    "\n",
    "**Why such a significant performance drop?!?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the annotated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_merged = \"cord_19_rf_sentences_merged\"\n",
    "file_db_out = f\"data/annotated/{datasets_merged}.jsonl\"\n",
    "file_spacy_format = f\"data/annotated/{datasets_merged}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created dataset 'cord_19_rf_sentences_merged'\u001b[0m\n",
      "\u001b[38;5;2m✔ Merged 652 examples from 4 datasets\u001b[0m\n",
      "Created merged dataset 'cord_19_rf_sentences_merged'\n"
     ]
    }
   ],
   "source": [
    "!prodigy db-merge $datasets_0_1_2_3 $datasets_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!prodigy db-out $datasets_merged > data/annotated/cord_19_rf_sentences_merged.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Starting with language en\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "\n",
      "Type   Total   Merged\n",
      "----   -----   ------\n",
      "NER      652      625\n",
      "\n",
      "\u001b[38;5;2m✔ Saved 625 examples to\n",
      "data/annotated/cord_19_rf_sentences_merged.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prodigy data-to-spacy data/annotated/cord_19_rf_sentences_merged.json --ner $datasets_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.04.14 (Tue)\n",
    "## Train final models with `md` base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= cord_19_rf_sentences ==================================\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     473.65       0.000      0.000      0.000                                 \n",
      " 2     717.18       0.000      0.000      0.000                                 \n",
      " 3     562.82      26.316     20.000     22.727                                 \n",
      " 4     539.94      31.250     20.000     24.390                                 \n",
      " 5     490.88      40.000     24.000     30.000                                 \n",
      " 6     427.17      43.750     28.000     34.146                                 \n",
      " 7     497.55      46.667     28.000     35.000                                 \n",
      " 8     526.19      50.000     36.000     41.860                                 \n",
      " 9     471.96      50.000     40.000     44.444                                 \n",
      "10     388.95      52.941     36.000     42.857                                 \n",
      "11     417.61      50.000     36.000     41.860                                 \n",
      "12     400.40      52.941     36.000     42.857                                 \n",
      "13     403.22      47.059     32.000     38.095                                 \n",
      "14     427.87      41.176     28.000     33.333                                 \n",
      "15     416.47      41.176     28.000     33.333                                 \n",
      "16     405.22      47.059     32.000     38.095                                 \n",
      "17     363.41      62.500     40.000     48.780                                 \n",
      "18     383.55      55.000     44.000     48.889                                 \n",
      "19     359.28      55.556     40.000     46.512                                 \n",
      "20     428.07      55.000     44.000     48.889                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      55.000   44.000    48.889\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m48.889\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model238_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     462.29       0.000      0.000      0.000                                 \n",
      " 2     562.42       0.000      0.000      0.000                                 \n",
      " 3     527.61      27.778     20.000     23.256                                 \n",
      " 4     488.41      42.857     24.000     30.769                                 \n",
      " 5     449.91      38.462     20.000     26.316                                 \n",
      " 6     487.15      31.250     20.000     24.390                                 \n",
      " 7     454.79      46.154     24.000     31.579                                 \n",
      " 8     475.30      38.889     28.000     32.558                                 \n",
      " 9     438.62      42.105     32.000     36.364                                 \n",
      "10     452.07      42.857     36.000     39.130                                 \n",
      "11     461.32      47.368     36.000     40.909                                 \n",
      "12     390.74      47.368     36.000     40.909                                 \n",
      "13     387.87      52.941     36.000     42.857                                 \n",
      "14     393.34      47.368     36.000     40.909                                 \n",
      "15     429.50      50.000     40.000     44.444                                 \n",
      "16     409.35      50.000     40.000     44.444                                 \n",
      "17     342.96      50.000     40.000     44.444                                 \n",
      "18     383.34      47.619     40.000     43.478                                 \n",
      "19     352.92      47.619     40.000     43.478                                 \n",
      "20     421.58      47.619     40.000     43.478                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      50.000   40.000    44.444\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m44.444\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2400_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     461.24       0.000      0.000      0.000                                 \n",
      " 2     597.21       0.000      0.000      0.000                                 \n",
      " 3     492.84      31.250     20.000     24.390                                 \n",
      " 4     449.50      50.000     28.000     35.897                                 \n",
      " 5     490.26      38.462     20.000     26.316                                 \n",
      " 6     412.66      46.154     24.000     31.579                                 \n",
      " 7     466.44      50.000     28.000     35.897                                 \n",
      " 8     500.71      43.750     28.000     34.146                                 \n",
      " 9     445.27      50.000     28.000     35.897                                 \n",
      "10     416.93      57.143     32.000     41.026                                 \n",
      "11     389.18      53.333     32.000     40.000                                 \n",
      "12     399.63      55.556     40.000     46.512                                 \n",
      "13     410.23      60.000     48.000     53.333                                 \n",
      "14     403.09      50.000     36.000     41.860                                 \n",
      "15     421.58      52.941     36.000     42.857                                 \n",
      "16     405.71      52.941     36.000     42.857                                 \n",
      "17     354.84      55.556     40.000     46.512                                 \n",
      "18     363.68      61.111     44.000     51.163                                 \n",
      "19     353.90      61.111     44.000     51.163                                 \n",
      "20     373.64      57.143     48.000     52.174                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   48.000    53.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m53.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2401_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     506.78       0.000      0.000      0.000                                 \n",
      " 2     605.36       0.000      0.000      0.000                                 \n",
      " 3     587.27      47.059     32.000     38.095                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4     519.65      47.368     36.000     40.909                                 \n",
      " 5     510.44      38.889     28.000     32.558                                 \n",
      " 6     444.14      42.105     32.000     36.364                                 \n",
      " 7     662.63      40.000     40.000     40.000                                 \n",
      " 8     469.91      31.818     28.000     29.787                                 \n",
      " 9     484.98      38.095     32.000     34.783                                 \n",
      "10     445.55      52.381     44.000     47.826                                 \n",
      "11     457.62      47.826     44.000     45.833                                 \n",
      "12     414.88      50.000     44.000     46.809                                 \n",
      "13     403.09      57.143     48.000     52.174                                 \n",
      "14     420.27      60.000     48.000     53.333                                 \n",
      "15     441.94      60.000     48.000     53.333                                 \n",
      "16     436.54      60.000     48.000     53.333                                 \n",
      "17     362.41      57.143     48.000     52.174                                 \n",
      "18     390.08      57.143     48.000     52.174                                 \n",
      "19     349.36      54.167     52.000     53.061                                 \n",
      "20     395.77      54.167     52.000     53.061                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      60.000   48.000    53.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m53.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2402_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     471.65       0.000      0.000      0.000                                 \n",
      " 2     695.68       0.000      0.000      0.000                                 \n",
      " 3     547.06      25.000     16.000     19.512                                 \n",
      " 4     514.80      46.154     24.000     31.579                                 \n",
      " 5     513.96      38.889     28.000     32.558                                 \n",
      " 6     422.26      46.667     28.000     35.000                                 \n",
      " 7     533.14      46.667     28.000     35.000                                 \n",
      " 8     538.79      47.368     36.000     40.909                                 \n",
      " 9     563.84      31.250     20.000     24.390                                 \n",
      "10     472.36      38.889     28.000     32.558                                 \n",
      "11     438.29      52.632     40.000     45.455                                 \n",
      "12     412.88      47.059     32.000     38.095                                 \n",
      "13     409.68      47.059     32.000     38.095                                 \n",
      "14     411.24      41.176     28.000     33.333                                 \n",
      "15     417.40      56.250     36.000     43.902                                 \n",
      "16     432.54      56.250     36.000     43.902                                 \n",
      "17     379.07      55.556     40.000     46.512                                 \n",
      "18     395.97      55.556     40.000     46.512                                 \n",
      "19     344.72      56.250     36.000     43.902                                 \n",
      "20     397.77      58.824     40.000     47.619                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      58.824   40.000    47.619\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m47.619\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model304_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     463.49       0.000      0.000      0.000                                 \n",
      " 2     578.47      33.333     12.000     17.647                                 \n",
      " 3     509.51      31.818     28.000     29.787                                 \n",
      " 4     491.75      35.714     20.000     25.641                                 \n",
      " 5     436.98      43.750     28.000     34.146                                 \n",
      " 6     426.52      50.000     36.000     41.860                                 \n",
      " 7     462.07      52.941     36.000     42.857                                 \n",
      " 8     471.55      47.059     32.000     38.095                                 \n",
      " 9     405.79      44.444     32.000     37.209                                 \n",
      "10     416.51      42.857     36.000     39.130                                 \n",
      "11     429.81      47.619     40.000     43.478                                 \n",
      "12     383.97      47.619     40.000     43.478                                 \n",
      "13     357.91      45.000     36.000     40.000                                 \n",
      "14     397.29      45.455     40.000     42.553                                 \n",
      "15     416.64      50.000     44.000     46.809                                 \n",
      "16     404.09      55.000     44.000     48.889                                 \n",
      "17     344.53      52.632     40.000     45.455                                 \n",
      "18     354.05      57.143     48.000     52.174                                 \n",
      "19     340.72      61.905     52.000     56.522                                 \n",
      "20     370.71      57.143     48.000     52.174                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      61.905   52.000    56.522\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m56.522\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2Kading 'en_core_sci_md'...\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     463.65       0.000      0.000      0.000                                 \n",
      " 2     585.74      12.500      4.000      6.061                                 \n",
      " 3     507.51      38.889     28.000     32.558                                 \n",
      " 4     495.60      53.333     32.000     40.000                                 \n",
      " 5     451.56      43.750     28.000     34.146                                 \n",
      " 6     418.83      43.750     28.000     34.146                                 \n",
      " 7     447.53      46.667     28.000     35.000                                 \n",
      " 8     576.92      38.462     20.000     26.316                                 \n",
      " 9     459.73      42.857     24.000     30.769                                 \n",
      "10     454.79      56.250     36.000     43.902                                 \n",
      "11     422.21      47.059     32.000     38.095                                 \n",
      "12     379.47      52.941     36.000     42.857                                 \n",
      "13     398.02      52.632     40.000     45.455                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14     402.47      50.000     40.000     44.444                                 \n",
      "15     442.71      50.000     40.000     44.444                                 \n",
      "16     415.41      50.000     36.000     41.860                                 \n",
      "17     356.17      55.556     40.000     46.512                                 \n",
      "18     355.91      66.667     48.000     55.814                                 \n",
      "19     348.44      66.667     48.000     55.814                                 \n",
      "20     363.66      61.111     44.000     51.163                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.667   48.000    55.814\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m55.814\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model336_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     465.20       0.000      0.000      0.000                                 \n",
      " 2     588.85      45.455     20.000     27.778                                 \n",
      " 3     517.53      43.750     28.000     34.146                                 \n",
      " 4     476.22      46.667     28.000     35.000                                 \n",
      " 5     549.46      43.750     28.000     34.146                                 \n",
      " 6     454.62      42.857     24.000     30.769                                 \n",
      " 7     521.39      38.889     28.000     32.558                                 \n",
      " 8     530.00      52.632     40.000     45.455                                 \n",
      " 9     437.86      52.632     40.000     45.455                                 \n",
      "10     483.52      47.368     36.000     40.909                                 \n",
      "11     420.56      52.632     40.000     45.455                                 \n",
      "12     396.41      50.000     40.000     44.444                                 \n",
      "13     403.52      35.000     28.000     31.111                                 \n",
      "14     417.08      43.478     40.000     41.667                                 \n",
      "15     404.12      40.909     36.000     38.298                                 \n",
      "16     390.57      45.000     36.000     40.000                                 \n",
      "17     352.64      52.174     48.000     50.000                                 \n",
      "18     373.24      45.455     40.000     42.553                                 \n",
      "19     340.80      52.174     48.000     50.000                                 \n",
      "20     369.38      50.000     40.000     44.444                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      52.174   48.000    50.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m50.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model4_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     480.26       0.000      0.000      0.000                                 \n",
      " 2     553.74      42.857     12.000     18.750                                 \n",
      " 3     530.05      43.750     28.000     34.146                                 \n",
      " 4     516.91      50.000     28.000     35.897                                 \n",
      " 5     520.04      34.783     32.000     33.333                                 \n",
      " 6     490.71      41.176     28.000     33.333                                 \n",
      " 7     579.76      41.176     28.000     33.333                                 \n",
      " 8     512.71      40.000     24.000     30.000                                 \n",
      " 9     444.21      38.889     28.000     32.558                                 \n",
      "10     447.83      47.368     36.000     40.909                                 \n",
      "11     423.04      47.368     36.000     40.909                                 \n",
      "12     399.84      36.364     32.000     34.043                                 \n",
      "13     433.26      34.783     32.000     33.333                                 \n",
      "14     421.94      40.000     32.000     35.556                                 \n",
      "15     461.32      40.000     32.000     35.556                                 \n",
      "16     421.65      40.000     32.000     35.556                                 \n",
      "17     374.08      38.095     32.000     34.783                                 \n",
      "18     376.66      42.857     36.000     39.130                                 \n",
      "19     387.13      39.130     36.000     37.500                                 \n",
      "20     352.25      37.500     36.000     36.735                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      47.368   36.000    40.909\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m40.909\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     494.66       0.000      0.000      0.000                                 \n",
      " 2     590.27       0.000      0.000      0.000                                 \n",
      " 3     581.81      36.364     32.000     34.043                                 \n",
      " 4     481.80      45.455     40.000     42.553                                 \n",
      " 5     541.66      37.500     36.000     36.735                                 \n",
      " 6     565.49      43.750     28.000     34.146                                 \n",
      " 7     551.96      47.059     32.000     38.095                                 \n",
      " 8     557.71      41.176     28.000     33.333                                 \n",
      " 9     522.42      41.176     28.000     33.333                                 \n",
      "10     536.20      50.000     32.000     39.024                                 \n",
      "11     496.98      46.667     28.000     35.000                                 \n",
      "12     432.54      52.381     44.000     47.826                                 \n",
      "13     486.58      52.381     44.000     47.826                                 \n",
      "14     432.82      55.000     44.000     48.889                                 \n",
      "15     472.82      52.632     40.000     45.455                                 \n",
      "16     435.98      52.632     40.000     45.455                                 \n",
      "17     366.85      52.632     40.000     45.455                                 \n",
      "18     387.10      55.556     40.000     46.512                                 \n",
      "19     362.13      55.556     40.000     46.512                                 \n",
      "20     393.71      55.556     40.000     46.512                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      55.000   44.000    48.889\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m48.889\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     468.97       0.000      0.000      0.000                                 \n",
      " 2     586.66       0.000      0.000      0.000                                 \n",
      " 3     537.96      50.000     32.000     39.024                                 \n",
      " 4     543.50      44.444     32.000     37.209                                 \n",
      " 5     475.28      42.857     36.000     39.130                                 \n",
      " 6     467.28      41.176     28.000     33.333                                 \n",
      " 7     463.37      55.000     44.000     48.889                                 \n",
      " 8     499.87      40.000     40.000     40.000                                 \n",
      " 9     446.57      42.308     44.000     43.137                                 \n",
      "10     433.04      40.000     40.000     40.000                                 \n",
      "11     450.77      47.619     40.000     43.478                                 \n",
      "12     414.32      50.000     44.000     46.809                                 \n",
      "13     430.52      50.000     40.000     44.444                                 \n",
      "14     416.19      47.826     44.000     45.833                                 \n",
      "15     433.68      52.000     52.000     52.000                                 \n",
      "16     429.71      50.000     48.000     48.980                                 \n",
      "17     354.60      57.143     48.000     52.174                                 \n",
      "18     379.31      59.091     52.000     55.319                                 \n",
      "19     357.09      59.091     52.000     55.319                                 \n",
      "20     359.88      54.545     48.000     51.064                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      59.091   52.000    55.319\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m55.319\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     539.05       0.000      0.000      0.000                                 \n",
      " 2     549.20       0.000      0.000      0.000                                 \n",
      " 3     526.58      31.579     24.000     27.273                                 \n",
      " 4     473.77      31.250     20.000     24.390                                 \n",
      " 5     537.43      43.750     28.000     34.146                                 \n",
      " 6     443.16      23.077     12.000     15.789                                 \n",
      " 7     464.02      50.000     36.000     41.860                                 \n",
      " 8     480.31      33.333     28.000     30.435                                 \n",
      " 9     495.67      35.000     28.000     31.111                                 \n",
      "10     420.68      47.619     40.000     43.478                                 \n",
      "11     484.23      50.000     40.000     44.444                                 \n",
      "12     462.05      52.381     44.000     47.826                                 \n",
      "13     404.50      50.000     44.000     46.809                                 \n",
      "14     402.07      39.130     36.000     37.500                                 \n",
      "15     433.28      42.857     36.000     39.130                                 \n",
      "16     417.93      42.857     36.000     39.130                                 \n",
      "17     342.18      45.455     40.000     42.553                                 \n",
      "18     362.38      45.455     40.000     42.553                                 \n",
      "19     342.18      50.000     44.000     46.809                                 \n",
      "20     377.08      50.000     44.000     46.809                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      52.381   44.000    47.826\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m47.826\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 99 total examples\n",
      "Using 80 train / 19 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1     504.44       0.000      0.000      0.000                                 \n",
      " 2     664.17       0.000      0.000      0.000                                 \n",
      " 3     535.62      43.750     28.000     34.146                                 \n",
      " 4     477.27      53.333     32.000     40.000                                 \n",
      " 5     554.16      46.667     28.000     35.000                                 \n",
      " 6     436.09      50.000     36.000     41.860                                 \n",
      " 7     457.92      47.619     40.000     43.478                                 \n",
      " 8     469.56      47.619     40.000     43.478                                 \n",
      " 9     475.10      42.857     36.000     39.130                                 \n",
      "10     526.88      42.105     32.000     36.364                                 \n",
      "11     414.92      47.368     36.000     40.909                                 \n",
      "12     423.94      52.381     44.000     47.826                                 \n",
      "13     422.35      59.091     52.000     55.319                                 \n",
      "14     435.48      59.091     52.000     55.319                                 \n",
      "15     437.25      61.905     52.000     56.522                                 \n",
      "16     423.76      60.000     48.000     53.333                                 \n",
      "17     367.32      65.000     52.000     57.778                                 \n",
      "18     375.01      61.905     52.000     56.522                                 \n",
      "19     358.90      61.905     52.000     56.522                                 \n",
      "20     395.61      61.905     52.000     56.522                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.000   52.000    57.778\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m57.778\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "= cord_19_rf_sentences,cord_19_rf_sentences_correct ==================================\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1583.05      70.370     29.688     41.758                                 \n",
      " 2    1449.07      57.895     51.562     54.545                                 \n",
      " 3    1561.91      64.583     48.438     55.357                                 \n",
      " 4    1471.27      60.714     53.125     56.667                                 \n",
      " 5    1438.89      70.909     60.938     65.546                                 \n",
      " 6    1424.30      72.222     60.938     66.102                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7    1345.34      68.627     54.688     60.870                                 \n",
      " 8    1284.09      68.627     54.688     60.870                                 \n",
      " 9    1331.92      70.588     56.250     62.609                                 \n",
      "10    1277.93      66.667     59.375     62.810                                 \n",
      "11    1183.08      68.852     65.625     67.200                                 \n",
      "12    1254.01      73.684     65.625     69.421                                 \n",
      "13    1220.34      71.186     65.625     68.293                                 \n",
      "14    1205.10      77.193     68.750     72.727                                 \n",
      "15    1159.80      74.138     67.188     70.492                                 \n",
      "16    1154.58      73.585     60.938     66.667                                 \n",
      "17    1066.97      72.222     60.938     66.102                                 \n",
      "18    1096.35      76.000     59.375     66.667                                 \n",
      "19    1080.09      75.510     57.812     65.487                                 \n",
      "20    1083.94      75.510     57.812     65.487                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.193   68.750    72.727\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.727\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model238_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1500.03      58.621     26.562     36.559                                 \n",
      " 2    1349.70      59.615     48.438     53.448                                 \n",
      " 3    1365.52      72.340     53.125     61.261                                 \n",
      " 4    1358.28      78.846     64.062     70.690                                 \n",
      " 5    1329.22      77.778     65.625     71.186                                 \n",
      " 6    1369.96      71.429     62.500     66.667                                 \n",
      " 7    1367.63      70.690     64.062     67.213                                 \n",
      " 8    1212.56      70.690     64.062     67.213                                 \n",
      " 9    1212.45      69.355     67.188     68.254                                 \n",
      "10    1174.55      71.667     67.188     69.355                                 \n",
      "11    1081.16      70.492     67.188     68.800                                 \n",
      "12    1232.07      67.213     64.062     65.600                                 \n",
      "13    1175.46      70.000     65.625     67.742                                 \n",
      "14    1130.29      70.000     65.625     67.742                                 \n",
      "15    1060.21      71.930     64.062     67.769                                 \n",
      "16    1110.08      73.684     65.625     69.421                                 \n",
      "17    1036.94      68.966     62.500     65.574                                 \n",
      "18    1066.93      69.492     64.062     66.667                                 \n",
      "19    1052.64      71.186     65.625     68.293                                 \n",
      "20    1091.09      75.000     65.625     70.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      77.778   65.625    71.186\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.186\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2400_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1511.44      53.488     35.938     42.991                                 \n",
      " 2    1404.45      53.846     43.750     48.276                                 \n",
      " 3    1417.16      68.333     64.062     66.129                                 \n",
      " 4    1384.53      67.273     57.812     62.185                                 \n",
      " 5    1345.29      73.214     64.062     68.333                                 \n",
      " 6    1362.23      76.786     67.188     71.667                                 \n",
      " 7    1351.95      76.786     67.188     71.667                                 \n",
      " 8    1248.33      72.881     67.188     69.919                                 \n",
      " 9    1226.78      75.000     65.625     70.000                                 \n",
      "10    1180.64      74.545     64.062     68.908                                 \n",
      "11    1099.17      74.545     64.062     68.908                                 \n",
      "12    1202.93      75.439     67.188     71.074                                 \n",
      "13    1182.53      75.000     65.625     70.000                                 \n",
      "14    1126.78      75.000     65.625     70.000                                 \n",
      "15    1083.51      71.930     64.062     67.769                                 \n",
      "16    1123.37      69.492     64.062     66.667                                 \n",
      "17    1018.89      71.667     67.188     69.355                                 \n",
      "18    1057.00      70.968     68.750     69.841                                 \n",
      "19    1038.93      71.429     70.312     70.866                                 \n",
      "20    1073.14      70.492     67.188     68.800                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.786   67.188    71.667\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.667\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2401_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1558.35      61.765     32.812     42.857                                 \n",
      " 2    1440.25      59.091     40.625     48.148                                 \n",
      " 3    1490.58      63.462     51.562     56.897                                 \n",
      " 4    1495.19      62.500     54.688     58.333                                 \n",
      " 5    1473.91      66.071     57.812     61.667                                 \n",
      " 6    1448.58      73.077     59.375     65.517                                 \n",
      " 7    1374.44      78.431     62.500     69.565                                 \n",
      " 8    1275.67      78.261     56.250     65.455                                 \n",
      " 9    1261.01      72.340     53.125     61.261                                 \n",
      "10    1214.56      72.340     53.125     61.261                                 \n",
      "11    1159.68      70.455     48.438     57.407                                 \n",
      "12    1263.45      74.419     50.000     59.813                                 \n",
      "13    1164.50      69.565     50.000     58.182                                 \n",
      "14    1234.34      71.739     51.562     60.000                                 \n",
      "15    1162.53      71.739     51.562     60.000                                 \n",
      "16    1114.43      73.585     60.938     66.667                                 \n",
      "17    1087.16      80.392     64.062     71.304                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    1079.45      78.431     62.500     69.565                                 \n",
      "19    1072.42      76.471     60.938     67.826                                 \n",
      "20    1130.36      75.000     60.938     67.241                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      80.392   64.062    71.304\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.304\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2402_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1545.99      70.968     34.375     46.316                                 \n",
      " 2    1428.75      53.846     43.750     48.276                                 \n",
      " 3    1497.23      64.444     45.312     53.211                                 \n",
      " 4    1512.30      67.308     54.688     60.345                                 \n",
      " 5    1472.43      64.815     54.688     59.322                                 \n",
      " 6    1467.80      68.421     60.938     64.463                                 \n",
      " 7    1412.05      72.222     60.938     66.102                                 \n",
      " 8    1280.70      70.370     59.375     64.407                                 \n",
      " 9    1289.28      74.074     62.500     67.797                                 \n",
      "10    1193.37      71.698     59.375     64.957                                 \n",
      "11    1124.43      72.222     60.938     66.102                                 \n",
      "12    1281.45      70.370     59.375     64.407                                 \n",
      "13    1172.75      70.588     56.250     62.609                                 \n",
      "14    1110.85      69.231     56.250     62.069                                 \n",
      "15    1075.64      71.154     57.812     63.793                                 \n",
      "16    1122.38      73.077     59.375     65.517                                 \n",
      "17    1041.15      72.549     57.812     64.348                                 \n",
      "18    1132.02      71.154     57.812     63.793                                 \n",
      "19    1097.78      69.811     57.812     63.248                                 \n",
      "20    1104.00      69.811     57.812     63.248                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.074   62.500    67.797\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.797\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model304_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1541.84      66.667     28.125     39.560                                 \n",
      " 2    1348.29      60.000     51.562     55.462                                 \n",
      " 3    1346.19      76.923     62.500     68.966                                 \n",
      " 4    1393.42      70.370     59.375     64.407                                 \n",
      " 5    1320.03      72.414     65.625     68.852                                 \n",
      " 6    1287.86      73.214     64.062     68.333                                 \n",
      " 7    1313.17      78.182     67.188     72.269                                 \n",
      " 8    1282.97      76.471     60.938     67.826                                 \n",
      " 9    1216.17      68.085     50.000     57.658                                 \n",
      "10    1217.17      64.000     50.000     56.140                                 \n",
      "11    1104.80      72.414     65.625     68.852                                 \n",
      "12    1189.47      72.414     65.625     68.852                                 \n",
      "13    1161.52      73.684     65.625     69.421                                 \n",
      "14    1122.24      71.186     65.625     68.293                                 \n",
      "15    1087.08      72.414     65.625     68.852                                 \n",
      "16    1124.46      70.175     62.500     66.116                                 \n",
      "17    1021.48      69.643     60.938     65.000                                 \n",
      "18    1103.97      69.643     60.938     65.000                                 \n",
      "19    1037.61      71.698     59.375     64.957                                 \n",
      "20    1083.10      72.222     60.938     66.102                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.182   67.188    72.269\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.269\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1515.67      56.667     26.562     36.170                                 \n",
      " 2    1357.37      57.407     48.438     52.542                                 \n",
      " 3    1407.76      75.000     65.625     70.000                                 \n",
      " 4    1390.67      74.545     64.062     68.908                                 \n",
      " 5    1379.80      68.750     68.750     68.750                                 \n",
      " 6    1325.09      67.857     59.375     63.333                                 \n",
      " 7    1319.67      67.857     59.375     63.333                                 \n",
      " 8    1210.35      70.175     62.500     66.116                                 \n",
      " 9    1144.21      67.241     60.938     63.934                                 \n",
      "10    1158.38      69.643     60.938     65.000                                 \n",
      "11    1154.90      68.966     62.500     65.574                                 \n",
      "12    1216.50      68.421     60.938     64.463                                 \n",
      "13    1135.42      67.241     60.938     63.934                                 \n",
      "14    1095.03      67.241     60.938     63.934                                 \n",
      "15    1073.32      68.421     60.938     64.463                                 \n",
      "16    1110.34      70.175     62.500     66.116                                 \n",
      "17    1047.70      67.273     57.812     62.185                                 \n",
      "18    1051.41      67.273     57.812     62.185                                 \n",
      "19    1026.83      68.519     57.812     62.712                                 \n",
      "20    1075.85      68.519     57.812     62.712                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   65.625    70.000\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.000\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model336_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    1494.70      45.455     23.438     30.928                                 \n",
      " 2    1388.62      59.615     48.438     53.448                                 \n",
      " 3    1377.47      67.857     59.375     63.333                                 \n",
      " 4    1352.62      68.421     60.938     64.463                                 \n",
      " 5    1322.40      69.355     67.188     68.254                                 \n",
      " 6    1323.54      70.492     67.188     68.800                                 \n",
      " 7    1325.43      67.742     65.625     66.667                                 \n",
      " 8    1195.20      68.254     67.188     67.717                                 \n",
      " 9    1171.08      66.129     64.062     65.079                                 \n",
      "10    1179.00      65.672     68.750     67.176                                 \n",
      "11    1093.51      68.182     70.312     69.231                                 \n",
      "12    1199.95      69.231     70.312     69.767                                 \n",
      "13    1173.48      70.492     67.188     68.800                                 \n",
      "14    1140.20      67.742     65.625     66.667                                 \n",
      "15    1088.93      68.333     64.062     66.129                                 \n",
      "16    1084.32      71.186     65.625     68.293                                 \n",
      "17    1024.74      72.727     62.500     67.227                                 \n",
      "18    1084.41      71.429     62.500     66.667                                 \n",
      "19    1041.97      71.429     62.500     66.667                                 \n",
      "20    1069.94      71.930     64.062     67.769                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      69.231   70.312    69.767\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.767\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model4_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1555.99      46.154     28.125     34.951                                 \n",
      " 2    1471.45      52.941     42.188     46.957                                 \n",
      " 3    1448.88      63.830     46.875     54.054                                 \n",
      " 4    1442.49      68.085     50.000     57.658                                 \n",
      " 5    1391.68      63.265     48.438     54.867                                 \n",
      " 6    1385.38      65.957     48.438     55.856                                 \n",
      " 7    1410.49      68.750     51.562     58.929                                 \n",
      " 8    1285.53      71.739     51.562     60.000                                 \n",
      " 9    1248.68      71.739     51.562     60.000                                 \n",
      "10    1220.98      70.213     51.562     59.459                                 \n",
      "11    1151.61      66.667     46.875     55.046                                 \n",
      "12    1260.07      65.957     48.438     55.856                                 \n",
      "13    1183.58      70.833     53.125     60.714                                 \n",
      "14    1098.66      71.429     54.688     61.947                                 \n",
      "15    1129.71      68.750     51.562     58.929                                 \n",
      "16    1139.40      70.833     53.125     60.714                                 \n",
      "17    1070.58      72.340     53.125     61.261                                 \n",
      "18    1106.83      70.833     53.125     60.714                                 \n",
      "19    1036.82      70.833     53.125     60.714                                 \n",
      "20    1080.06      68.750     51.562     58.929                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.429   54.688    61.947\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m61.947\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1739.95      77.273     26.562     39.535                                 \n",
      " 2    1443.64      52.174     37.500     43.636                                 \n",
      " 3    1468.38      72.222     60.938     66.102                                 \n",
      " 4    1463.93      76.471     60.938     67.826                                 \n",
      " 5    1391.14      69.492     64.062     66.667                                 \n",
      " 6    1366.50      73.214     64.062     68.333                                 \n",
      " 7    1354.68      76.364     65.625     70.588                                 \n",
      " 8    1191.12      73.585     60.938     66.667                                 \n",
      " 9    1232.84      77.358     64.062     70.085                                 \n",
      "10    1255.67      76.364     65.625     70.588                                 \n",
      "11    1150.66      73.214     64.062     68.333                                 \n",
      "12    1233.96      71.429     62.500     66.667                                 \n",
      "13    1200.47      71.698     59.375     64.957                                 \n",
      "14    1159.75      70.370     59.375     64.407                                 \n",
      "15    1138.86      75.000     60.938     67.241                                 \n",
      "16    1108.01      76.000     59.375     66.667                                 \n",
      "17    1044.90      76.000     59.375     66.667                                 \n",
      "18    1069.01      74.510     59.375     66.087                                 \n",
      "19    1059.17      75.000     60.938     67.241                                 \n",
      "20    1131.54      75.000     60.938     67.241                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.364   65.625    70.588\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.588\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1567.08      58.537     37.500     45.714                                 \n",
      " 2    1581.72      56.604     46.875     51.282                                 \n",
      " 3    1440.75      72.000     56.250     63.158                                 \n",
      " 4    1481.64      70.588     56.250     62.609                                 \n",
      " 5    1412.90      64.815     54.688     59.322                                 \n",
      " 6    1438.43      71.698     59.375     64.957                                 \n",
      " 7    1353.06      75.472     62.500     68.376                                 \n",
      " 8    1308.77      73.585     60.938     66.667                                 \n",
      " 9    1246.02      71.154     57.812     63.793                                 \n",
      "10    1207.23      69.811     57.812     63.248                                 \n",
      "11    1139.78      70.370     59.375     64.407                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12    1228.52      73.077     59.375     65.517                                 \n",
      "13    1176.59      72.222     60.938     66.102                                 \n",
      "14    1143.49      73.585     60.938     66.667                                 \n",
      "15    1131.78      74.074     62.500     67.797                                 \n",
      "16    1125.37      72.222     60.938     66.102                                 \n",
      "17    1058.72      70.370     59.375     64.407                                 \n",
      "18    1083.66      73.585     60.938     66.667                                 \n",
      "19    1112.12      70.909     60.938     65.546                                 \n",
      "20    1094.54      72.727     62.500     67.227                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.472   62.500    68.376\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.376\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1646.39      57.576     29.688     39.175                                 \n",
      " 2    1399.29      64.815     54.688     59.322                                 \n",
      " 3    1412.12      69.565     50.000     58.182                                 \n",
      " 4    1458.12      72.549     57.812     64.348                                 \n",
      " 5    1422.03      68.750     51.562     58.929                                 \n",
      " 6    1365.63      75.510     57.812     65.487                                 \n",
      " 7    1357.09      75.510     57.812     65.487                                 \n",
      " 8    1234.03      77.551     59.375     67.257                                 \n",
      " 9    1194.89      75.926     64.062     69.492                                 \n",
      "10    1230.99      75.439     67.188     71.074                                 \n",
      "11    1156.03      74.138     67.188     70.492                                 \n",
      "12    1235.93      77.193     68.750     72.727                                 \n",
      "13    1133.96      75.472     62.500     68.376                                 \n",
      "14    1111.45      74.074     62.500     67.797                                 \n",
      "15    1177.05      78.947     70.312     74.380                                 \n",
      "16    1166.93      79.245     65.625     71.795                                 \n",
      "17    1067.20      77.778     65.625     71.186                                 \n",
      "18    1088.89      76.364     65.625     70.588                                 \n",
      "19    1080.09      77.778     65.625     71.186                                 \n",
      "20    1130.04      74.138     67.188     70.492                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.947   70.312    74.380\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.380\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 308 total examples\n",
      "Using 247 train / 61 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    1559.12      50.000     35.938     41.818                                 \n",
      " 2    1432.23      62.963     53.125     57.627                                 \n",
      " 3    1462.87      62.791     42.188     50.467                                 \n",
      " 4    1469.62      65.217     46.875     54.545                                 \n",
      " 5    1387.09      67.391     48.438     56.364                                 \n",
      " 6    1473.72      67.797     62.500     65.041                                 \n",
      " 7    1386.23      70.909     60.938     65.546                                 \n",
      " 8    1261.04      66.667     59.375     62.810                                 \n",
      " 9    1282.73      66.000     51.562     57.895                                 \n",
      "10    1213.38      64.706     51.562     57.391                                 \n",
      "11    1160.48      66.038     54.688     59.829                                 \n",
      "12    1260.21      66.667     56.250     61.017                                 \n",
      "13    1186.86      68.519     57.812     62.712                                 \n",
      "14    1219.25      70.909     60.938     65.546                                 \n",
      "15    1141.70      67.241     60.938     63.934                                 \n",
      "16    1161.60      68.421     60.938     64.463                                 \n",
      "17    1089.94      69.643     60.938     65.000                                 \n",
      "18    1089.90      69.091     59.375     63.866                                 \n",
      "19    1057.90      69.643     60.938     65.000                                 \n",
      "20    1122.62      69.643     60.938     65.000                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      70.909   60.938    65.546\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m65.546\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "= cord_19_rf_sentences,cord_19_rf_sentences_correct,cord_19_rf_sentences_correct_2 ==================================\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2897.17      65.476     45.455     53.659                                 \n",
      " 2    2562.71      73.171     49.587     59.113                                 \n",
      " 3    2571.32      72.632     57.025     63.889                                 \n",
      " 4    2443.85      71.429     53.719     61.321                                 \n",
      " 5    2292.14      74.000     61.157     66.968                                 \n",
      " 6    2269.52      70.093     61.983     65.789                                 \n",
      " 7    2158.31      73.267     61.157     66.667                                 \n",
      " 8    2128.42      73.077     62.810     67.556                                 \n",
      " 9    2140.31      73.148     65.289     68.996                                 \n",
      "10    2128.14      72.897     64.463     68.421                                 \n",
      "11    1953.51      74.074     66.116     69.869                                 \n",
      "12    1964.37      76.190     66.116     70.796                                 \n",
      "13    1934.57      76.190     66.116     70.796                                 \n",
      "14    1938.91      76.699     65.289     70.536                                 \n",
      "15    1927.21      75.962     65.289     70.222                                 \n",
      "16    1818.65      74.074     66.116     69.869                                 \n",
      "17    1743.74      73.394     66.116     69.565                                 \n",
      "18    1840.19      73.394     66.116     69.565                                 \n",
      "19    1756.54      73.394     66.116     69.565                                 \n",
      "20    1782.82      73.214     67.769     70.386                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.190   66.116    70.796\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.796\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model238_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2841.63      66.667     51.240     57.944                                 \n",
      " 2    2541.54      71.000     58.678     64.253                                 \n",
      " 3    2624.98      74.286     64.463     69.027                                 \n",
      " 4    2479.19      72.381     62.810     67.257                                 \n",
      " 5    2270.30      76.000     62.810     68.778                                 \n",
      " 6    2212.17      78.788     64.463     70.909                                 \n",
      " 7    2110.47      77.451     65.289     70.852                                 \n",
      " 8    2153.75      75.962     65.289     70.222                                 \n",
      " 9    2121.30      70.536     65.289     67.811                                 \n",
      "10    2128.43      74.312     66.942     70.435                                 \n",
      "11    2052.19      72.642     63.636     67.841                                 \n",
      "12    1985.68      74.528     65.289     69.604                                 \n",
      "13    1987.99      75.962     65.289     70.222                                 \n",
      "14    1907.61      75.472     66.116     70.485                                 \n",
      "15    1909.07      78.302     68.595     73.128                                 \n",
      "16    1837.15      78.704     70.248     74.236                                 \n",
      "17    1805.89      75.676     69.421     72.414                                 \n",
      "18    1785.03      75.676     69.421     72.414                                 \n",
      "19    1753.89      75.676     69.421     72.414                                 \n",
      "20    1806.61      75.926     67.769     71.616                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.704   70.248    74.236\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m74.236\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2400_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2806.66      75.714     43.802     55.497                                 \n",
      " 2    2633.43      67.347     54.545     60.274                                 \n",
      " 3    2572.44      70.755     61.983     66.079                                 \n",
      " 4    2364.41      79.592     64.463     71.233                                 \n",
      " 5    2314.21      78.947     61.983     69.444                                 \n",
      " 6    2192.11      79.208     66.116     72.072                                 \n",
      " 7    2178.49      78.095     67.769     72.566                                 \n",
      " 8    2140.86      76.636     67.769     71.930                                 \n",
      " 9    2077.71      75.455     68.595     71.861                                 \n",
      "10    2060.41      75.455     68.595     71.861                                 \n",
      "11    1954.71      74.545     67.769     70.996                                 \n",
      "12    1985.18      74.074     66.116     69.869                                 \n",
      "13    1974.89      72.727     66.116     69.264                                 \n",
      "14    1901.23      74.074     66.116     69.869                                 \n",
      "15    1868.37      74.528     65.289     69.604                                 \n",
      "16    1846.59      75.238     65.289     69.912                                 \n",
      "17    1746.86      75.472     66.116     70.485                                 \n",
      "18    1805.07      75.000     66.942     70.742                                 \n",
      "19    1745.85      75.000     66.942     70.742                                 \n",
      "20    1784.49      76.415     66.942     71.366                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      78.095   67.769    72.566\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m72.566\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2401_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2793.83      63.514     38.843     48.205                                 \n",
      " 2    2667.81      64.557     42.149     51.000                                 \n",
      " 3    2491.55      63.889     57.025     60.262                                 \n",
      " 4    2427.21      74.444     55.372     63.507                                 \n",
      " 5    2308.64      72.727     59.504     65.455                                 \n",
      " 6    2244.07      71.560     64.463     67.826                                 \n",
      " 7    2147.13      72.549     61.157     66.368                                 \n",
      " 8    2091.62      72.549     61.157     66.368                                 \n",
      " 9    2126.65      66.667     57.851     61.947                                 \n",
      "10    2065.45      65.686     55.372     60.090                                 \n",
      "11    1995.32      65.686     55.372     60.090                                 \n",
      "12    1993.21      66.346     57.025     61.333                                 \n",
      "13    1944.17      68.269     58.678     63.111                                 \n",
      "14    1929.26      68.932     58.678     63.393                                 \n",
      "15    1863.04      68.627     57.851     62.780                                 \n",
      "16    1858.96      66.667     57.851     61.947                                 \n",
      "17    1822.12      66.019     56.198     60.714                                 \n",
      "18    1831.17      66.019     56.198     60.714                                 \n",
      "19    1783.38      66.667     56.198     60.987                                 \n",
      "20    1807.48      67.619     58.678     62.832                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      71.560   64.463    67.826\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.826\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2402_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2808.31      71.084     48.760     57.843                                 \n",
      " 2    2583.10      65.957     51.240     57.674                                 \n",
      " 3    2561.20      68.224     60.331     64.035                                 \n",
      " 4    2542.19      72.549     61.157     66.368                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5    2361.31      73.469     59.504     65.753                                 \n",
      " 6    2303.57      76.842     60.331     67.593                                 \n",
      " 7    2176.19      75.000     64.463     69.333                                 \n",
      " 8    2213.70      67.890     61.157     64.348                                 \n",
      " 9    2150.87      66.972     60.331     63.478                                 \n",
      "10    2167.82      69.231     59.504     64.000                                 \n",
      "11    2003.04      70.476     61.157     65.487                                 \n",
      "12    2087.85      70.588     59.504     64.574                                 \n",
      "13    1997.76      71.569     60.331     65.471                                 \n",
      "14    1983.34      71.845     61.157     66.071                                 \n",
      "15    1937.10      71.154     61.157     65.778                                 \n",
      "16    1839.76      67.593     60.331     63.755                                 \n",
      "17    1801.46      68.807     61.983     65.217                                 \n",
      "18    1863.33      68.807     61.983     65.217                                 \n",
      "19    1808.65      68.182     61.983     64.935                                 \n",
      "20    1802.61      67.857     62.810     65.236                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      75.000   64.463    69.333\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.333\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model304_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2795.15      67.857     47.107     55.610                                 \n",
      " 2    2536.50      68.627     57.851     62.780                                 \n",
      " 3    2555.82      72.897     64.463     68.421                                 \n",
      " 4    2422.45      71.681     66.942     69.231                                 \n",
      " 5    2308.64      74.312     66.942     70.435                                 \n",
      " 6    2209.30      75.455     68.595     71.861                                 \n",
      " 7    2113.25      76.699     65.289     70.536                                 \n",
      " 8    2127.03      75.728     64.463     69.643                                 \n",
      " 9    2052.88      75.926     67.769     71.616                                 \n",
      "10    2053.66      77.143     66.942     71.681                                 \n",
      "11    1923.30      76.923     66.116     71.111                                 \n",
      "12    1954.14      75.000     66.942     70.742                                 \n",
      "13    1941.27      75.238     65.289     69.912                                 \n",
      "14    1927.78      76.636     67.769     71.930                                 \n",
      "15    1871.33      77.143     66.942     71.681                                 \n",
      "16    1847.48      78.846     67.769     72.889                                 \n",
      "17    1779.30      76.190     66.116     70.796                                 \n",
      "18    1804.10      74.528     65.289     69.604                                 \n",
      "19    1773.02      75.676     69.421     72.414                                 \n",
      "20    1788.58      76.577     70.248     73.276                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.577   70.248    73.276\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.276\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2797.67      60.215     46.281     52.336                                 \n",
      " 2    2641.78      65.049     55.372     59.821                                 \n",
      " 3    2620.63      65.546     64.463     65.000                                 \n",
      " 4    2482.34      67.826     64.463     66.102                                 \n",
      " 5    2308.18      68.750     63.636     66.094                                 \n",
      " 6    2166.06      76.415     66.942     71.366                                 \n",
      " 7    2144.83      76.415     66.942     71.366                                 \n",
      " 8    2195.78      70.909     64.463     67.532                                 \n",
      " 9    2069.41      70.909     64.463     67.532                                 \n",
      "10    2019.54      70.796     66.116     68.376                                 \n",
      "11    1995.21      70.690     67.769     69.198                                 \n",
      "12    1936.85      71.681     66.942     69.231                                 \n",
      "13    1960.66      74.775     68.595     71.552                                 \n",
      "14    1917.22      74.107     68.595     71.245                                 \n",
      "15    1875.61      74.074     66.116     69.869                                 \n",
      "16    1856.18      71.171     65.289     68.103                                 \n",
      "17    1776.93      72.477     65.289     68.696                                 \n",
      "18    1847.68      71.429     66.116     68.670                                 \n",
      "19    1769.72      73.148     65.289     68.996                                 \n",
      "20    1822.49      72.222     64.463     68.122                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      74.775   68.595    71.552\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m71.552\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model336_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2807.84      67.857     47.107     55.610                                 \n",
      " 2    2565.42      67.708     53.719     59.908                                 \n",
      " 3    2521.45      68.807     61.983     65.217                                 \n",
      " 4    2411.11      74.528     65.289     69.604                                 \n",
      " 5    2360.68      76.699     65.289     70.536                                 \n",
      " 6    2248.64      80.198     66.942     72.973                                 \n",
      " 7    2165.88      79.612     67.769     73.214                                 \n",
      " 8    2152.64      78.095     67.769     72.566                                 \n",
      " 9    2100.98      78.846     67.769     72.889                                 \n",
      "10    1990.05      79.048     68.595     73.451                                 \n",
      "11    1959.98      78.095     67.769     72.566                                 \n",
      "12    1967.26      77.000     63.636     69.683                                 \n",
      "13    1967.40      77.228     64.463     70.270                                 \n",
      "14    1912.65      78.000     64.463     70.588                                 \n",
      "15    1882.06      77.228     64.463     70.270                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    1852.45      77.670     66.116     71.429                                 \n",
      "17    1763.95      77.885     66.942     72.000                                 \n",
      "18    1850.99      75.000     66.942     70.742                                 \n",
      "19    1760.18      74.074     66.116     69.869                                 \n",
      "20    1793.47      75.472     66.116     70.485                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      79.048   68.595    73.451\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m73.451\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model4_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2840.54      65.217     37.190     47.368                                 \n",
      " 2    2653.74      69.149     53.719     60.465                                 \n",
      " 3    2628.88      72.632     57.025     63.889                                 \n",
      " 4    2460.33      67.677     55.372     60.909                                 \n",
      " 5    2461.94      77.083     61.157     68.203                                 \n",
      " 6    2294.17      72.449     58.678     64.840                                 \n",
      " 7    2204.53      74.000     61.157     66.968                                 \n",
      " 8    2235.81      73.585     64.463     68.722                                 \n",
      " 9    2139.04      73.077     62.810     67.556                                 \n",
      "10    2156.96      76.699     65.289     70.536                                 \n",
      "11    2061.10      75.490     63.636     69.058                                 \n",
      "12    2095.24      75.728     64.463     69.643                                 \n",
      "13    2003.88      74.038     63.636     68.444                                 \n",
      "14    1963.08      72.642     63.636     67.841                                 \n",
      "15    1957.70      72.897     64.463     68.421                                 \n",
      "16    1889.26      69.091     62.810     65.801                                 \n",
      "17    1833.07      70.642     63.636     66.957                                 \n",
      "18    1848.20      71.296     63.636     67.249                                 \n",
      "19    1791.94      69.159     61.157     64.912                                 \n",
      "20    1856.41      67.890     61.157     64.348                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      76.699   65.289    70.536\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m70.536\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2862.82      65.882     46.281     54.369                                 \n",
      " 2    2616.25      71.951     48.760     58.128                                 \n",
      " 3    2675.21      74.000     61.157     66.968                                 \n",
      " 4    2518.05      71.845     61.157     66.071                                 \n",
      " 5    2474.83      74.000     61.157     66.968                                 \n",
      " 6    2239.61      74.257     61.983     67.568                                 \n",
      " 7    2207.63      74.000     61.157     66.968                                 \n",
      " 8    2162.70      73.585     64.463     68.722                                 \n",
      " 9    2152.96      71.429     61.983     66.372                                 \n",
      "10    2087.07      70.874     60.331     65.179                                 \n",
      "11    2062.46      68.571     59.504     63.717                                 \n",
      "12    1973.77      70.588     59.504     64.574                                 \n",
      "13    1998.71      74.257     61.983     67.568                                 \n",
      "14    1911.77      73.333     63.636     68.142                                 \n",
      "15    1910.92      74.257     61.983     67.568                                 \n",
      "16    1882.94      74.257     61.983     67.568                                 \n",
      "17    1757.46      73.529     61.983     67.265                                 \n",
      "18    1834.98      73.077     62.810     67.556                                 \n",
      "19    1810.17      72.642     63.636     67.841                                 \n",
      "20    1793.99      71.028     62.810     66.667                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.585   64.463    68.722\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.722\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2794.57      67.500     44.628     53.731                                 \n",
      " 2    2676.78      71.591     52.066     60.287                                 \n",
      " 3    2652.73      74.757     63.636     68.750                                 \n",
      " 4    2492.62      72.477     65.289     68.696                                 \n",
      " 5    2349.20      72.072     66.116     68.966                                 \n",
      " 6    2177.82      72.381     62.810     67.257                                 \n",
      " 7    2135.84      74.000     61.157     66.968                                 \n",
      " 8    2124.91      73.000     60.331     66.063                                 \n",
      " 9    2071.28      69.608     58.678     63.677                                 \n",
      "10    2061.34      67.327     56.198     61.261                                 \n",
      "11    1988.24      68.687     56.198     61.818                                 \n",
      "12    1934.11      69.608     58.678     63.677                                 \n",
      "13    1951.67      69.388     56.198     62.100                                 \n",
      "14    1892.36      67.677     55.372     60.909                                 \n",
      "15    1898.52      66.990     57.025     61.607                                 \n",
      "16    1839.48      65.094     57.025     60.793                                 \n",
      "17    1774.77      65.094     57.025     60.793                                 \n",
      "18    1823.04      65.714     57.025     61.062                                 \n",
      "19    1792.11      64.815     57.851     61.135                                 \n",
      "20    1761.68      66.355     58.678     62.281                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.072   66.116    68.966\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.966\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2887.46      60.606     49.587     54.545                                 \n",
      " 2    2691.38      64.211     50.413     56.481                                 \n",
      " 3    2570.09      70.270     64.463     67.241                                 \n",
      " 4    2378.41      73.333     63.636     68.142                                 \n",
      " 5    2345.38      71.429     61.983     66.372                                 \n",
      " 6    2291.42      70.000     63.636     66.667                                 \n",
      " 7    2229.52      71.963     63.636     67.544                                 \n",
      " 8    2167.06      72.816     61.983     66.964                                 \n",
      " 9    2082.87      72.816     61.983     66.964                                 \n",
      "10    2097.05      72.381     62.810     67.257                                 \n",
      "11    1990.27      70.642     63.636     66.957                                 \n",
      "12    1937.83      71.028     62.810     66.667                                 \n",
      "13    2033.24      73.148     65.289     68.996                                 \n",
      "14    1898.92      73.394     66.116     69.565                                 \n",
      "15    1918.35      70.796     66.116     68.376                                 \n",
      "16    1900.82      72.973     66.942     69.828                                 \n",
      "17    1797.56      72.973     66.942     69.828                                 \n",
      "18    1898.56      71.429     66.116     68.670                                 \n",
      "19    1793.60      71.930     67.769     69.787                                 \n",
      "20    1802.78      71.681     66.942     69.231                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      72.973   66.942    69.828\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.828\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 547 total examples\n",
      "Using 438 train / 109 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    2883.15      70.769     38.017     49.462                                 \n",
      " 2    2738.32      67.327     56.198     61.261                                 \n",
      " 3    2792.42      65.714     57.025     61.062                                 \n",
      " 4    2589.71      73.394     66.116     69.565                                 \n",
      " 5    2391.13      72.477     65.289     68.696                                 \n",
      " 6    2200.77      72.381     62.810     67.257                                 \n",
      " 7    2173.22      69.811     61.157     65.198                                 \n",
      " 8    2122.49      68.182     61.983     64.935                                 \n",
      " 9    2148.31      66.364     60.331     63.203                                 \n",
      "10    2166.39      66.667     61.157     63.793                                 \n",
      "11    2027.04      67.273     61.157     64.069                                 \n",
      "12    2011.47      66.667     59.504     62.882                                 \n",
      "13    2000.59      65.766     60.331     62.931                                 \n",
      "14    1914.27      67.593     60.331     63.755                                 \n",
      "15    1895.75      66.355     58.678     62.281                                 \n",
      "16    1860.21      67.308     57.851     62.222                                 \n",
      "17    1824.88      68.868     60.331     64.317                                 \n",
      "18    1797.93      66.364     60.331     63.203                                 \n",
      "19    1753.96      66.972     60.331     63.478                                 \n",
      "20    1775.64      65.455     59.504     62.338                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      73.394   66.116    69.565\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.565\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "= cord_19_rf_sentences,cord_19_rf_sentences_correct,cord_19_rf_sentences_correct_2,cord_19_rf_sentences_correct_3 ==================================\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_fil_sci_model975_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3294.10      55.118     44.304     49.123                                 \n",
      " 2    3144.89      58.710     57.595     58.147                                 \n",
      " 3    2843.06      58.580     62.658     60.550                                 \n",
      " 4    2683.41      61.176     65.823     63.415                                 \n",
      " 5    2660.83      62.500     66.456     64.417                                 \n",
      " 6    2744.55      62.577     64.557     63.551                                 \n",
      " 7    2499.85      62.275     65.823     64.000                                 \n",
      " 8    2494.08      62.577     64.557     63.551                                 \n",
      " 9    2377.12      63.030     65.823     64.396                                 \n",
      "10    2447.42      61.850     67.722     64.653                                 \n",
      "11    2258.15      61.272     67.089     64.048                                 \n",
      "12    2318.00      61.538     65.823     63.609                                 \n",
      "13    2270.55      61.988     67.089     64.438                                 \n",
      "14    2137.15      62.874     66.456     64.615                                 \n",
      "15    2242.41      62.195     64.557     63.354                                 \n",
      "16    2215.25      63.006     68.987     65.861                                 \n",
      "17    2164.49      61.905     65.823     63.804                                 \n",
      "18    2143.07      62.651     65.823     64.198                                 \n",
      "19    2097.86      62.573     67.722     65.046                                 \n",
      "20    2110.40      61.017     68.354     64.478                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      63.006   68.987    65.861\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m65.861\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model238_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3093.32      62.162     58.228     60.131                                 \n",
      " 2    3023.72      60.606     63.291     61.920                                 \n",
      " 3    2790.50      63.924     63.924     63.924                                 \n",
      " 4    2737.17      59.429     65.823     62.462                                 \n",
      " 5    2689.04      62.353     67.089     64.634                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6    2704.25      61.047     66.456     63.636                                 \n",
      " 7    2515.93      64.458     67.722     66.049                                 \n",
      " 8    2408.94      64.848     67.722     66.254                                 \n",
      " 9    2225.26      62.722     67.089     64.832                                 \n",
      "10    2307.57      62.209     67.722     64.848                                 \n",
      "11    2218.61      62.428     68.354     65.257                                 \n",
      "12    2245.70      61.017     68.354     64.478                                 \n",
      "13    2187.27      60.227     67.089     63.473                                 \n",
      "14    2113.84      59.444     67.722     63.314                                 \n",
      "15    2176.02      59.551     67.089     63.095                                 \n",
      "16    2209.57      62.011     70.253     65.875                                 \n",
      "17    2125.54      61.538     70.886     65.882                                 \n",
      "18    2127.06      61.667     70.253     65.680                                 \n",
      "19    2071.28      61.798     69.620     65.476                                 \n",
      "20    2095.05      62.147     69.620     65.672                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      64.848   67.722    66.254\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.254\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2400_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3162.30      69.027     49.367     57.565                                 \n",
      " 2    3103.72      59.429     65.823     62.462                                 \n",
      " 3    2760.52      59.538     65.190     62.236                                 \n",
      " 4    2750.42      61.714     68.354     64.865                                 \n",
      " 5    2586.46      63.793     70.253     66.867                                 \n",
      " 6    2640.77      65.497     70.886     68.085                                 \n",
      " 7    2535.86      65.714     72.785     69.069                                 \n",
      " 8    2425.09      64.706     69.620     67.073                                 \n",
      " 9    2250.11      63.006     68.987     65.861                                 \n",
      "10    2355.13      61.850     67.722     64.653                                 \n",
      "11    2240.51      62.712     70.253     66.269                                 \n",
      "12    2280.69      63.429     70.253     66.667                                 \n",
      "13    2241.91      62.644     68.987     65.663                                 \n",
      "14    2166.71      63.372     68.987     66.061                                 \n",
      "15    2195.16      60.227     67.089     63.473                                 \n",
      "16    2225.34      61.714     68.354     64.865                                 \n",
      "17    2170.97      59.659     66.456     62.874                                 \n",
      "18    2142.17      61.017     68.354     64.478                                 \n",
      "19    2068.66      62.069     68.354     65.060                                 \n",
      "20    2117.31      60.000     66.456     63.063                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      65.714   72.785    69.069\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.069\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2401_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3342.40      53.913     39.241     45.421                                 \n",
      " 2    3127.17      58.904     54.430     56.579                                 \n",
      " 3    2854.93      56.322     62.025     59.036                                 \n",
      " 4    2773.00      57.838     67.722     62.391                                 \n",
      " 5    2692.39      60.674     68.354     64.286                                 \n",
      " 6    2755.96      61.538     70.886     65.882                                 \n",
      " 7    2527.83      61.714     68.354     64.865                                 \n",
      " 8    2501.04      63.372     68.987     66.061                                 \n",
      " 9    2391.68      61.714     68.354     64.865                                 \n",
      "10    2348.48      61.017     68.354     64.478                                 \n",
      "11    2292.74      60.112     67.722     63.690                                 \n",
      "12    2393.73      60.795     67.722     64.072                                 \n",
      "13    2364.78      60.694     66.456     63.444                                 \n",
      "14    2195.55      61.714     68.354     64.865                                 \n",
      "15    2228.89      61.047     66.456     63.636                                 \n",
      "16    2229.43      60.819     65.823     63.222                                 \n",
      "17    2213.96      60.714     64.557     62.577                                 \n",
      "18    2228.19      59.763     63.924     61.774                                 \n",
      "19    2090.92      59.412     63.924     61.585                                 \n",
      "20    2156.21      60.000     64.557     62.195                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      63.372   68.987    66.061\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.061\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model2402_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3369.27      56.489     46.835     51.211                                 \n",
      " 2    3304.39      59.763     63.924     61.774                                 \n",
      " 3    3037.59      58.242     67.089     62.353                                 \n",
      " 4    2904.90      61.310     65.190     63.190                                 \n",
      " 5    2728.94      64.151     64.557     64.353                                 \n",
      " 6    2745.43      62.874     66.456     64.615                                 \n",
      " 7    2542.22      62.573     67.722     65.046                                 \n",
      " 8    2494.95      61.798     69.620     65.476                                 \n",
      " 9    2332.51      62.428     68.354     65.257                                 \n",
      "10    2354.52      61.272     67.089     64.048                                 \n",
      "11    2297.31      63.636     66.456     65.015                                 \n",
      "12    2343.85      62.941     67.722     65.244                                 \n",
      "13    2299.34      62.573     67.722     65.046                                 \n",
      "14    2235.92      61.850     67.722     64.653                                 \n",
      "15    2230.12      62.069     68.354     65.060                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16    2259.31      62.286     68.987     65.465                                 \n",
      "17    2172.34      60.819     65.823     63.222                                 \n",
      "18    2185.19      60.234     65.190     62.614                                 \n",
      "19    2099.32      60.588     65.190     62.805                                 \n",
      "20    2158.36      61.628     67.089     64.242                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      61.798   69.620    65.476\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m65.476\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model304_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3132.24      57.857     51.266     54.362                                 \n",
      " 2    2949.80      58.750     59.494     59.119                                 \n",
      " 3    2778.83      59.649     64.557     62.006                                 \n",
      " 4    2694.90      61.143     67.722     64.264                                 \n",
      " 5    2574.86      58.564     67.089     62.537                                 \n",
      " 6    2670.84      58.192     65.190     61.493                                 \n",
      " 7    2542.23      61.272     67.089     64.048                                 \n",
      " 8    2392.85      60.694     66.456     63.444                                 \n",
      " 9    2401.07      58.791     67.722     62.941                                 \n",
      "10    2352.82      59.677     70.253     64.535                                 \n",
      "11    2271.36      60.335     68.354     64.095                                 \n",
      "12    2269.58      62.573     67.722     65.046                                 \n",
      "13    2249.90      59.444     67.722     63.314                                 \n",
      "14    2163.20      60.694     66.456     63.444                                 \n",
      "15    2187.82      58.757     65.823     62.090                                 \n",
      "16    2209.48      59.341     68.354     63.529                                 \n",
      "17    2172.41      59.322     66.456     62.687                                 \n",
      "18    2168.97      60.000     68.354     63.905                                 \n",
      "19    2038.43      60.894     68.987     64.688                                 \n",
      "20    2129.97      61.272     67.089     64.048                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      62.573   67.722    65.046\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m65.046\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model308_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3156.95      61.151     53.797     57.239                                 \n",
      " 2    3017.74      65.605     65.190     65.397                                 \n",
      " 3    2873.36      61.017     68.354     64.478                                 \n",
      " 4    2664.88      63.006     68.987     65.861                                 \n",
      " 5    2662.04      63.536     72.785     67.847                                 \n",
      " 6    2750.53      64.671     68.354     66.462                                 \n",
      " 7    2456.09      65.060     68.354     66.667                                 \n",
      " 8    2444.32      66.667     69.620     68.111                                 \n",
      " 9    2290.36      66.667     70.886     68.712                                 \n",
      "10    2332.16      65.868     69.620     67.692                                 \n",
      "11    2251.41      67.456     72.152     69.725                                 \n",
      "12    2275.62      65.269     68.987     67.077                                 \n",
      "13    2294.32      64.912     70.253     67.477                                 \n",
      "14    2166.58      64.497     68.987     66.667                                 \n",
      "15    2245.13      62.941     67.722     65.244                                 \n",
      "16    2196.38      63.690     67.722     65.644                                 \n",
      "17    2170.64      63.253     66.456     64.815                                 \n",
      "18    2182.58      61.404     66.456     63.830                                 \n",
      "19    2082.13      61.988     67.089     64.438                                 \n",
      "20    2113.87      61.988     67.089     64.438                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      67.456   72.152    69.725\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m69.725\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model336_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3189.90      60.563     54.430     57.333                                 \n",
      " 2    3011.57      59.394     62.025     60.681                                 \n",
      " 3    2732.94      62.360     70.253     66.071                                 \n",
      " 4    2654.66      62.644     68.987     65.663                                 \n",
      " 5    2675.53      61.538     65.823     63.609                                 \n",
      " 6    2594.20      61.728     63.291     62.500                                 \n",
      " 7    2466.90      60.843     63.924     62.346                                 \n",
      " 8    2440.93      63.580     65.190     64.375                                 \n",
      " 9    2289.85      63.030     65.823     64.396                                 \n",
      "10    2391.16      61.143     67.722     64.264                                 \n",
      "11    2203.84      60.571     67.089     63.664                                 \n",
      "12    2279.53      61.494     67.722     64.458                                 \n",
      "13    2178.66      61.714     68.354     64.865                                 \n",
      "14    2174.87      61.494     67.722     64.458                                 \n",
      "15    2187.26      62.722     67.089     64.832                                 \n",
      "16    2203.74      63.529     68.354     65.854                                 \n",
      "17    2184.91      63.158     68.354     65.653                                 \n",
      "18    2175.33      64.162     70.253     67.069                                 \n",
      "19    2068.13      63.953     69.620     66.667                                 \n",
      "20    2101.97      62.857     69.620     66.066                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      64.162   70.253    67.069\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.069\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_abs_sci_model4_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3252.78      63.158     37.975     47.431                                 \n",
      " 2    3145.03      55.556     60.127     57.751                                 \n",
      " 3    2881.81      58.182     60.759     59.443                                 \n",
      " 4    2755.29      62.893     63.291     63.091                                 \n",
      " 5    2683.58      60.241     63.291     61.728                                 \n",
      " 6    2673.09      61.585     63.924     62.733                                 \n",
      " 7    2510.47      61.078     64.557     62.769                                 \n",
      " 8    2501.42      61.538     65.823     63.609                                 \n",
      " 9    2392.42      62.275     65.823     64.000                                 \n",
      "10    2332.24      63.354     64.557     63.950                                 \n",
      "11    2283.44      64.634     67.089     65.839                                 \n",
      "12    2303.36      64.417     66.456     65.421                                 \n",
      "13    2240.49      64.286     68.354     66.258                                 \n",
      "14    2194.01      62.209     67.722     64.848                                 \n",
      "15    2248.30      61.905     65.823     63.804                                 \n",
      "16    2223.60      60.947     65.190     62.997                                 \n",
      "17    2211.45      60.119     63.924     61.963                                 \n",
      "18    2187.76      59.064     63.924     61.398                                 \n",
      "19    2070.55      59.302     64.557     61.818                                 \n",
      "20    2112.19      59.091     65.823     62.275                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      64.286   68.354    66.258\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.258\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model328.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3319.06      58.974     43.671     50.182                                 \n",
      " 2    3122.23      60.976     63.291     62.112                                 \n",
      " 3    2861.07      58.642     60.127     59.375                                 \n",
      " 4    2679.18      58.434     61.392     59.877                                 \n",
      " 5    2626.89      58.788     61.392     60.062                                 \n",
      " 6    2802.22      59.649     64.557     62.006                                 \n",
      " 7    2489.77      60.674     68.354     64.286                                 \n",
      " 8    2454.14      58.857     65.190     61.862                                 \n",
      " 9    2308.08      58.659     66.456     62.315                                 \n",
      "10    2368.19      59.659     66.456     62.874                                 \n",
      "11    2284.69      59.195     65.190     62.048                                 \n",
      "12    2298.18      59.302     64.557     61.818                                 \n",
      "13    2234.99      59.195     65.190     62.048                                 \n",
      "14    2215.40      61.538     65.823     63.609                                 \n",
      "15    2185.27      61.988     67.089     64.438                                 \n",
      "16    2213.28      61.988     67.089     64.438                                 \n",
      "17    2196.58      61.988     67.089     64.438                                 \n",
      "18    2208.78      61.765     66.456     64.024                                 \n",
      "19    2122.16      61.538     65.823     63.609                                 \n",
      "20    2112.34      62.130     66.456     64.220                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      61.988   67.089    64.438\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m64.438\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model978_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3268.47      59.333     56.329     57.792                                 \n",
      " 2    3236.41      56.707     58.861     57.764                                 \n",
      " 3    2860.58      60.227     67.089     63.473                                 \n",
      " 4    2781.13      59.538     65.190     62.236                                 \n",
      " 5    2675.89      60.109     69.620     64.516                                 \n",
      " 6    2654.27      63.636     70.886     67.066                                 \n",
      " 7    2547.10      64.327     69.620     66.869                                 \n",
      " 8    2477.01      66.467     70.253     68.308                                 \n",
      " 9    2344.13      64.118     68.987     66.463                                 \n",
      "10    2393.50      63.953     69.620     66.667                                 \n",
      "11    2299.88      61.236     68.987     64.881                                 \n",
      "12    2334.80      63.584     69.620     66.465                                 \n",
      "13    2291.06      63.429     70.253     66.667                                 \n",
      "14    2209.91      60.335     68.354     64.095                                 \n",
      "15    2237.64      60.571     67.089     63.664                                 \n",
      "16    2209.43      62.286     68.987     65.465                                 \n",
      "17    2189.68      63.743     68.987     66.261                                 \n",
      "18    2145.88      64.118     68.987     66.463                                 \n",
      "19    2065.52      64.118     68.987     66.463                                 \n",
      "20    2113.72      64.912     70.253     67.477                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      66.467   70.253    68.308\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m68.308\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model989.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3205.45      55.556     47.468     51.195                                 \n",
      " 2    3117.68      58.025     59.494     58.750                                 \n",
      " 3    3025.00      58.427     65.823     61.905                                 \n",
      " 4    2707.06      58.235     62.658     60.366                                 \n",
      " 5    2693.91      56.757     66.456     61.224                                 \n",
      " 6    2788.81      58.659     66.456     62.315                                 \n",
      " 7    2492.68      58.889     67.089     62.722                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8    2481.98      63.636     70.886     67.066                                 \n",
      " 9    2308.64      61.667     70.253     65.680                                 \n",
      "10    2331.56      61.667     70.253     65.680                                 \n",
      "11    2263.43      61.364     68.354     64.671                                 \n",
      "12    2270.75      59.777     67.722     63.501                                 \n",
      "13    2240.81      60.112     67.722     63.690                                 \n",
      "14    2167.25      59.669     68.354     63.717                                 \n",
      "15    2222.46      60.112     67.722     63.690                                 \n",
      "16    2221.35      60.894     68.987     64.688                                 \n",
      "17    2218.76      62.360     70.253     66.071                                 \n",
      "18    2190.62      60.773     69.620     64.897                                 \n",
      "19    2090.48      60.773     69.620     64.897                                 \n",
      "20    2124.58      61.111     69.620     65.089                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      63.636   70.886    67.066\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m67.066\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded model 'en_core_sci_md'\u001b[0m\n",
      "Created and merged data for 625 total examples\n",
      "Using 500 train / 125 eval (split 20%)\n",
      "Component: ner | Batch size: compounding | Dropout: 0.2 | Iterations: 20\n",
      "\u001b[38;5;2m✔ Initializing with tok2vec weights\n",
      "models/tok2vec_rf_sci_model997_gpu.bin\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ Baseline accuracy: 0.000\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== ✨  Training the model ===========================\u001b[0m\n",
      "\n",
      "#    Loss       Precision   Recall     F-Score \n",
      "--   --------   ---------   --------   --------\n",
      " 1    3296.37      66.418     56.329     60.959                                 \n",
      " 2    3039.12      63.694     63.291     63.492                                 \n",
      " 3    2833.30      60.123     62.025     61.059                                 \n",
      " 4    2722.14      60.241     63.291     61.728                                 \n",
      " 5    2628.34      63.314     67.722     65.443                                 \n",
      " 6    2654.93      64.286     68.354     66.258                                 \n",
      " 7    2498.33      62.500     66.456     64.417                                 \n",
      " 8    2445.82      63.473     67.089     65.231                                 \n",
      " 9    2317.68      62.651     65.823     64.198                                 \n",
      "10    2331.69      64.024     66.456     65.217                                 \n",
      "11    2297.64      64.242     67.089     65.635                                 \n",
      "12    2260.03      64.815     66.456     65.625                                 \n",
      "13    2225.47      64.024     66.456     65.217                                 \n",
      "14    2172.33      62.722     67.089     64.832                                 \n",
      "15    2248.65      62.722     67.089     64.832                                 \n",
      "16    2240.78      62.874     66.456     64.615                                 \n",
      "17    2172.88      62.651     65.823     64.198                                 \n",
      "18    2186.47      63.095     67.089     65.031                                 \n",
      "19    2069.33      62.722     67.089     64.832                                 \n",
      "20    2140.38      62.353     67.089     64.634                                 \n",
      "\u001b[1m\n",
      "============================= ✨  Results summary =============================\u001b[0m\n",
      "\n",
      "Label         Precision   Recall   F-Score\n",
      "-----------   ---------   ------   -------\n",
      "RISK_FACTOR      64.286   68.354    66.258\n",
      "\n",
      "\n",
      "Best F-Score   \u001b[38;5;2m66.258\u001b[0m\n",
      "Baseline       0.000              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets_list = [\n",
    "    \"cord_19_rf_sentences\",\n",
    "    \"cord_19_rf_sentences,cord_19_rf_sentences_correct\",\n",
    "    \"cord_19_rf_sentences,cord_19_rf_sentences_correct,cord_19_rf_sentences_correct_2\",\n",
    "    \"cord_19_rf_sentences,cord_19_rf_sentences_correct,cord_19_rf_sentences_correct_2,cord_19_rf_sentences_correct_3\"\n",
    "]\n",
    "for datasets in datasets_list:\n",
    "    print(f\"= {datasets} ==================================\")\n",
    "    train_ner_with_every_tok2vec(datasets, \"en_core_sci_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save top `md` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package top `md` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Try to use the `teach` recipe!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
